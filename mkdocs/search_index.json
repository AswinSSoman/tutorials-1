{
    "docs": [
        {
            "location": "/", 
            "text": "Welcome!\n\n\nABRPI training materials\n\n\nAntibiotic Resistant Pathogens Initiative\n\n\n\n\n\n\nThis site contains tutorials for using the ABRPI\n\nMicrobial Genomics Virtual Lab\n (the mGVL) to perform bioinformatics\ntasks on bacterial \nomics\n data, either on the Unix command line or using\nthe \nGalaxy\n system.\n\n\n\n\n\n\nTutorials are listed under the tabs in the top panel and are being added progressively.\n\n\n\n\n\n\nIf you wish to set up your own instance (version) of the mGVL, follow the instructions \nhere\n.\n\n\n\n\nNote: at the stage where you select options in the GVL Launcher window, go to \nShow advanced startup options\n and under \nFlavor\n select \nMicrobial GVL with Tutorial Indices\n. In this mGVL instance, you can use both Galaxy and command line tools. If you wish to use the command line tools on a different computer (e.g. your local computer), you would need to make sure the required tools are installed (e.g. Canu, Circlator, Pilon, SPAdes, etc.).\n\n\n\n\n\n\n\n\nFor more information about how to use the Microbial Genomics Virtual Lab and Galaxy, see \nhttp://www.genome.edu.au/", 
            "title": "Home"
        }, 
        {
            "location": "/#welcome", 
            "text": "", 
            "title": "Welcome!"
        }, 
        {
            "location": "/#abrpi-training-materials", 
            "text": "", 
            "title": "ABRPI training materials"
        }, 
        {
            "location": "/#antibiotic-resistant-pathogens-initiative", 
            "text": "This site contains tutorials for using the ABRPI Microbial Genomics Virtual Lab  (the mGVL) to perform bioinformatics\ntasks on bacterial  omics  data, either on the Unix command line or using\nthe  Galaxy  system.    Tutorials are listed under the tabs in the top panel and are being added progressively.    If you wish to set up your own instance (version) of the mGVL, follow the instructions  here .   Note: at the stage where you select options in the GVL Launcher window, go to  Show advanced startup options  and under  Flavor  select  Microbial GVL with Tutorial Indices . In this mGVL instance, you can use both Galaxy and command line tools. If you wish to use the command line tools on a different computer (e.g. your local computer), you would need to make sure the required tools are installed (e.g. Canu, Circlator, Pilon, SPAdes, etc.).     For more information about how to use the Microbial Genomics Virtual Lab and Galaxy, see  http://www.genome.edu.au/", 
            "title": "Antibiotic Resistant Pathogens Initiative"
        }, 
        {
            "location": "/modules/workshop_overview/", 
            "text": "Genomics workshop overview\n\n\n\n\n\n\nThe modules in this workshop cover microbial genomics, from assembly to annotation and variant calling.\n\n\n\n\n\n\nThe analyses are conducted on the Galaxy platform, and links to training data are provided.\n\n\n\n\n\n\nThese modules can be delivered to a group workshop or used online independently.\n\n\n\n\n\n\nIf you have not yet used the Galaxy platform, we recommend following the modules in order.\n\n\n\n\n\n\nIf you are using these tutorials outside of a workshop and need access to Galaxy, you can follow the instructions on the homepage \nhere\n to obtain your own mGVL instance with Galaxy and command line tools.\n\n\n\n\n\n\nOverview\n\n\n\n\nStarting with Galaxy\n\n\nTraining dataset\n\n\nGenome assembly with two tools - Velvet and Spades\n\n\nGenome annotation\n\n\nVariant finding\n\n\nAccessing public data: assembly to annotation", 
            "title": "Workshop overview"
        }, 
        {
            "location": "/modules/workshop_overview/#genomics-workshop-overview", 
            "text": "The modules in this workshop cover microbial genomics, from assembly to annotation and variant calling.    The analyses are conducted on the Galaxy platform, and links to training data are provided.    These modules can be delivered to a group workshop or used online independently.    If you have not yet used the Galaxy platform, we recommend following the modules in order.    If you are using these tutorials outside of a workshop and need access to Galaxy, you can follow the instructions on the homepage  here  to obtain your own mGVL instance with Galaxy and command line tools.", 
            "title": "Genomics workshop overview"
        }, 
        {
            "location": "/modules/workshop_overview/#overview", 
            "text": "Starting with Galaxy  Training dataset  Genome assembly with two tools - Velvet and Spades  Genome annotation  Variant finding  Accessing public data: assembly to annotation", 
            "title": "Overview"
        }, 
        {
            "location": "/modules/galaxy/", 
            "text": "Get Data into Galaxy\n\n\nKeywords: Galaxy, Microbial Genomics Virtual Lab\n\n\nGalaxy Background\n\n\nGalaxy is a web-based analysis and workflow platform designed for biologists to analyse their own data. It can be used to run a variety of bioinformatics tools. The selection of bioinformatics tools installed on the Galaxy instance we are using today caters for the analysis of bacterial genomics data sets.\n\n\nGalaxy is an open, web-based platform. Details about the project can be found \nhere\n.\n\n\nThe Galaxy interface is separated into three parts. The \nTools\n list on the left, the \nViewing\n panel in the middle and the analysis and data \nHistory\n on the right.\n\n\n\n\nRegister in Galaxy\n\n\nOpen a new tab or window on your web browser. Use Firefox or Chrome - please don\u2019t use Internet Explorer or Safari.\n\n\nIn the address bar, type in the address of your galaxy server. Alternatively, you can access galaxy via the dashboard of your mGVL.\n\n\n\n\nClick on \nUser\n button on the right.\n\n\n\n\n\n\nSelect: \nUser \n Register\n\n\nEnter your email, choose a password, and choose a user name.\n\n\nClick \nSubmit\n\n\n\n\nImport a history\n\n\n\n\nIn the menu options across the top, go to \nShared Data\n.\n\n\nClick on \nHistories\n.\n\n\n\n\n\n\n\n\nA list of published histories should appear. Click on the history that you want to use.\n\n\nClick on \nImport history\n.\n\n\n\n\nAn option will appear to re-name the history. We don\nt need to rename it, so click \nImport\n.\n\n\n\n\n\n\nThe history will now appear in your Current History pane, and the files are ready to use in Galaxy analyses.\n\n\n\n\n\n\nOther ways to import data into Galaxy\n\n\n\n\nUpload a file from your computer\n\n\nCopy a link to a Galaxy history\n\n\nFor sample training data files to use, see the \nnext section.", 
            "title": "Starting with Galaxy"
        }, 
        {
            "location": "/modules/galaxy/#get-data-into-galaxy", 
            "text": "Keywords: Galaxy, Microbial Genomics Virtual Lab", 
            "title": "Get Data into Galaxy"
        }, 
        {
            "location": "/modules/galaxy/#galaxy-background", 
            "text": "Galaxy is a web-based analysis and workflow platform designed for biologists to analyse their own data. It can be used to run a variety of bioinformatics tools. The selection of bioinformatics tools installed on the Galaxy instance we are using today caters for the analysis of bacterial genomics data sets.  Galaxy is an open, web-based platform. Details about the project can be found  here .  The Galaxy interface is separated into three parts. The  Tools  list on the left, the  Viewing  panel in the middle and the analysis and data  History  on the right.", 
            "title": "Galaxy Background"
        }, 
        {
            "location": "/modules/galaxy/#register-in-galaxy", 
            "text": "Open a new tab or window on your web browser. Use Firefox or Chrome - please don\u2019t use Internet Explorer or Safari.  In the address bar, type in the address of your galaxy server. Alternatively, you can access galaxy via the dashboard of your mGVL.   Click on  User  button on the right.    Select:  User   Register  Enter your email, choose a password, and choose a user name.  Click  Submit", 
            "title": "Register in Galaxy"
        }, 
        {
            "location": "/modules/galaxy/#import-a-history", 
            "text": "In the menu options across the top, go to  Shared Data .  Click on  Histories .     A list of published histories should appear. Click on the history that you want to use.  Click on  Import history .   An option will appear to re-name the history. We don t need to rename it, so click  Import .    The history will now appear in your Current History pane, and the files are ready to use in Galaxy analyses.", 
            "title": "Import a history"
        }, 
        {
            "location": "/modules/galaxy/#other-ways-to-import-data-into-galaxy", 
            "text": "Upload a file from your computer  Copy a link to a Galaxy history  For sample training data files to use, see the  next section.", 
            "title": "Other ways to import data into Galaxy"
        }, 
        {
            "location": "/modules/data-dna/", 
            "text": "Dataset\n\n\nThis page contains data for the tutorials. The tutorials will specify whether to import a whole history (URLs listed in the first section) or an individual file (URLs listed in the second section).\n\n\nGalaxy histories: URLs\n\n\n\n\nGalaxy history of input files\n\n\n\n\nhttps://swift.rc.nectar.org.au:8888/v1/AUTH_377/public/Microbial_tutorials/Galaxy_history_input_files.tar.gz\n\n\n\n\nGalaxy history: FastQC\n\n\n\n\nhttps://swift.rc.nectar.org.au:8888/v1/AUTH_377/public/Microbial_tutorials/FastQChistory.tar.gz\n\n\n\n\nGalaxy history: Spades\n\n\n\n\nhttps://swift.rc.nectar.org.au:8888/v1/AUTH_377/public/Microbial_tutorials/Spadeshistory.tar.gz\n\n\n\n\nGalaxy history: Prokka\n\n\n\n\nhttps://swift.rc.nectar.org.au:8888/v1/AUTH_377/public/Microbial_tutorials/Prokkahistory.tar.gz\n\n\n\n\nGalaxy history: Snippy\n\n\n\n\nhttps://swift.rc.nectar.org.au:8888/v1/AUTH_377/public/Microbial_tutorials/Snippyhistory.tar.gz\n\n\nTo get the saved tutorial history (a set of files) into Galaxy:\n\n\n\n\nCopy the link address.\n\n\nGo to your Galaxy instance. Make sure you are registered and logged in. Refresh the page.\n\n\nClick on the \nHistory\n cog \n\n\nSelect \nImport from File\n\n\n\n\n\n\n\n\nIn the box called \nArchived History URL\n, paste in the link address to the Galaxy history.\n\n\nClick \nSubmit\n\n\nWait a few seconds.\n\n\nClick on the \nview all histories\n button \n\n\nSee if the Galaxy history has been imported: it will be called \nimported from archive: Data\n\n\nAbove that pane, click on the \nSwitch to\n button.\n\n\nThen click \nDone\n (in the top left corner).\n\n\nYou should now have a list of five files in your current history.\n\n\n\n\n\n\nIndividual input files\n\n\nWildtype reference\n\n\n\n\nwildtype.fna\n\n\n\n\n https://swift.rc.nectar.org.au:8888/v1/AUTH_377/public/Microbial_tutorials/wildtype.fna\n\n\n\n\nwildtype.gbk\n\n\n\n\n https://swift.rc.nectar.org.au:8888/v1/AUTH_377/public/Microbial_tutorials/wildtype.gbk\n\n\n\n\nwildtype.gff\n\n\n\n\n https://swift.rc.nectar.org.au:8888/v1/AUTH_377/public/Microbial_tutorials/wildtype.gff\n\n\nMutant Illumina sequence\n\n\n\n\nmutant_R1.fastq.gz\n\n\n\n\n https://swift.rc.nectar.org.au:8888/v1/AUTH_377/public/Microbial_tutorials/mutant_R1.fastq.gz\n\n\n\n\nmutant_R2.fastq.gz\n\n\n\n\nhttps://swift.rc.nectar.org.au:8888/v1/AUTH_377/public/Microbial_tutorials/mutant_R2.fastq.gz\n\n\nAssembled contigs\n\n\n\n\nSPAdes_contigs.fasta\n\n\n\n\nhttps://swift.rc.nectar.org.au:8888/v1/AUTH_377/public/Microbial_tutorials/SPAdes_contigs.fasta\n\n\nUpload to Galaxy\n\n\nThere are two ways to upload these files to Galaxy. You can either download to your local computer and upload to Galaxy, or you can tell Galaxy to directly upload the file from an external source.\n\n\nDownload and upload:\n\n\n\n\nDownload required file(s) to your computer.\n\n\nFrom the Galaxy tool panel, click on \nGet Data \n Upload File\n  \n\n\nClick the \nChoose local file\n button  \n\n\nFind and select the \nfile\n you downloaded and click \nOpen\n  \n\n\nSet the \nType\n correctly.  \n\n\nClick the \nStart\n button.  \n\n\nOnce the progress bar reaches 100%, click the \nClose\n button  \n\n\nThe file will now upload to your current history.\n\n\n\n\nOr, tell Galaxy to find the file from an external source:\n\n\n\n\nFrom the Galaxy tool panel, click on \nGet Data \n Upload File\n  \n\n\nClick the \nPaste/Fetch data\n button  \n\n\nPaste the URL into the box.\n\n\nClick the \nStart\n button.  \n\n\nOnce the progress bar reaches 100%, click the \nClose\n button  \n\n\nThe file will now upload to your current history.", 
            "title": "Training dataset"
        }, 
        {
            "location": "/modules/data-dna/#dataset", 
            "text": "This page contains data for the tutorials. The tutorials will specify whether to import a whole history (URLs listed in the first section) or an individual file (URLs listed in the second section).", 
            "title": "Dataset"
        }, 
        {
            "location": "/modules/data-dna/#galaxy-histories-urls", 
            "text": "Galaxy history of input files   https://swift.rc.nectar.org.au:8888/v1/AUTH_377/public/Microbial_tutorials/Galaxy_history_input_files.tar.gz   Galaxy history: FastQC   https://swift.rc.nectar.org.au:8888/v1/AUTH_377/public/Microbial_tutorials/FastQChistory.tar.gz   Galaxy history: Spades   https://swift.rc.nectar.org.au:8888/v1/AUTH_377/public/Microbial_tutorials/Spadeshistory.tar.gz   Galaxy history: Prokka   https://swift.rc.nectar.org.au:8888/v1/AUTH_377/public/Microbial_tutorials/Prokkahistory.tar.gz   Galaxy history: Snippy   https://swift.rc.nectar.org.au:8888/v1/AUTH_377/public/Microbial_tutorials/Snippyhistory.tar.gz  To get the saved tutorial history (a set of files) into Galaxy:   Copy the link address.  Go to your Galaxy instance. Make sure you are registered and logged in. Refresh the page.  Click on the  History  cog   Select  Import from File     In the box called  Archived History URL , paste in the link address to the Galaxy history.  Click  Submit  Wait a few seconds.  Click on the  view all histories  button   See if the Galaxy history has been imported: it will be called  imported from archive: Data  Above that pane, click on the  Switch to  button.  Then click  Done  (in the top left corner).  You should now have a list of five files in your current history.", 
            "title": "Galaxy histories: URLs"
        }, 
        {
            "location": "/modules/data-dna/#individual-input-files", 
            "text": "", 
            "title": "Individual input files"
        }, 
        {
            "location": "/modules/data-dna/#wildtype-reference", 
            "text": "wildtype.fna    https://swift.rc.nectar.org.au:8888/v1/AUTH_377/public/Microbial_tutorials/wildtype.fna   wildtype.gbk    https://swift.rc.nectar.org.au:8888/v1/AUTH_377/public/Microbial_tutorials/wildtype.gbk   wildtype.gff    https://swift.rc.nectar.org.au:8888/v1/AUTH_377/public/Microbial_tutorials/wildtype.gff", 
            "title": "Wildtype reference"
        }, 
        {
            "location": "/modules/data-dna/#mutant-illumina-sequence", 
            "text": "mutant_R1.fastq.gz    https://swift.rc.nectar.org.au:8888/v1/AUTH_377/public/Microbial_tutorials/mutant_R1.fastq.gz   mutant_R2.fastq.gz   https://swift.rc.nectar.org.au:8888/v1/AUTH_377/public/Microbial_tutorials/mutant_R2.fastq.gz", 
            "title": "Mutant Illumina sequence"
        }, 
        {
            "location": "/modules/data-dna/#assembled-contigs", 
            "text": "SPAdes_contigs.fasta   https://swift.rc.nectar.org.au:8888/v1/AUTH_377/public/Microbial_tutorials/SPAdes_contigs.fasta", 
            "title": "Assembled contigs"
        }, 
        {
            "location": "/modules/data-dna/#upload-to-galaxy", 
            "text": "There are two ways to upload these files to Galaxy. You can either download to your local computer and upload to Galaxy, or you can tell Galaxy to directly upload the file from an external source.  Download and upload:   Download required file(s) to your computer.  From the Galaxy tool panel, click on  Get Data   Upload File     Click the  Choose local file  button    Find and select the  file  you downloaded and click  Open     Set the  Type  correctly.    Click the  Start  button.    Once the progress bar reaches 100%, click the  Close  button    The file will now upload to your current history.   Or, tell Galaxy to find the file from an external source:   From the Galaxy tool panel, click on  Get Data   Upload File     Click the  Paste/Fetch data  button    Paste the URL into the box.  Click the  Start  button.    Once the progress bar reaches 100%, click the  Close  button    The file will now upload to your current history.", 
            "title": "Upload to Galaxy"
        }, 
        {
            "location": "/modules/velvet/", 
            "text": "Assembly using Velvet\n\n\nKeywords: de novo assembly, Velvet, Galaxy, Microbial Genomics Virtual Lab\n\n\nBackground\n\n\nVelvet is one of a number of \nde novo\n assemblers that use short read sets as input (e.g. Illumina Reads), and the assembly method is based on de Bruijn graphs. For information about Velvet see this \nlink\n.\n\n\n\n\n\nIn this activity, we will perform a \nde novo\n assembly of a short read set using the Velvet assembler.\n\n\nLearning objectives\n\n\nAt the end of this tutorial you should be able to:\n\n\n\n\nassemble the reads using Velvet, and\n\n\nexamine the output assembly.\n\n\n\n\nImport and view data\n\n\n\n\n\nSee \nhere\n for information about how to start with Galaxy.\n\n\nImport files\n\n\nTo import the files for this tutorial:\n\n\n\n\nGo to your Galaxy instance. Make sure you are registered and logged in. Refresh the page.\n\n\nIn the centre of the top panel, select \nShared Data: Histories\n\n\nSelect \nMicrobial-assembly-start-history\n and then in the top right corner click on \nImport history\n.\n\n\nThis should now be your current history (the right hand panel) with five files.\n\n\n\n\nAlternatively:\n\n\n\n\nClick on the \nHistory\n cog \n\n\nSelect \nImport from File\n\n\nIn the box called \nArchived History URL\n, paste in this link address to the Galaxy history of input files:\n\n\n\n\nhttps://swift.rc.nectar.org.au:8888/v1/AUTH_377/public/Microbial_tutorials/Galaxy_history_input_files.tar.gz\n\n\n\n\nClick \nSubmit\n\n\nWait a few seconds.\n\n\nClick on the \nview all histories\n button \n\n\nSee if the Galaxy history has been imported: it will be called \nimported from archive: Data\n\n\nAbove that pane, click on the \nSwitch to\n button.\n\n\nThen click \nDone\n (in the top left corner).\n\n\nYou should now have a list of five files in your current history.\n\n\n\n\nThe data\n\n\nThe read set for today is from an imaginary \nStaphylococcus aureus\n bacterium with a miniature genome. The whole genome shotgun method used to sequence our mutant strain read set was produced on an Illumina DNA sequencing instrument.\n\n\n\n\nThe files we need for assembly are the \nmutant_R1.fastq\n and \nmutant_R2.fastq\n.\n\n\n\n\n(We don\nt need the reference genome sequences for this tutorial).\n\n\n\n\n\n\nThe reads are paired-end.\n\n\n\n\n\n\nEach read is 150 bases long. \n\n\n\n\n\n\nThe number of bases sequenced is equivalent to 19x the genome sequence of the wildtype strain. (Read coverage 19x - rather low!).\n\n\n\n\n\n\n\n\n\n\n\nClick on the View Data button (the \n) next to one of the FASTQ sequence files.\n\n\n\n\n\n\n\nAssemble reads with Velvet\n\n\n\n\nWe will perform a \nde novo\n assembly of the mutant FASTQ reads into long contiguous sequences (in FASTA format.)\n\n\nVelvet requires the user to input a value of \nk\n for the assembly process. K-mers are fragments of sequence reads. Small k-mers will give greater connectivity, but large k-mers will give better specificity.\n\n\n\n\n\n\n\n\n\nGo to \nTools \n NGS Analysis \n NGS: Assembly \n velvet\n\n\n\n\nSet the following parameters (leave other settings as they are):\n\n\n\n\nK-mer\n: Enter the value for \nk\n that you have been assigned in the spreadsheet.\n\n\n\n\n\n\n\n\n\nInput file type\n: Fastq\n\n\nSingle or paired end reads\n: Paired\n\n\n Select first set of reads\n: \nmutant_R1.fastq\n  \n\n\n Select second set of reads\n: \nmutant_R2.fastq\n\n\n\n\n\n\n\n\nYour tool interface should look like this (you will most likely have a different value for k):\n\n\n\n\n\n\n\n\n\n\nClick \nExecute\n\n\n\n\nExamine the output\n\n\n\n\nGalaxy is now running velvet on the reads for you.\n\n\nPress the refresh button in the history pane to see if it has finished.\n\n\n\n\nWhen it is finished, you will have four new files in your history.  \n\n\n\n\na \nContigs\n file\n\n\na \nContigs stats\n file\n\n\nthe velvet \nlog\n file\n\n\nan assembly \nLast Graph\n file\n\n\n\n\n\n\n\n\nClick on the View Data button \n on each of the files.\n\n\n\n\n\n\nThe \nContigs\n file will show each contig with the \nk-mer length\n and \nk-mer coverage\n listed as part of the header (however, these are just called \nlength\n and \ncoverage\n).\n\n\n\n\nK-mer length\n: For the value of k chosen in the assembly, a measure of how many k-mers overlap (by 1 bp each overlap) to give this length.\n\n\nK-mer coverage\n: For the value of k chosen in the assembly, a measure of how many k-mers overlap each base position (in the assembly).\n\n\n\n\n\n\n\n\n\n\n\n\nThe \nContigs stats\n file will show a list of these k-mer lengths and k-mer coverages.\n\n\n\n\n\n\n\n\nWe will summarise the information in the \nlog\n file.\n\n\nGo to \nNGS Common Toolsets \n FASTA manipulation \n Fasta statistics\n\n\nFor the required input file, choose the velvet \nContigs\n file.\n\n\nClick \nExecute\n.\n\n\nA new file will appear called \nFasta summary stats\n\n\nClick the eye icon to look at this file.\n\n\n\n\n\n\n\n\nLook at:\n\n\nnum_seq\n: the number of contigs in the FASTA file.\n\n\nnum_bp\n: the number of assembled bases. Roughly proportional to genome size.\n\n\nlen_max\n: the biggest contig.  \n\n\nlen_N50\n: N50 is a contig size. If contigs were ordered from small to large, half of all the nucleotides will be in contigs this size or larger.\n\n\n\n\n\n\n\n\nNow copy the relevant data back into the k-mer spreadsheet on your line.\n\n\nAlong with the demonstrator, have a look at the effect of the k-mer size on the output metrics of the assembly. Note that there are local maxima and minima in the charts.\n\n\n\n\n\nAssembly with Velvet Optimiser\n\n\nNow that we have seen the effect of k-mer size on the assembly, we will run the Velvet Optimiser to automatically choose the best k-mer size for us. It will use the \nn50\n to determine the best k-mer value to use. It then performs the further graph cleaning steps and automatically chooses other parameters for velvet. We should get a much better assembly result than we did with our attempts with Velvet alone.\n\n\n\n\nGo to \nTools \n NGS Analysis \n NGS: Assembly \n Velvet Optimiser\n\n\n\n\nSet the following parameters (leave other settings as they are):\n\n\n\n\nStart k-mer size\n: 45\n\n\nEnd k-mer size\n: 73\n\n\nInput file type\n: Fastq\n\n\nSingle or paired end reads\n: Paired\n\n\n Select first set of reads\n: \nmutant_R1.fastq\n  \n\n\n\n\n Select second set of reads\n: \nmutant_R2.fastq\n\n\n\n\n\n\nClick \nExecute\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLook at the fasta statistics for the Velvet Optimiser contigs\n\n\nUse the Fasta Statistics tool you used earlier to summarise the Velvet Optimiser output. Examine the resulting table. What are the main differences?", 
            "title": "Genome assembly with Velvet"
        }, 
        {
            "location": "/modules/velvet/#assembly-using-velvet", 
            "text": "Keywords: de novo assembly, Velvet, Galaxy, Microbial Genomics Virtual Lab", 
            "title": "Assembly using Velvet"
        }, 
        {
            "location": "/modules/velvet/#background", 
            "text": "Velvet is one of a number of  de novo  assemblers that use short read sets as input (e.g. Illumina Reads), and the assembly method is based on de Bruijn graphs. For information about Velvet see this  link .   In this activity, we will perform a  de novo  assembly of a short read set using the Velvet assembler.", 
            "title": "Background"
        }, 
        {
            "location": "/modules/velvet/#learning-objectives", 
            "text": "At the end of this tutorial you should be able to:   assemble the reads using Velvet, and  examine the output assembly.", 
            "title": "Learning objectives"
        }, 
        {
            "location": "/modules/velvet/#import-and-view-data", 
            "text": "See  here  for information about how to start with Galaxy.", 
            "title": "Import and view data"
        }, 
        {
            "location": "/modules/velvet/#import-files", 
            "text": "To import the files for this tutorial:   Go to your Galaxy instance. Make sure you are registered and logged in. Refresh the page.  In the centre of the top panel, select  Shared Data: Histories  Select  Microbial-assembly-start-history  and then in the top right corner click on  Import history .  This should now be your current history (the right hand panel) with five files.   Alternatively:   Click on the  History  cog   Select  Import from File  In the box called  Archived History URL , paste in this link address to the Galaxy history of input files:   https://swift.rc.nectar.org.au:8888/v1/AUTH_377/public/Microbial_tutorials/Galaxy_history_input_files.tar.gz   Click  Submit  Wait a few seconds.  Click on the  view all histories  button   See if the Galaxy history has been imported: it will be called  imported from archive: Data  Above that pane, click on the  Switch to  button.  Then click  Done  (in the top left corner).  You should now have a list of five files in your current history.", 
            "title": "Import files"
        }, 
        {
            "location": "/modules/velvet/#the-data", 
            "text": "The read set for today is from an imaginary  Staphylococcus aureus  bacterium with a miniature genome. The whole genome shotgun method used to sequence our mutant strain read set was produced on an Illumina DNA sequencing instrument.   The files we need for assembly are the  mutant_R1.fastq  and  mutant_R2.fastq .   (We don t need the reference genome sequences for this tutorial).    The reads are paired-end.    Each read is 150 bases long.     The number of bases sequenced is equivalent to 19x the genome sequence of the wildtype strain. (Read coverage 19x - rather low!).      Click on the View Data button (the  ) next to one of the FASTQ sequence files.", 
            "title": "The data"
        }, 
        {
            "location": "/modules/velvet/#assemble-reads-with-velvet", 
            "text": "We will perform a  de novo  assembly of the mutant FASTQ reads into long contiguous sequences (in FASTA format.)  Velvet requires the user to input a value of  k  for the assembly process. K-mers are fragments of sequence reads. Small k-mers will give greater connectivity, but large k-mers will give better specificity.     Go to  Tools   NGS Analysis   NGS: Assembly   velvet   Set the following parameters (leave other settings as they are):   K-mer : Enter the value for  k  that you have been assigned in the spreadsheet.     Input file type : Fastq  Single or paired end reads : Paired   Select first set of reads :  mutant_R1.fastq      Select second set of reads :  mutant_R2.fastq     Your tool interface should look like this (you will most likely have a different value for k):      Click  Execute", 
            "title": "Assemble reads with Velvet"
        }, 
        {
            "location": "/modules/velvet/#examine-the-output", 
            "text": "Galaxy is now running velvet on the reads for you.  Press the refresh button in the history pane to see if it has finished.   When it is finished, you will have four new files in your history.     a  Contigs  file  a  Contigs stats  file  the velvet  log  file  an assembly  Last Graph  file     Click on the View Data button   on each of the files.    The  Contigs  file will show each contig with the  k-mer length  and  k-mer coverage  listed as part of the header (however, these are just called  length  and  coverage ).   K-mer length : For the value of k chosen in the assembly, a measure of how many k-mers overlap (by 1 bp each overlap) to give this length.  K-mer coverage : For the value of k chosen in the assembly, a measure of how many k-mers overlap each base position (in the assembly).       The  Contigs stats  file will show a list of these k-mer lengths and k-mer coverages.     We will summarise the information in the  log  file.  Go to  NGS Common Toolsets   FASTA manipulation   Fasta statistics  For the required input file, choose the velvet  Contigs  file.  Click  Execute .  A new file will appear called  Fasta summary stats  Click the eye icon to look at this file.     Look at:  num_seq : the number of contigs in the FASTA file.  num_bp : the number of assembled bases. Roughly proportional to genome size.  len_max : the biggest contig.    len_N50 : N50 is a contig size. If contigs were ordered from small to large, half of all the nucleotides will be in contigs this size or larger.", 
            "title": "Examine the output"
        }, 
        {
            "location": "/modules/velvet/#now-copy-the-relevant-data-back-into-the-k-mer-spreadsheet-on-your-line", 
            "text": "Along with the demonstrator, have a look at the effect of the k-mer size on the output metrics of the assembly. Note that there are local maxima and minima in the charts.", 
            "title": "Now copy the relevant data back into the k-mer spreadsheet on your line."
        }, 
        {
            "location": "/modules/velvet/#assembly-with-velvet-optimiser", 
            "text": "Now that we have seen the effect of k-mer size on the assembly, we will run the Velvet Optimiser to automatically choose the best k-mer size for us. It will use the  n50  to determine the best k-mer value to use. It then performs the further graph cleaning steps and automatically chooses other parameters for velvet. We should get a much better assembly result than we did with our attempts with Velvet alone.   Go to  Tools   NGS Analysis   NGS: Assembly   Velvet Optimiser   Set the following parameters (leave other settings as they are):   Start k-mer size : 45  End k-mer size : 73  Input file type : Fastq  Single or paired end reads : Paired   Select first set of reads :  mutant_R1.fastq       Select second set of reads :  mutant_R2.fastq    Click  Execute", 
            "title": "Assembly with Velvet Optimiser"
        }, 
        {
            "location": "/modules/velvet/#look-at-the-fasta-statistics-for-the-velvet-optimiser-contigs", 
            "text": "Use the Fasta Statistics tool you used earlier to summarise the Velvet Optimiser output. Examine the resulting table. What are the main differences?", 
            "title": "Look at the fasta statistics for the Velvet Optimiser contigs"
        }, 
        {
            "location": "/modules/spades/", 
            "text": "Assembly using Spades\n\n\nKeywords: de novo assembly, Spades, Galaxy, Microbial Genomics Virtual Lab\n\n\nBackground\n\n\nSpades is one of a number of \nde novo\n assemblers that use short read sets as input (e.g. Illumina Reads), and the assembly method is based on de Bruijn graphs. For information about Spades see this \nlink\n.\n\n\n\n\n\nIn this activity, we will perform a \nde novo\n assembly of a short read set using the Spades assembler. The output from Spades that we are interested in is a multiFASTA file that contains the draft genome sequence.\n\n\n\n\n\nLearning objectives\n\n\nAt the end of this tutorial you should be able to:\n\n\n\n\n\n\n\nassemble the reads using Spades, and\n\n\nexamine the output assembly.\n\n\n\n\n\n\n\nImport and view data\n\n\n\n\n\nSee \nhere\n for information about how to start with Galaxy, and \nhere\n for the link to import the \nGalaxy history of input files\n for this tutorial, if you don\nt already have them in your history.\n\n\n\n\nThe read set for today is from an imaginary \nStaphylococcus aureus\n bacterium with a miniature genome.\n\n\n\n\nThe whole genome shotgun method used to sequence our mutant strain read set was produced on an Illumina DNA sequencing instrument.\n\n\n\n\n\n\nThe files we need for assembly are the \nmutant_R1.fastq\n and \nmutant_R2.fastq\n.\n\n\n\n\n\n\n(We don\nt need the reference genome sequences for this tutorial).\n\n\n\n\n\n\nThe reads are paired-end.\n\n\n\n\n\n\nEach read is 150 bases long. \n\n\n\n\n\n\nThe number of bases sequenced is equivalent to 19x the genome sequence of the wildtype strain. (Read coverage 19x - rather low!).\n\n\n\n\n\n\n\n\n\n\n\nClick on the View Data button (the \n) next to one of the FASTQ sequence files.\n\n\n\n\n\n\n\nAssemble reads with Spades\n\n\n\n\nWe will perform a \nde novo\n assembly of the mutant FASTQ reads into long contiguous sequences (in FASTA format.)\n\n\n\n\n\n\n\n\n\nGo to \nTools \n NGS Analysis \n NGS: Assembly \n spades\n\n\n\n\nSet the following parameters (leave other settings as they are):\n\n\n\n\nRun only Assembly\n: \nYes\n [the \nYes\n button should be darker grey]\n\n\nKmers to use separated by commas:\n \n33,55,91\n  [note: no spaces]  \n\n\nCoverage cutoff:\n \nauto\n  \n\n\nFiles \n Forward reads:\n \nmutant_R1.fastq\n  \n\n\nFiles \n Reverse reads:\n \nmutant_R2.fastq\n  \n\n\n\n\n\n\n\n\nYour tool interface should look like this:\n\n\n\n\n\n\n\n\n\n\nClick \nExecute\n\n\n\n\nExamine the output\n\n\n\n\nGalaxy is now running Spades on the reads for you.\n\n\n\n\nWhen it is finished, you will have five new files in your history.  \n\n\n\n\ntwo FASTA files of the resulting contigs and scaffolds\n\n\ntwo files for statistics about these\n\n\nthe Spades logfile\n\n\n\n\n\n\n\n\n\n\n\n\nClick on the View Data button \n on each of the files.\n\n\nNote that the short reads have been assembled into much longer contigs.\n\n\n(However, in this case, the contigs have not been assembled into larger scaffolds.)\n\n\nThe stats files will give you the length of each of the contigs.", 
            "title": "Genome assembly with Spades"
        }, 
        {
            "location": "/modules/spades/#assembly-using-spades", 
            "text": "Keywords: de novo assembly, Spades, Galaxy, Microbial Genomics Virtual Lab", 
            "title": "Assembly using Spades"
        }, 
        {
            "location": "/modules/spades/#background", 
            "text": "Spades is one of a number of  de novo  assemblers that use short read sets as input (e.g. Illumina Reads), and the assembly method is based on de Bruijn graphs. For information about Spades see this  link .   In this activity, we will perform a  de novo  assembly of a short read set using the Spades assembler. The output from Spades that we are interested in is a multiFASTA file that contains the draft genome sequence.", 
            "title": "Background"
        }, 
        {
            "location": "/modules/spades/#learning-objectives", 
            "text": "At the end of this tutorial you should be able to:    assemble the reads using Spades, and  examine the output assembly.", 
            "title": "Learning objectives"
        }, 
        {
            "location": "/modules/spades/#import-and-view-data", 
            "text": "See  here  for information about how to start with Galaxy, and  here  for the link to import the  Galaxy history of input files  for this tutorial, if you don t already have them in your history.   The read set for today is from an imaginary  Staphylococcus aureus  bacterium with a miniature genome.   The whole genome shotgun method used to sequence our mutant strain read set was produced on an Illumina DNA sequencing instrument.    The files we need for assembly are the  mutant_R1.fastq  and  mutant_R2.fastq .    (We don t need the reference genome sequences for this tutorial).    The reads are paired-end.    Each read is 150 bases long.     The number of bases sequenced is equivalent to 19x the genome sequence of the wildtype strain. (Read coverage 19x - rather low!).      Click on the View Data button (the  ) next to one of the FASTQ sequence files.", 
            "title": "Import and view data"
        }, 
        {
            "location": "/modules/spades/#assemble-reads-with-spades", 
            "text": "We will perform a  de novo  assembly of the mutant FASTQ reads into long contiguous sequences (in FASTA format.)     Go to  Tools   NGS Analysis   NGS: Assembly   spades   Set the following parameters (leave other settings as they are):   Run only Assembly :  Yes  [the  Yes  button should be darker grey]  Kmers to use separated by commas:   33,55,91   [note: no spaces]    Coverage cutoff:   auto     Files   Forward reads:   mutant_R1.fastq     Files   Reverse reads:   mutant_R2.fastq        Your tool interface should look like this:      Click  Execute", 
            "title": "Assemble reads with Spades"
        }, 
        {
            "location": "/modules/spades/#examine-the-output", 
            "text": "Galaxy is now running Spades on the reads for you.   When it is finished, you will have five new files in your history.     two FASTA files of the resulting contigs and scaffolds  two files for statistics about these  the Spades logfile       Click on the View Data button   on each of the files.  Note that the short reads have been assembled into much longer contigs.  (However, in this case, the contigs have not been assembled into larger scaffolds.)  The stats files will give you the length of each of the contigs.", 
            "title": "Examine the output"
        }, 
        {
            "location": "/modules/prokka/", 
            "text": "Genome annotation using Prokka\n\n\nKeywords: annotation, Prokka, JBrowse, Galaxy, Microbial Genomics Virtual Lab\n\n\nBackground\n\n\nIn this section we will use a software tool called Prokka to annotate the draft genome sequence produced in the previous \ntutorial\n. Prokka is a \u201cwrapper\u201d; it collects together several pieces of software (from various authors), and so avoids \u201cre-inventing the wheel\u201d.\n\n\nProkka finds and annotates features (both protein coding regions and RNA genes, i.e. tRNA, rRNA) present on on a sequence. Note, Prokka uses a two-step process for the annotation of protein coding regions: first, protein coding regions on the genome are identified using \nProdigal\n; second, the \nfunction\n of the encoded protein is predicted by similarity to proteins in one of many protein or protein domain databases. Prokka is a software tool that can be used to annotate bacterial, archaeal and viral genomes quickly, generating standard output files in GenBank, EMBL and gff formats. More information about Prokka can be found \nhere\n.\n\n\nLearning objectives\n\n\nAt the end of this tutorial you should be able to:\n\n\n\n\nload a genome assembly into Prokka\n\n\nannotate the assembly using Prokka\n\n\nexamine the annotated genome using JBrowse\n\n\n\n\nInput data\n\n\nProkka requires assembled contigs.\n\n\n\n\n\n\nIf you are continuing on from the previous workshop (\nAssembly with Spades\n), this file will be in your current history: \nSPAdes_contigs.fasta\n.\n\n\n\n\n\n\nAlternatively, get the file called \nassembled contigs\n from the \nTraining dataset page.\n\n\n\n\n\n\n\n\n\nRun Prokka\n\n\n\n\nIn Galaxy, go to \nTools \n NGS Analysis \n NGS: Annotation \n Prokka\n  \n\n\nSet the following parameters (leave everything else unchanged):\n\n\nContigs to annotate\n: \nSPAdes contigs (fasta)\n  \n\n\nLocus tag prefix (\nlocustag)\n: P\n\n\nForce GenBank/ENA/DDJB compliance (\ncompliant)\n: \nNo\n\n\nSequencing Centre ID (\ncentre)\n: V\n\n\nGenus Name\n: \nStaphylococcus\n  \n\n\nSpecies Name\n: \naureus\n  \n\n\nUse genus-specific BLAST database\n \nNo\n  \n\n\n\n\n\n\n\n\nYour tool interface should look like this:\n\n\n\n\n\n\nClick \nExecute\n  \n\n\n\n\nExamine the output\n\n\nFirst, enable \nScratchbook\n in Galaxy - this allows you to view several windows simultaneously. Click on the 3\n3 squares icon on the menu bar:\n\n\n\n\nOnce Prokka has finished, examine each of its output files.\n\n\n\n\nThe \nGFF\n and \nGBK\n files contain all of the information about the features annotated (in different formats.)\n\n\nThe \n.txt\n file contains a summary of the number of features annotated.\n\n\nThe \n.faa\n file contains the protein sequences of the genes annotated.\n\n\nThe \n.ffn\n file contains the nucleotide sequences of the genes annotated.\n\n\n\n\nView annotated features in JBrowse\n\n\nNow that we have annotated the draft genome sequence, we would like to view the sequence in the JBrowse genome viewer.\n\n\n\n\n\n\nGo to \nStatistics and Visualisation \n Graph/Display Data \n JBrowse\n (choose the top listed one; version 0.5.2).\n\n\n\n\n\n\nUnder \nJBrowse-in-Galaxy Action\n choose \nNew JBrowse Instance\n.\n\n\n\n\n\n\nUnder \nReference genome to display\n choose \nUse a genome from history\n.\n\n\n\n\n\n\nUnder \nFasta sequences\n choose \nProkka on data XX:fna\n. This .fna sequence is the fasta nucleotide sequence, and will be the reference against which annotations are displayed.\n\n\n\n\n\n\nFor \nProduce a Standalone Instance\n select \nYes\n.\n\n\n\n\n\n\nFor \nGenetic Code\n choose \n11: The Bacterial, Archaeal and Plant Plastid Code\n.\n\n\n\n\n\n\nClick \nInsert Track Group\n\n\n\n\n\n\nUnder \nTrack Category\n type in \ngene annotations\n.\n\n\n\n\n\n\nClick \nInsert Annotation Track\n\n\n\n\n\n\nFor \nTrack Type\n choose \nGFF/GFF3/BED/GBK Features\n\n\n\n\n\n\nFor \nGFF/GFF3/BED Track Data\n select \nProkka on data XX:gff\n  [Note: not wildtype.gff]\n\n\n\n\n\n\nUnder \nJBrowse Track Type[Advanced]\n select \nCanvas Features\n.\n\n\n\n\n\n\nClick on \nJBrowse Styling Options \n\n\n\n\n\n\nUnder \nJBrowse style.label\n correct the word \nprodcut\n to \nproduct\n.\n\n\n\n\n\n\nUnder \nTrack Visibility\n choose \nOn for new users\n.\n\n\n\n\n\n\nYour tool interface should look like this:\n\n\n\n\n\n\n\n\n\n\n\nClick \nExecute\n\n\n\n\n\n\nA new file will be created, called \nJBrowse on data XX and data XX - Complete\n. Click on the eye icon next to the file name. The JBrowse window will appear in the centre Galaxy panel.\n\n\n\n\n\n\nUnder \nAvailable Tracks\n on the left, tick the box for \nProkka on data XX:gff\n.\n\n\n\n\n\n\nSelect contig 6 in the drop down box. You can only see one contig displayed at a time.\n\n\n\n\n\n\n\n\n\n\n\n\nUse the plus and minus buttons to zoom in and out, and the arrows to move left or right (or click and drag within the window to move left or right).\n\n\n\n\n\n\nZoom in to see the reference sequence at the top. JBrowse displays the sequence and a 6-frame amino acid translation.\n\n\n\n\n\n\nZoomed in view:\n\n\n\n\n\n\nRight click on a gene/feature annotation (the bars on the annotation track), then select \nView Details\n to see more information.\n\n\ngene name\n\n\nproduct name\n\n\nyou can download the FASTA sequence by clicking on the disk icon.", 
            "title": "Genome annotation"
        }, 
        {
            "location": "/modules/prokka/#genome-annotation-using-prokka", 
            "text": "Keywords: annotation, Prokka, JBrowse, Galaxy, Microbial Genomics Virtual Lab", 
            "title": "Genome annotation using Prokka"
        }, 
        {
            "location": "/modules/prokka/#background", 
            "text": "In this section we will use a software tool called Prokka to annotate the draft genome sequence produced in the previous  tutorial . Prokka is a \u201cwrapper\u201d; it collects together several pieces of software (from various authors), and so avoids \u201cre-inventing the wheel\u201d.  Prokka finds and annotates features (both protein coding regions and RNA genes, i.e. tRNA, rRNA) present on on a sequence. Note, Prokka uses a two-step process for the annotation of protein coding regions: first, protein coding regions on the genome are identified using  Prodigal ; second, the  function  of the encoded protein is predicted by similarity to proteins in one of many protein or protein domain databases. Prokka is a software tool that can be used to annotate bacterial, archaeal and viral genomes quickly, generating standard output files in GenBank, EMBL and gff formats. More information about Prokka can be found  here .", 
            "title": "Background"
        }, 
        {
            "location": "/modules/prokka/#learning-objectives", 
            "text": "At the end of this tutorial you should be able to:   load a genome assembly into Prokka  annotate the assembly using Prokka  examine the annotated genome using JBrowse", 
            "title": "Learning objectives"
        }, 
        {
            "location": "/modules/prokka/#input-data", 
            "text": "Prokka requires assembled contigs.    If you are continuing on from the previous workshop ( Assembly with Spades ), this file will be in your current history:  SPAdes_contigs.fasta .    Alternatively, get the file called  assembled contigs  from the  Training dataset page.", 
            "title": "Input data"
        }, 
        {
            "location": "/modules/prokka/#run-prokka", 
            "text": "In Galaxy, go to  Tools   NGS Analysis   NGS: Annotation   Prokka     Set the following parameters (leave everything else unchanged):  Contigs to annotate :  SPAdes contigs (fasta)     Locus tag prefix ( locustag) : P  Force GenBank/ENA/DDJB compliance ( compliant) :  No  Sequencing Centre ID ( centre) : V  Genus Name :  Staphylococcus     Species Name :  aureus     Use genus-specific BLAST database   No        Your tool interface should look like this:    Click  Execute", 
            "title": "Run Prokka"
        }, 
        {
            "location": "/modules/prokka/#examine-the-output", 
            "text": "First, enable  Scratchbook  in Galaxy - this allows you to view several windows simultaneously. Click on the 3 3 squares icon on the menu bar:   Once Prokka has finished, examine each of its output files.   The  GFF  and  GBK  files contain all of the information about the features annotated (in different formats.)  The  .txt  file contains a summary of the number of features annotated.  The  .faa  file contains the protein sequences of the genes annotated.  The  .ffn  file contains the nucleotide sequences of the genes annotated.", 
            "title": "Examine the output"
        }, 
        {
            "location": "/modules/prokka/#view-annotated-features-in-jbrowse", 
            "text": "Now that we have annotated the draft genome sequence, we would like to view the sequence in the JBrowse genome viewer.    Go to  Statistics and Visualisation   Graph/Display Data   JBrowse  (choose the top listed one; version 0.5.2).    Under  JBrowse-in-Galaxy Action  choose  New JBrowse Instance .    Under  Reference genome to display  choose  Use a genome from history .    Under  Fasta sequences  choose  Prokka on data XX:fna . This .fna sequence is the fasta nucleotide sequence, and will be the reference against which annotations are displayed.    For  Produce a Standalone Instance  select  Yes .    For  Genetic Code  choose  11: The Bacterial, Archaeal and Plant Plastid Code .    Click  Insert Track Group    Under  Track Category  type in  gene annotations .    Click  Insert Annotation Track    For  Track Type  choose  GFF/GFF3/BED/GBK Features    For  GFF/GFF3/BED Track Data  select  Prokka on data XX:gff   [Note: not wildtype.gff]    Under  JBrowse Track Type[Advanced]  select  Canvas Features .    Click on  JBrowse Styling Options     Under  JBrowse style.label  correct the word  prodcut  to  product .    Under  Track Visibility  choose  On for new users .    Your tool interface should look like this:      Click  Execute    A new file will be created, called  JBrowse on data XX and data XX - Complete . Click on the eye icon next to the file name. The JBrowse window will appear in the centre Galaxy panel.    Under  Available Tracks  on the left, tick the box for  Prokka on data XX:gff .    Select contig 6 in the drop down box. You can only see one contig displayed at a time.       Use the plus and minus buttons to zoom in and out, and the arrows to move left or right (or click and drag within the window to move left or right).    Zoom in to see the reference sequence at the top. JBrowse displays the sequence and a 6-frame amino acid translation.    Zoomed in view:    Right click on a gene/feature annotation (the bars on the annotation track), then select  View Details  to see more information.  gene name  product name  you can download the FASTA sequence by clicking on the disk icon.", 
            "title": "View annotated features in JBrowse"
        }, 
        {
            "location": "/modules/snippy/", 
            "text": "Variant calling with Snippy\n\n\nKeywords: variant calling, SNP, Snippy, JBrowse, Galaxy, Microbial Genomics Virtual Lab\n\n\nBackground\n\n\nVariant calling is the process of identifying differences between two genome samples.\nUsually differences are limited to single nucleotide polymorphisms (SNPs) and small insertions and deletions (indels). Larger structural variation such as inversions, duplications and large deletions are not typically covered by \nvariant calling\n.\n\n\nLearning Objectives\n\n\n\n\nFind variants between a reference genome and a set of reads\n\n\nVisualise the SNP in context of the reads aligned to the genome\n\n\nDetermine the effect of those variants on genomic features\n\n\nUnderstand if the SNP is potentially affecting the phenotype\n\n\n\n\nPrepare reference\n\n\n\n\n\n\n\n\nFor variant calling, we need a reference genome that is of the same strain as the input sequence reads.\n\n\nFor this tutorial, our reference is the \nwildtype.gbk\n file and our reads are \nmutant_R1.fastq\n and \nmutant_R2.fastq\n.\n\n\nIf these files are not presently in your Galaxy history, import them from the \nTraining dataset page.\n\n\nCall variants with Snippy\n\n\n\n\nGo to \nTools \n NGS Analysis \n NGS: Variant Analysis \n snippy\n\n\nFor \nReference type\n select \nGenbank\n.\n\n\nThen for \nReference Genbank\n choose the \nwildtype.gbk\n file.\n\n\nFor \nSingle or Paired-end reads\n choose \nPaired\n.\n\n\nThen choose the first set of reads, \nmutant_R1.fastq\n and second set of reads, \nmutant_R2.fastq\n.\n\n\nFor \nCleanup the non-snp output files\n select \nNo\n.\n\n\n\n\nYour tool interface should look like this:\n\n\n\n\n\n\nClick \nExecute\n.\n\n\n\n\nExamine Snippy output\n\n\nFirst, enable \nScratchbook\n in Galaxy - this allows you to view several windows simultaneously. Click on the squares:\n\n\n\n\nFrom Snippy, there are 10 output files in various formats.\n\n\n\n\nGo to the file called \nsnippy on data XX, data XX and data XX table\n and click on the eye icon.\n\n\nWe can see a list of variants. Look in column 3 to see which types the variants are, such as a SNP or a deletion.\n\n\nLook at the third variant called. This is a T\nA mutation, causing a stop codon. Look at column 14: the product of this gene is a methicillin resistance protein. Methicillin is an antibiotic. What might be the result of such a mutation? \n\n\n\n\nView Snippy output in JBrowse\n\n\n\n\n\n\nGo to \nStatistics and Visualisation \n Graph/Display Data \n JBrowse\n (choose the top listed one; version 0.5.2).\n\n\n\n\n\n\nUnder \nJBrowse-in-Galaxy Action\n choose \nNew JBrowse Instance\n.\n\n\n\n\n\n\nUnder \nReference genome to display\n choose \nUse a genome from history\n.\n\n\n\n\n\n\nUnder \nFasta Sequence(s)\n choose \nwildtype.fna\n. This sequence will be the reference against which annotations are displayed.\n\n\n\n\n\n\nFor \nProduce a Standalone Instance\n select \nYes\n.\n\n\n\n\n\n\nFor \nGenetic Code\n choose \n11: The Bacterial, Archaeal and Plant Plastid Code\n.\n\n\n\n\n\n\nWe will now set up three different tracks - these are datasets displayed underneath the reference sequence (which is displayed as nucleotides in FASTA format). We will choose to display the sequence reads (the .bam file), the variants found by snippy (the .gff file) and the annotated reference genome (the wildtype.gff)\n\n\n\n\n\n\nTrack 1 - sequence reads\n\n\n\n\nClick \nInsert Track Group\n\n\nFor \nTrack Cateogry\n name it \nsequence reads\n\n\nClick \nInsert Annotation Track\n\n\nFor \nTrack Type\n choose \nBAM Pileups\n\n\nFor \nBAM Track Data\n select \nthe snippy bam file\n\n\nFor \nAutogenerate SNP Track\n select \nYes\n\n\nUnder \nTrack Visibility\n choose \nOn for new users\n.\n\n\n\n\nTrack 2 - variants\n\n\n\n\nClick \nInsert Track Group\n again\n\n\nFor \nTrack Category\n name it \nvariants\n\n\nClick \nInsert Annotation Track\n\n\nFor \nTrack Type\n choose \nGFF/GFF3/BED/GBK Features\n\n\nFor \nSNP Track Data\n select \nthe snippy snps gff file\n\n\nUnder \nTrack Visibility\n choose \nOn for new users\n.\n\n\n\n\nTrack 3 - annotated reference\n\n\n\n\nClick \nInsert Track Group\n again\n\n\nFor \n Track Category\n name it \nannotated reference\n\n\nClick \nInsert Annotation Track\n\n\nFor \nTrack Type\n choose \nGFF/GFF3/BED/GBK Features\n\n\nFor \nSNP Track Data\n select \nwildtype.gff\n\n\nUnder \nJBrowse Track Type[Advanced]\n select \nCanvas Features\n.\n\n\nClick on \nJBrowse Styling Options \n\n\nUnder \nJBrowse style.label\n correct the word \nprodcut\n to \nproduct\n.\n\n\nUnder \nJBrowse style.description\n type in \nproduct,note,description\n\n\n\n\nUnder \nTrack Visibility\n choose \nOn for new users\n.\n\n\n\n\n\n\nClick \nExecute\n\n\n\n\n\n\nA new file will be created, called \nJBrowse on data XX and data XX - Complete\n. Click on the eye icon next to the file name. The JBrowse window will appear in the centre Galaxy panel.\n\n\n\n\n\n\nOn the left, tick boxes to display the tracks\n\n\n\n\n\n\nUse the minus button to zoom out to see:\n\n\n\n\nsequence reads and their coverage (the grey graph)\n\n\n\n\n\n\n\n\nUse the plus button to zoom in to see:\n\n\n\n\nprobable real variants (a whole column of snps)\n\n\nprobable errors (single one here and there)\n\n\n\n\n\n\n\n\n\n\n\n\nIn the coordinates box, type in \n47299\n and then \nGo\n to see the position of the SNP discussed above.\n\n\nthe correct codon at this position is TGT, coding for the amino acid Cysteine, in the middle row of the amino acid translations.\n\n\nthe mutation of T \n A turns this triplet into TGA, a stop codon.", 
            "title": "Variant finding"
        }, 
        {
            "location": "/modules/snippy/#variant-calling-with-snippy", 
            "text": "Keywords: variant calling, SNP, Snippy, JBrowse, Galaxy, Microbial Genomics Virtual Lab", 
            "title": "Variant calling with Snippy"
        }, 
        {
            "location": "/modules/snippy/#background", 
            "text": "Variant calling is the process of identifying differences between two genome samples.\nUsually differences are limited to single nucleotide polymorphisms (SNPs) and small insertions and deletions (indels). Larger structural variation such as inversions, duplications and large deletions are not typically covered by  variant calling .", 
            "title": "Background"
        }, 
        {
            "location": "/modules/snippy/#learning-objectives", 
            "text": "Find variants between a reference genome and a set of reads  Visualise the SNP in context of the reads aligned to the genome  Determine the effect of those variants on genomic features  Understand if the SNP is potentially affecting the phenotype", 
            "title": "Learning Objectives"
        }, 
        {
            "location": "/modules/snippy/#prepare-reference", 
            "text": "For variant calling, we need a reference genome that is of the same strain as the input sequence reads.  For this tutorial, our reference is the  wildtype.gbk  file and our reads are  mutant_R1.fastq  and  mutant_R2.fastq .  If these files are not presently in your Galaxy history, import them from the  Training dataset page.", 
            "title": "Prepare reference"
        }, 
        {
            "location": "/modules/snippy/#call-variants-with-snippy", 
            "text": "Go to  Tools   NGS Analysis   NGS: Variant Analysis   snippy  For  Reference type  select  Genbank .  Then for  Reference Genbank  choose the  wildtype.gbk  file.  For  Single or Paired-end reads  choose  Paired .  Then choose the first set of reads,  mutant_R1.fastq  and second set of reads,  mutant_R2.fastq .  For  Cleanup the non-snp output files  select  No .   Your tool interface should look like this:    Click  Execute .", 
            "title": "Call variants with Snippy"
        }, 
        {
            "location": "/modules/snippy/#examine-snippy-output", 
            "text": "First, enable  Scratchbook  in Galaxy - this allows you to view several windows simultaneously. Click on the squares:   From Snippy, there are 10 output files in various formats.   Go to the file called  snippy on data XX, data XX and data XX table  and click on the eye icon.  We can see a list of variants. Look in column 3 to see which types the variants are, such as a SNP or a deletion.  Look at the third variant called. This is a T A mutation, causing a stop codon. Look at column 14: the product of this gene is a methicillin resistance protein. Methicillin is an antibiotic. What might be the result of such a mutation?", 
            "title": "Examine Snippy output"
        }, 
        {
            "location": "/modules/snippy/#view-snippy-output-in-jbrowse", 
            "text": "Go to  Statistics and Visualisation   Graph/Display Data   JBrowse  (choose the top listed one; version 0.5.2).    Under  JBrowse-in-Galaxy Action  choose  New JBrowse Instance .    Under  Reference genome to display  choose  Use a genome from history .    Under  Fasta Sequence(s)  choose  wildtype.fna . This sequence will be the reference against which annotations are displayed.    For  Produce a Standalone Instance  select  Yes .    For  Genetic Code  choose  11: The Bacterial, Archaeal and Plant Plastid Code .    We will now set up three different tracks - these are datasets displayed underneath the reference sequence (which is displayed as nucleotides in FASTA format). We will choose to display the sequence reads (the .bam file), the variants found by snippy (the .gff file) and the annotated reference genome (the wildtype.gff)    Track 1 - sequence reads   Click  Insert Track Group  For  Track Cateogry  name it  sequence reads  Click  Insert Annotation Track  For  Track Type  choose  BAM Pileups  For  BAM Track Data  select  the snippy bam file  For  Autogenerate SNP Track  select  Yes  Under  Track Visibility  choose  On for new users .   Track 2 - variants   Click  Insert Track Group  again  For  Track Category  name it  variants  Click  Insert Annotation Track  For  Track Type  choose  GFF/GFF3/BED/GBK Features  For  SNP Track Data  select  the snippy snps gff file  Under  Track Visibility  choose  On for new users .   Track 3 - annotated reference   Click  Insert Track Group  again  For   Track Category  name it  annotated reference  Click  Insert Annotation Track  For  Track Type  choose  GFF/GFF3/BED/GBK Features  For  SNP Track Data  select  wildtype.gff  Under  JBrowse Track Type[Advanced]  select  Canvas Features .  Click on  JBrowse Styling Options   Under  JBrowse style.label  correct the word  prodcut  to  product .  Under  JBrowse style.description  type in  product,note,description   Under  Track Visibility  choose  On for new users .    Click  Execute    A new file will be created, called  JBrowse on data XX and data XX - Complete . Click on the eye icon next to the file name. The JBrowse window will appear in the centre Galaxy panel.    On the left, tick boxes to display the tracks    Use the minus button to zoom out to see:   sequence reads and their coverage (the grey graph)     Use the plus button to zoom in to see:   probable real variants (a whole column of snps)  probable errors (single one here and there)       In the coordinates box, type in  47299  and then  Go  to see the position of the SNP discussed above.  the correct codon at this position is TGT, coding for the amino acid Cysteine, in the middle row of the amino acid translations.  the mutation of T   A turns this triplet into TGA, a stop codon.", 
            "title": "View Snippy output in JBrowse"
        }, 
        {
            "location": "/modules/access_data/", 
            "text": "Public data \n assembly, annotation, MLST\n\n\nOverview\n\n\n\n\nDownload a readset from a public database\n\n\nCheck the quality of the data and filter\n\n\nAssemble the reads into a draft genome\n\n\nFind antibiotic resistance genes\n\n\nAnnotate the genome\n\n\nFind the sequence type (the MLST)\n\n\n\n\nBackground\n\n\nSequencing reads (readsets) for more than 100,000 isolates are available on public molecular sequence databases (GenBank/ENA/DDJB):\n\n\n\n\nMost of these have been produced using the Illumina sequencing platform.\n\n\nMost of these have no corresponding draft assembly.\n\n\n\n\nNot all readsets are of high quality:\n\n\n\n\nThere may be insufficient reads (usually ~x20 is the minimum read coverage needed).\n\n\nThe reads could be from a mixed colony.\n\n\nThe classification could be incorrect (both genus and species).\n\n\n\n\nIt is VERY important to check that what you find in the readset makes sense!\n\n\nImport data\n\n\n\n\nGo to your Galaxy instance.\n\n\n\n\nSet up a new History for this Activity.\n\n\n\n\nIn the History panel, click on the cog icon, select \nCreate New\n.\n\n\nA new empty history should appear; click on \nUnnamed history\n and re-name it (e.g. ENA Activity).\n\n\n\n\n\n\n\n\n\n\nChoose an accession number.\n\n\n\n\nIf you are working on this tutorial in a workshop: assign yourself a readset from the table of isolates provided. Put your name in Column B. The accession number for the readset that relates to each isolate is located in Column A. ERR019289 will be used in this demonstration. \n\n\nAlternatively, use accession number ERR019289. This is \nVibrio cholerae\n.\n\n\n\n\n\n\n\n\nIn Galaxy, go to the Tools panel on the left, select \nGet Data \n EBI SRA\n.\n\n\n\n\nThis causes the ENA website to open.\n\n\nEnter the accession number in the ENA search bar.\n\n\n\n\n\n\n\n\n\n(The search may find reads under Experiment and Run. If so, click on the Accession number under \nRun\n.)\n\n\n\n\n\n\nFind the column called \nFastq files (galaxy)\n. Click on \nFile 1\n.\n\n\n\n\n\n\n\n\nThis file will download to your Galaxy history, and will return you to the Galaxy page.\n\n\n\n\n\n\nRepeat the above steps for \nGet Data \n EBI SRA\n and download \nFile 2\n.\n\n\n\n\n\n\nThe files should now be in your Galaxy history.\n\n\n\n\nClick on the pencil icon next to File 1.\n\n\nRe-name it \nERR019289_1.fastq.gz\n. \nSave\n\n\nChange the datatype to \nfastqsanger\n (note: not fastqCsanger). \n Save\n\n\n\n\n\n\nRepeat for File 2 (name it \nERR019289_2.fastq.gz\n).\n\n\n\n\nEvaluate quality\n\n\nWe will run FastQC on the pair of fastq files.\n\n\n\n\nIn the Galaxy tools panel, go to \nNGS Analysis: NGS QC and manipulation: FastQC\n.\n\n\nChoose the \nMultiple datasets\n icon and then select both \nfastq\n files.\n\n\nYour Galaxy window should look like this:\n\n\n\n\n\n\n\n\nClick \nExecute\n  \n\n\nThe output (4 files) will appear at the top of your Galaxy history.\n\n\nClick on the eye icon next to \nFastQC on data 1: Web page\n\n\nScroll through the results. Take note of the maximum read length (\ne.g.\n 54 bp).\n\n\n\n\nTrim\n\n\nIn this step we will remove adapters and trim low-quality sequence from the reads.\n\n\n\n\nIn the Galaxy tools panel, go to \nNGS Analysis: NGS QC and manipulation: Trimmomatic\n\n\nLeave settings as they are except for:\n\n\nInput FASTQ file R1\n - check this is File 1\n\n\nInput FASTQ file R2\n - check this is File 2\n\n\n\n\n\n\nUnder \nPerform initial ILLUMINACLIP step\n choose \nYes\n\n\nUnder \nAdapter sequences to use\n choose \nNextera(paired-ended)\n\n\nThis trims particular adapters from the sequences.\n\n\n\n\n\n\nUnder \nTrimmomatic Operation\n leave the settings as they are.\n\n\nWe will use the average quality across a 4-base sliding window to identify and delete bad sequence (and the flanking bases to the start or end of the sequences - whichever is nearest to the patch of poor quality sequence)\n\n\n\n\n\n\n\n\nYour tool interface should look like this:\n\n\n\n\n\n\nClick \nExecute\n  \n\n\n\n\nThere are four output files.\n\n\n\n\nBecause trimmomatic might have trimmed some reads to zero, there are now some reads reads with no pair. These are in the \nunpaired\n output files. These can be deleted (with the cross button).\n\n\nRe-name the other two output files, e.g. as \nERRxxxxx_T1.fastq.gz\n \n \nERRxxxxx_T2.fastq.gz\n. These properly paired fastq files will be the input for the Spades assembly.  \n\n\n\n\nAssemble\n\n\nWe will assemble the trimmed reads.\n\n\nIn the left hand tools panel, go to \nNGS Analysis: NGS Assembly: spades\n.\n\n\nLeave the parameters as their defaults except:\n\n\n\n\nCareful correction?\n \nNo\n\n\nKmers to use, separated by commas:\n \n21,33,51\n\n\nchosen kmers must be \nshorter\n than the maximum read length (see the FastQC output: sequence length)\n\n\n\n\n\n\nCoverage Cutoff:\n \nOff\n\n\nusing a coverage cutoff might cause a problem if there are high-copy-number plasmids\n\n\n\n\n\n\nForward reads:\n ERR019289_T1.fastq.gz\n\n\nReverse reads:\n ERR019289_T2.fastq.gz\n\n\n\n\nYour tool interface should look like this:\n\n\n\n\n\n\nClick \nExecute\n  \n\n\n\n\nThere are five output files.\n\n\n\n\nSPAdes contigs (fasta)\n \n \nSPAdes scaffolds (fasta)\n: The draft genome assembly. (These should be identical with the conditions used here.)\n\n\nSPAdes contig stats\n \n \nSPAdes scaffold stats\n: A list of all the contigs and sizes in each of these files.\n\n\nSPAdes log\n: A summary of the assembly run.\n\n\n\n\nRename \nSPAdes contigs (fasta)\n to something like \nERR019289.fasta\n.\n\n\nCheck the size of your draft genome sequence\n\n\n\n\nIf you only have a few contigs, you can estimate the size from the \nSPAdes contig stats\n file by adding together the contig sizes.\n\n\nAlternatively, go to \nNGS Common Toolsets: Fasta Statistics\n and input the \nSPAdes contigs (fasta)\n file. Click \nExecute\n. The output will show the draft genome size next to  \nnum_bp\n.\n\n\n\n\nCompare your assembly size to others of the same species\n\n\n\n\nGo to the \nNCBI website: Genome\n\n\nNext to \n Genome \n, enter the name of your species; \ne.g. Vibrio cholerae\n.\n\n\nClick on \nGenome ASsembly and Annotation report\n\n\nView the table. Click on the \nSize\n column to sort by size. (Check for additional pages at the bottom right.)\n\n\nIs your assembly size similar?\n\n\n\n\nFind antibiotic resistance genes\n\n\nNow that we have our draft genome sequence, we can search for particular genes.\n\n\n\n\nWe will use the tool called \nABRicate\n to find antibiotic resistance genes in the genome.\n\n\nABRicate uses a \ndatabase\n of these genes called \nResFinder\n.\n\n\n\n\nIn the tools panel, go to \nNGS Analysis: NGS Annotation: ABRicate\n.\n\n\n\n\nFor \nSelect fasta file\n choose \nSPAdes contigs (fasta)\n or whatever you renamed it (e.g. ERR019289.fasta).\n\n\nClick \nExecute\n.\n\n\n\n\nThere is one output file. Click on the eye icon to view.\n\n\n\n\nThis shows a table with one line for each antibiotic resistance gene found, in which contig, at which position, and the % coverage.\n\n\n\n\n\n\nFind the sequence type (MLST)\n\n\nBacterial samples (isolates) are often assigned a \nsequence type\n. This is a number that defines the particular combination of alleles in that isolate, \ne.g.\n ST248.\n\n\n\n\nBecause several genes (loci) are used, this is termed Multi-Locus Sequence Typing (MLST).\n\n\nThere are different MLST schemes for different groups of bacteria.\n\n\n\n\nIn the tools panel, go to \nNGS Analysis: NGS Annotation: MLST\n\n\n\n\nUnder \ninput_file\n choose choose \nSPAdes contigs (fasta)\n or whatever you renamed it (e.g. ERR019289.fasta).\n\n\nNote: a specific MLST scheme can be specified if you wish, but by default all schemes are searched\n\n\nClick \nExecute\n.\n\n\n\n\nThere is one output file. Click on the eye icon to view.\n\n\n\n\nThere is a one line output.\n\n\n\n\n\n\nSome symbols are used to describe missing or inexact matches to alleles:\n\n\n\n\nn: Exact intact allele\n\n\n~n : Novel allele similar to n\n\n\nn,m : Multiple alleles\n\n\n- : Allele missing\n\n\n\n\nAnnotate\n\n\nWe have found a list of resistance genes in the draft sequence, but we can also annotate the whole genome to find all the genes present.\n\n\nIn the tools panel, go to \nTools \n NGS Analysis \n NGS: Annotation \n Prokka\n  \n\n\nSet the following parameters (leave everything else unchanged):\n\n\n\n\nContigs to annotate\n: \nSPAdes contigs (fasta)\n (or equivalent)\n\n\nLocus tag prefix (\nlocustag)\n: P\n\n\nForce GenBank/ENA/DDJB compliance (\ncompliant)\n: \nNo\n\n\nSequencing Centre ID (\ncentre)\n: V\n\n\nClick \nExecute\n  \n\n\n\n\nThere are several output files:\n\n\n\n\n\n\ngff\n: the master annotation in GFF format, containing both sequences and annotations\n\n\n\n\n\n\ngbk\n: a standard GenBank file derived from the master .gff. If the input to prokka was a multi-FASTA, then this will be a multi-GenBank, with one record for each sequence\n\n\n\n\n\n\nfna\n: nucleotide FASTA file of the input contig sequences\n\n\n\n\n\n\nfaa\n: protein FASTA file of the translated CDS sequences\n\n\n\n\n\n\nffn\n: nucleotide FASTA file of all the annotated sequences, not just CDS\n\n\n\n\n\n\nsqn\n: an ASN1 format \nSequin\n file for submission to GenBank. It needs to be edited to set the correct taxonomy, authors, related publication, etc.\n\n\n\n\n\n\nfsa\n: nucleotide FASTA file of the input contig sequences, used by \ntbl2asn\n to create the .sqn file. It is mostly the same as the .fna file, but with extra Sequin tags in the sequence description lines\n\n\n\n\n\n\ntbl\n: Feature Table file, used by \ntbl2asn\n to create the .sqn file\n\n\n\n\n\n\nerr\n: unacceptable annotations - the NCBI discrepancy report\n\n\n\n\n\n\nlog\n: contains all the output that Prokka produced during its run\n\n\n\n\n\n\ntxt\n: statistics relating to the annotated features found\n\n\n\n\n\n\nTabulate\n\n\nIf you are working on this tutorial as part of a class workshop:\n\n\n\n\nGo to the table of isolates and add information about genome size, GC content, and number of contigs.\n\n\n\n\nNext\n\n\n\n\nView the annotated genome in Artemis or JBrowse.", 
            "title": "Public data &rarr; assembly, annotation"
        }, 
        {
            "location": "/modules/access_data/#public-data-assembly-annotation-mlst", 
            "text": "", 
            "title": "Public data &rarr; assembly, annotation, MLST"
        }, 
        {
            "location": "/modules/access_data/#overview", 
            "text": "Download a readset from a public database  Check the quality of the data and filter  Assemble the reads into a draft genome  Find antibiotic resistance genes  Annotate the genome  Find the sequence type (the MLST)", 
            "title": "Overview"
        }, 
        {
            "location": "/modules/access_data/#background", 
            "text": "Sequencing reads (readsets) for more than 100,000 isolates are available on public molecular sequence databases (GenBank/ENA/DDJB):   Most of these have been produced using the Illumina sequencing platform.  Most of these have no corresponding draft assembly.   Not all readsets are of high quality:   There may be insufficient reads (usually ~x20 is the minimum read coverage needed).  The reads could be from a mixed colony.  The classification could be incorrect (both genus and species).   It is VERY important to check that what you find in the readset makes sense!", 
            "title": "Background"
        }, 
        {
            "location": "/modules/access_data/#import-data", 
            "text": "Go to your Galaxy instance.   Set up a new History for this Activity.   In the History panel, click on the cog icon, select  Create New .  A new empty history should appear; click on  Unnamed history  and re-name it (e.g. ENA Activity).      Choose an accession number.   If you are working on this tutorial in a workshop: assign yourself a readset from the table of isolates provided. Put your name in Column B. The accession number for the readset that relates to each isolate is located in Column A. ERR019289 will be used in this demonstration.   Alternatively, use accession number ERR019289. This is  Vibrio cholerae .     In Galaxy, go to the Tools panel on the left, select  Get Data   EBI SRA .   This causes the ENA website to open.  Enter the accession number in the ENA search bar.     (The search may find reads under Experiment and Run. If so, click on the Accession number under  Run .)    Find the column called  Fastq files (galaxy) . Click on  File 1 .     This file will download to your Galaxy history, and will return you to the Galaxy page.    Repeat the above steps for  Get Data   EBI SRA  and download  File 2 .    The files should now be in your Galaxy history.   Click on the pencil icon next to File 1.  Re-name it  ERR019289_1.fastq.gz .  Save  Change the datatype to  fastqsanger  (note: not fastqCsanger).   Save    Repeat for File 2 (name it  ERR019289_2.fastq.gz ).", 
            "title": "Import data"
        }, 
        {
            "location": "/modules/access_data/#evaluate-quality", 
            "text": "We will run FastQC on the pair of fastq files.   In the Galaxy tools panel, go to  NGS Analysis: NGS QC and manipulation: FastQC .  Choose the  Multiple datasets  icon and then select both  fastq  files.  Your Galaxy window should look like this:     Click  Execute     The output (4 files) will appear at the top of your Galaxy history.  Click on the eye icon next to  FastQC on data 1: Web page  Scroll through the results. Take note of the maximum read length ( e.g.  54 bp).", 
            "title": "Evaluate quality"
        }, 
        {
            "location": "/modules/access_data/#trim", 
            "text": "In this step we will remove adapters and trim low-quality sequence from the reads.   In the Galaxy tools panel, go to  NGS Analysis: NGS QC and manipulation: Trimmomatic  Leave settings as they are except for:  Input FASTQ file R1  - check this is File 1  Input FASTQ file R2  - check this is File 2    Under  Perform initial ILLUMINACLIP step  choose  Yes  Under  Adapter sequences to use  choose  Nextera(paired-ended)  This trims particular adapters from the sequences.    Under  Trimmomatic Operation  leave the settings as they are.  We will use the average quality across a 4-base sliding window to identify and delete bad sequence (and the flanking bases to the start or end of the sequences - whichever is nearest to the patch of poor quality sequence)     Your tool interface should look like this:    Click  Execute      There are four output files.   Because trimmomatic might have trimmed some reads to zero, there are now some reads reads with no pair. These are in the  unpaired  output files. These can be deleted (with the cross button).  Re-name the other two output files, e.g. as  ERRxxxxx_T1.fastq.gz     ERRxxxxx_T2.fastq.gz . These properly paired fastq files will be the input for the Spades assembly.", 
            "title": "Trim"
        }, 
        {
            "location": "/modules/access_data/#assemble", 
            "text": "We will assemble the trimmed reads.  In the left hand tools panel, go to  NGS Analysis: NGS Assembly: spades .  Leave the parameters as their defaults except:   Careful correction?   No  Kmers to use, separated by commas:   21,33,51  chosen kmers must be  shorter  than the maximum read length (see the FastQC output: sequence length)    Coverage Cutoff:   Off  using a coverage cutoff might cause a problem if there are high-copy-number plasmids    Forward reads:  ERR019289_T1.fastq.gz  Reverse reads:  ERR019289_T2.fastq.gz   Your tool interface should look like this:    Click  Execute      There are five output files.   SPAdes contigs (fasta)     SPAdes scaffolds (fasta) : The draft genome assembly. (These should be identical with the conditions used here.)  SPAdes contig stats     SPAdes scaffold stats : A list of all the contigs and sizes in each of these files.  SPAdes log : A summary of the assembly run.   Rename  SPAdes contigs (fasta)  to something like  ERR019289.fasta .  Check the size of your draft genome sequence   If you only have a few contigs, you can estimate the size from the  SPAdes contig stats  file by adding together the contig sizes.  Alternatively, go to  NGS Common Toolsets: Fasta Statistics  and input the  SPAdes contigs (fasta)  file. Click  Execute . The output will show the draft genome size next to   num_bp .   Compare your assembly size to others of the same species   Go to the  NCBI website: Genome  Next to   Genome  , enter the name of your species;  e.g. Vibrio cholerae .  Click on  Genome ASsembly and Annotation report  View the table. Click on the  Size  column to sort by size. (Check for additional pages at the bottom right.)  Is your assembly size similar?", 
            "title": "Assemble"
        }, 
        {
            "location": "/modules/access_data/#find-antibiotic-resistance-genes", 
            "text": "Now that we have our draft genome sequence, we can search for particular genes.   We will use the tool called  ABRicate  to find antibiotic resistance genes in the genome.  ABRicate uses a  database  of these genes called  ResFinder .   In the tools panel, go to  NGS Analysis: NGS Annotation: ABRicate .   For  Select fasta file  choose  SPAdes contigs (fasta)  or whatever you renamed it (e.g. ERR019289.fasta).  Click  Execute .   There is one output file. Click on the eye icon to view.   This shows a table with one line for each antibiotic resistance gene found, in which contig, at which position, and the % coverage.", 
            "title": "Find antibiotic resistance genes"
        }, 
        {
            "location": "/modules/access_data/#find-the-sequence-type-mlst", 
            "text": "Bacterial samples (isolates) are often assigned a  sequence type . This is a number that defines the particular combination of alleles in that isolate,  e.g.  ST248.   Because several genes (loci) are used, this is termed Multi-Locus Sequence Typing (MLST).  There are different MLST schemes for different groups of bacteria.   In the tools panel, go to  NGS Analysis: NGS Annotation: MLST   Under  input_file  choose choose  SPAdes contigs (fasta)  or whatever you renamed it (e.g. ERR019289.fasta).  Note: a specific MLST scheme can be specified if you wish, but by default all schemes are searched  Click  Execute .   There is one output file. Click on the eye icon to view.   There is a one line output.    Some symbols are used to describe missing or inexact matches to alleles:   n: Exact intact allele  ~n : Novel allele similar to n  n,m : Multiple alleles  - : Allele missing", 
            "title": "Find the sequence type (MLST)"
        }, 
        {
            "location": "/modules/access_data/#annotate", 
            "text": "We have found a list of resistance genes in the draft sequence, but we can also annotate the whole genome to find all the genes present.  In the tools panel, go to  Tools   NGS Analysis   NGS: Annotation   Prokka     Set the following parameters (leave everything else unchanged):   Contigs to annotate :  SPAdes contigs (fasta)  (or equivalent)  Locus tag prefix ( locustag) : P  Force GenBank/ENA/DDJB compliance ( compliant) :  No  Sequencing Centre ID ( centre) : V  Click  Execute      There are several output files:    gff : the master annotation in GFF format, containing both sequences and annotations    gbk : a standard GenBank file derived from the master .gff. If the input to prokka was a multi-FASTA, then this will be a multi-GenBank, with one record for each sequence    fna : nucleotide FASTA file of the input contig sequences    faa : protein FASTA file of the translated CDS sequences    ffn : nucleotide FASTA file of all the annotated sequences, not just CDS    sqn : an ASN1 format  Sequin  file for submission to GenBank. It needs to be edited to set the correct taxonomy, authors, related publication, etc.    fsa : nucleotide FASTA file of the input contig sequences, used by  tbl2asn  to create the .sqn file. It is mostly the same as the .fna file, but with extra Sequin tags in the sequence description lines    tbl : Feature Table file, used by  tbl2asn  to create the .sqn file    err : unacceptable annotations - the NCBI discrepancy report    log : contains all the output that Prokka produced during its run    txt : statistics relating to the annotated features found    Tabulate  If you are working on this tutorial as part of a class workshop:   Go to the table of isolates and add information about genome size, GC content, and number of contigs.", 
            "title": "Annotate"
        }, 
        {
            "location": "/modules/access_data/#next", 
            "text": "View the annotated genome in Artemis or JBrowse.", 
            "title": "Next"
        }, 
        {
            "location": "/modules/viral_genomes/", 
            "text": "Viral Genome Sequencing\n\n\nThis tutorial is about determining the genome sequence of a virus, using comparisons to a reference sequence.\n\n\nBackground\n\n\nMurray Valley encephalitis virus is classified as part of the Flavivirus genus of viruses, all of which are positive strand RNA viruses. The type species for this genus is yellow fever virus, and the genus includes dengue virus, west nile virus and zika virus.\n\n\nViruses from this genus have a single-segment genome of about 11 kb. Within this, there is a 10 kb open reading frame that encodes a polyprotein. Following translation, this protein is modified to yield the various, mature structural and non-structural viral proteins as illustrated in Fig. 1.\n\n\n\n\nFig. 1 - An overview of a typical flavivirus genome and the viral proteins that are part of the viral polyprotein (from \nViralzone\n).\n\n\nThere are 14 complete Murray Valley encephalitis virus genome sequences available at NCBI Viral Genomes.\n\n\n\n\nGo to NCBI \nViral Genomes\n.\n\n\nSelect \nBrowse viral genomes by family\n and click on the family \nFlaviviridae\n: \nComplete Genomes\n\n\nNote: you may have to widen your screen to see all the columns of viral family names.\n\n\n\n\n\n\n\n\nLook at the row for Murray Valley encephelitis virus. In the Neigbours column, we can see there are 14.\n\n\n\n\n\n\n\nIn this tutorial we will use the prototype strain 1-151 as the reference genome sequence.\n\n\n\n\nThis strain was isolated in the early 1950s - see, AF161266.\n\n\n[are we using this AF seq exactly? or if not, which seq]\n\n\nsee \nhttps://www.ncbi.nlm.nih.gov/pubmed/10567642\n\n\n[This seq is not in the list of 14 \n does this mean it is just more distant and therefore didn\nt align closely?]\n\n\n\n\nThe isolate we are looking at has been sequenced using the Illumina platform.\n\n\n\n\nThe genomic cDNA was prepared using random hexamers to prime the reverse transcription of the viral genomic RNA.\n\n\nAfter second strand synthesis, the cDNA was used to prepare an Illumina sequencing library and run on an Illumina MiSeq instrument.\n\n\n\n\nIn this activity we will use a read mapping approach to determine the sequence of a new Murray Valley encephalitis virus isolate.\n\n\nImport data\n\n\nSection overview:\n\n\n\n\nLog in to your Galaxy server\n\n\nImport files required for the activity\n\n\nView imported files\n\n\n\n\nGo to the Galaxy Page\n\n\n\n\nWeb address: \nhttp://phln.genome.edu.au/galaxy\n\n\nRemind me how to logon\n\n\n\n\nImport files to Galaxy\n\n\n\n\nClick on the \nAnalyze Data\n menu at the top of the page.\n\n\nClick on the \nHistory\n menu button (the \n on the top right of the history pane)\n\n\nClick \nImport from File\n (at the bottom of the list)\n\n\nA new page will appear with a text box for the URL of the history to import.\n\n\nCopy the following URL into the text box:\n\n\n\n\nhttp://phln.genome.edu.au/public/dieter/Galaxy-History-MVEVmapping.tar.gz\n\n\n\n\n\n\nClick \nSubmit\n\n\n\n\nGalaxy will download the data files from the internet and will be available as an additional history (takes about one minute).\n\n\n\n\nTo make the newly imported history appear as the current history:\n\n\n\n\nClick on the View all Histories button (the \n on the top right of the history pane.)\n\n\nIf the history has finished downloading it will appear with the title:\n\n\n\u201cimported from archive: MVEVmapping\u201c\n\n\nClick on the \nSwitch to\n button above this history and then the \nDone\n button.\n\n\n\n\nYou should now have 4 files in the history pane as follows:\n\n\n\n\nReference sequence files [from AF161266?]:\n\n\n\n\nMVEV.gbk\n - genbank format\n\n\nMVEV.fna\n - fasta format\n\n\n\n\nIllumina sequence reads (R1 and R2) from the new isolate:\n\n\n\n\nMVE_R1.fq\n - forward reads\n\n\nMVE_R2.fq\n - reverse reads\n\n\n\n\nSnippy\n\n\nSection overview:\n\n\n\n\nFind variants in the isolate using the tool Snippy.\n\n\n\n\nSnippy is a fast bacterial [/viral?] variant caller for NGS reads. The software is available on GitHub at \nhttps://github.com/tseemann/snippy\n. For this activity, we are using Snippy as installed on Galaxy.\n\n\nPreliminary Activity\n\n\n\n\n\n\nRun FastQC: How many reads in in each of the fastq files \nMVE_R1.fq\n and \nMVE_R2.fq\n?\n\n\n\n\n\n\nMVEV.fna\n and \nMVEV.gbk\n each contain the genome sequence of Murray Valley encephalitis virus strain 1-151 - how many bases in the genome? (Hint: use Fasta Statistics)\n\n\n\n\n\n\nRunning Snippy\n\n\nSnippy maps reads from the new Murray Valley encephalitis virus isolate (the \nMVE_R1.fq\n and \nMVE_R2.fq\n reads) onto the genome sequence of Murray Valley encephalitis virus strain 1-151 (\nMVEV.fna\n). [or gbk? that\ns in the screenshot]\n\n\n\n\nFind Snippy in the tool menu (in  NGS: Variant Analysis)\n\n\nSelect appropriate files (see screenshot below) and Execute (use default settings).\n\n\n\n\n\n\nOutput\n\n\nFiles cataloging SNP differences:\n\n\n\n\n9: \nsnippy on data 4, data 3, and data 2 snps vcf file\n\n\n10: \nsnippy on data 4, data 3, and data 2 snps gff file\n\n\n11: \nsnippy on data 4, data 3, and data 2 snps table\n\n\n12: \nsnippy on data 4, data 3, and data 2 snps summary\n\n\n\n\nA log of the progress of the run:\n\n\n\n\n13: \nsnippy on data 4, data 3, and data 2 log file\n\n\n\n\nRegions where reads aligned (NNNN \n, indicate regions where there was low or no read data):\n\n\n\n\n14: \nsnippy on data 4, data 3, and data 2 aligned fasta\n\n\n\n\nA consensus genome sequence for the new isolate:\n\n\n\n\n15: \nsnippy on data 4, data 3, and data 2 consensus fasta\n\n\n\n\nSummary of the read depth:\n\n\n\n\n16: \nsnippy on data 4, data 3, and data 2 mapping depth\n\n\n\n\nA compressed version of the above files (and more that can be downloaded):\n\n\n\n\n17: \nsnippy on data 4, data 3, and data 2 out dir\n\n\n\n\nDownload these files to your local computer (click on the file name and then the disk icon in the lower left hand corner):\n\n\n\n\n17: \nsnippy on data 4, data 3, and data 2 out dir\n (and unzip)\n\n\n2: \nMVEV.gbk\n\n\n1: \nMVEV.fna\n\n\n\n\nAlso download these bam files from these URLs (open each URL in a new tab and the file should download automatically):\n\n\n\n\nhttp://phln.genome.edu.au/public/dieter/snps.bam\n\n\nhttp://phln.genome.edu.au/public/dieter/snps.bam.bai\n\n\nhttp://phln.genome.edu.au/public/dieter/snps.depth.gz\n\n\nhttp://phln.genome.edu.au/public/dieter/snps.depth.gz.tbi\n\n\n\n\nNote: if you have previously downloaded these files, the new downloads may be renamed. Remove any spaces in the names.\n\n\n[Should we explain why we have these four other files - where they are from, what they are needed for, etc - so if people are repeating this exercise on their own they can follow]\n\n\nArtemis\n\n\nSection overview:\n\n\n\n\nView the reads from the new isolate mapped against the reference sequence, using the tool Artemis.\n\n\n\n\nArtemis is a tool to view genome sequences and mapped reads, including variants (SNPs).\n\n\nIf Artemis is not installed, go to \nhttp://www.sanger.ac.uk/science/tools/artemis\n.\n\n\nView the reference sequence\n\n\n\n\nOpen Artemis.\n\n\nGo to \nFile: Open\n and select \nMVEV.gbk\n. The file will probably have a \nGalaxy\n prefix, e.g. \nGalaxy2-[MVEV.gbk].genbank\n.\n\n\n\n\nThe Artemis window:\n\n\n\n\npanes 1 and 2 are the same, but can be scaled differently\n\n\neach pane has the double-stranded sequence in the centre, with amino acid translations above and below\n\n\nthere is a third lower pane with feature information\n\n\ncoding sequences are highlighted in blue\n\n\nother features are highlighted in green\n\n\nclicking on one of these will select it in all panels\n\n\nblack vertical lines are stop codons (when zoomed out)\n\n\nmove left and right with horizontal scroll bar\n\n\nzoom in and out with right-hand scroll bar\n\n\n\n\n\n\nAdd a plot\n\n\n\n\nGo to \nGraph: Add User Plot\n, select \nsnps.depth.gz\n\n\nA graph should display at the top of the screen\n[is this depth of reads or depth of snps?]\n\n\n\n\n\n\nThe file that is used to produce the graph is a 3 column table (part of the file is shown below)\n\n\n[what is the file name?]\n\n\n             \u2026\n\n\n\nColumn 1: the name of the sequence, Column 2: the position in the sequence, Column 1: the read depth at that position\n\n\nProducing a draft genome sequence\n\n\nSection overview:\n\n\n\n\nProduce draft genome sequence for the new viral isolate.\n\n\n\n\nExamine the mapped reads\n\n\n[or title]\n\n\nWhat is the minimum read depth used by Snippy to call a SNP?\n\n\n\n\nHint: Go back to Snippy on Galaxy - look at the information below the \u2018Execute\u2019 button\n\n\n\n\nWould Snippy call a SNP at positions 1 \u2192 5 ?\n\n\nWhat is the maximum read depth?\n\n\nWhat do we know about the sequence of the new isolate in the regions where there is low read coverage?\n\n\n[close first Artemis window?]\n\n\n\n\nUnzip \n17: snippy on data 4, data 3, and data 2 out dir\n\n\n\n\nThis makes an \nout\n folder containing some files including the consensus file.\n\n\n\n\n\n\nIn Artemis, open \nsnps.consensus.fa\n\n\n\n\n\n\nThis is a file that is based on the reference sequence and includes any confirmed SNPs called by Snippy.\n\n\nIf we were going to use this sequence to produce the draft sequence of the new isolate, what bases would you have at positions 1\u2192 5?\n\n\nGetting an Overview of the Difference between strain 1-151 and our new isolate\n\n\nSimplest overview: view the bam file with Artemis\n\n\nOpen \nMVEV.gbk\n in Artemis and load the \nsnps.bam\n via the File menu to \u201cRead BAM / VCF\u201d\n\n\nOnce loaded, differences between reads and the reference sequence can be highlighted by right/command click in the bam view window. Select \u2018Show \n SNP marks\u2019.\n\n\n\n\nGetting more detail: looking at the table of SNPs\n\n\nLocated in the out folder there is a html file that contains a table with information about each of the SNPs called by Snippy.\n\n\nIncluded in the table is a column that provides a prediction about the impact each SNP will have on annotated protein coding regions. The genbank file provides the annotation information used by Snippy to make the predictions.\n\n\nA total of 790 SNP differences were call by Snippy\n\n\nOpen snps.html in your web browser\n\n\n[screenshot]\n\n\nSummary: 663/790 SNPs do not result a difference in the encoded polyprotein\n\n\nIs this pattern of variable genome sequence and more conserved protein sequence normal in viruses? What might be the cause?", 
            "title": "Viral genome sequencing"
        }, 
        {
            "location": "/modules/viral_genomes/#viral-genome-sequencing", 
            "text": "This tutorial is about determining the genome sequence of a virus, using comparisons to a reference sequence.", 
            "title": "Viral Genome Sequencing"
        }, 
        {
            "location": "/modules/viral_genomes/#background", 
            "text": "Murray Valley encephalitis virus is classified as part of the Flavivirus genus of viruses, all of which are positive strand RNA viruses. The type species for this genus is yellow fever virus, and the genus includes dengue virus, west nile virus and zika virus.  Viruses from this genus have a single-segment genome of about 11 kb. Within this, there is a 10 kb open reading frame that encodes a polyprotein. Following translation, this protein is modified to yield the various, mature structural and non-structural viral proteins as illustrated in Fig. 1.   Fig. 1 - An overview of a typical flavivirus genome and the viral proteins that are part of the viral polyprotein (from  Viralzone ).  There are 14 complete Murray Valley encephalitis virus genome sequences available at NCBI Viral Genomes.   Go to NCBI  Viral Genomes .  Select  Browse viral genomes by family  and click on the family  Flaviviridae :  Complete Genomes  Note: you may have to widen your screen to see all the columns of viral family names.     Look at the row for Murray Valley encephelitis virus. In the Neigbours column, we can see there are 14.    In this tutorial we will use the prototype strain 1-151 as the reference genome sequence.   This strain was isolated in the early 1950s - see, AF161266.  [are we using this AF seq exactly? or if not, which seq]  see  https://www.ncbi.nlm.nih.gov/pubmed/10567642  [This seq is not in the list of 14   does this mean it is just more distant and therefore didn t align closely?]   The isolate we are looking at has been sequenced using the Illumina platform.   The genomic cDNA was prepared using random hexamers to prime the reverse transcription of the viral genomic RNA.  After second strand synthesis, the cDNA was used to prepare an Illumina sequencing library and run on an Illumina MiSeq instrument.   In this activity we will use a read mapping approach to determine the sequence of a new Murray Valley encephalitis virus isolate.", 
            "title": "Background"
        }, 
        {
            "location": "/modules/viral_genomes/#import-data", 
            "text": "", 
            "title": "Import data"
        }, 
        {
            "location": "/modules/viral_genomes/#section-overview", 
            "text": "Log in to your Galaxy server  Import files required for the activity  View imported files", 
            "title": "Section overview:"
        }, 
        {
            "location": "/modules/viral_genomes/#go-to-the-galaxy-page", 
            "text": "Web address:  http://phln.genome.edu.au/galaxy  Remind me how to logon", 
            "title": "Go to the Galaxy Page"
        }, 
        {
            "location": "/modules/viral_genomes/#import-files-to-galaxy", 
            "text": "Click on the  Analyze Data  menu at the top of the page.  Click on the  History  menu button (the   on the top right of the history pane)  Click  Import from File  (at the bottom of the list)  A new page will appear with a text box for the URL of the history to import.  Copy the following URL into the text box:   http://phln.genome.edu.au/public/dieter/Galaxy-History-MVEVmapping.tar.gz    Click  Submit   Galaxy will download the data files from the internet and will be available as an additional history (takes about one minute).", 
            "title": "Import files to Galaxy"
        }, 
        {
            "location": "/modules/viral_genomes/#to-make-the-newly-imported-history-appear-as-the-current-history", 
            "text": "Click on the View all Histories button (the   on the top right of the history pane.)  If the history has finished downloading it will appear with the title:  \u201cimported from archive: MVEVmapping\u201c  Click on the  Switch to  button above this history and then the  Done  button.   You should now have 4 files in the history pane as follows:   Reference sequence files [from AF161266?]:   MVEV.gbk  - genbank format  MVEV.fna  - fasta format   Illumina sequence reads (R1 and R2) from the new isolate:   MVE_R1.fq  - forward reads  MVE_R2.fq  - reverse reads", 
            "title": "To make the newly imported history appear as the current history:"
        }, 
        {
            "location": "/modules/viral_genomes/#snippy", 
            "text": "", 
            "title": "Snippy"
        }, 
        {
            "location": "/modules/viral_genomes/#section-overview_1", 
            "text": "Find variants in the isolate using the tool Snippy.   Snippy is a fast bacterial [/viral?] variant caller for NGS reads. The software is available on GitHub at  https://github.com/tseemann/snippy . For this activity, we are using Snippy as installed on Galaxy.", 
            "title": "Section overview:"
        }, 
        {
            "location": "/modules/viral_genomes/#preliminary-activity", 
            "text": "Run FastQC: How many reads in in each of the fastq files  MVE_R1.fq  and  MVE_R2.fq ?    MVEV.fna  and  MVEV.gbk  each contain the genome sequence of Murray Valley encephalitis virus strain 1-151 - how many bases in the genome? (Hint: use Fasta Statistics)", 
            "title": "Preliminary Activity"
        }, 
        {
            "location": "/modules/viral_genomes/#running-snippy", 
            "text": "Snippy maps reads from the new Murray Valley encephalitis virus isolate (the  MVE_R1.fq  and  MVE_R2.fq  reads) onto the genome sequence of Murray Valley encephalitis virus strain 1-151 ( MVEV.fna ). [or gbk? that s in the screenshot]   Find Snippy in the tool menu (in  NGS: Variant Analysis)  Select appropriate files (see screenshot below) and Execute (use default settings).", 
            "title": "Running Snippy"
        }, 
        {
            "location": "/modules/viral_genomes/#output", 
            "text": "Files cataloging SNP differences:   9:  snippy on data 4, data 3, and data 2 snps vcf file  10:  snippy on data 4, data 3, and data 2 snps gff file  11:  snippy on data 4, data 3, and data 2 snps table  12:  snippy on data 4, data 3, and data 2 snps summary   A log of the progress of the run:   13:  snippy on data 4, data 3, and data 2 log file   Regions where reads aligned (NNNN  , indicate regions where there was low or no read data):   14:  snippy on data 4, data 3, and data 2 aligned fasta   A consensus genome sequence for the new isolate:   15:  snippy on data 4, data 3, and data 2 consensus fasta   Summary of the read depth:   16:  snippy on data 4, data 3, and data 2 mapping depth   A compressed version of the above files (and more that can be downloaded):   17:  snippy on data 4, data 3, and data 2 out dir   Download these files to your local computer (click on the file name and then the disk icon in the lower left hand corner):   17:  snippy on data 4, data 3, and data 2 out dir  (and unzip)  2:  MVEV.gbk  1:  MVEV.fna   Also download these bam files from these URLs (open each URL in a new tab and the file should download automatically):   http://phln.genome.edu.au/public/dieter/snps.bam  http://phln.genome.edu.au/public/dieter/snps.bam.bai  http://phln.genome.edu.au/public/dieter/snps.depth.gz  http://phln.genome.edu.au/public/dieter/snps.depth.gz.tbi   Note: if you have previously downloaded these files, the new downloads may be renamed. Remove any spaces in the names.  [Should we explain why we have these four other files - where they are from, what they are needed for, etc - so if people are repeating this exercise on their own they can follow]", 
            "title": "Output"
        }, 
        {
            "location": "/modules/viral_genomes/#artemis", 
            "text": "", 
            "title": "Artemis"
        }, 
        {
            "location": "/modules/viral_genomes/#section-overview_2", 
            "text": "View the reads from the new isolate mapped against the reference sequence, using the tool Artemis.   Artemis is a tool to view genome sequences and mapped reads, including variants (SNPs).  If Artemis is not installed, go to  http://www.sanger.ac.uk/science/tools/artemis .", 
            "title": "Section overview:"
        }, 
        {
            "location": "/modules/viral_genomes/#view-the-reference-sequence", 
            "text": "Open Artemis.  Go to  File: Open  and select  MVEV.gbk . The file will probably have a  Galaxy  prefix, e.g.  Galaxy2-[MVEV.gbk].genbank .", 
            "title": "View the reference sequence"
        }, 
        {
            "location": "/modules/viral_genomes/#the-artemis-window", 
            "text": "panes 1 and 2 are the same, but can be scaled differently  each pane has the double-stranded sequence in the centre, with amino acid translations above and below  there is a third lower pane with feature information  coding sequences are highlighted in blue  other features are highlighted in green  clicking on one of these will select it in all panels  black vertical lines are stop codons (when zoomed out)  move left and right with horizontal scroll bar  zoom in and out with right-hand scroll bar", 
            "title": "The Artemis window:"
        }, 
        {
            "location": "/modules/viral_genomes/#add-a-plot", 
            "text": "Go to  Graph: Add User Plot , select  snps.depth.gz  A graph should display at the top of the screen\n[is this depth of reads or depth of snps?]    The file that is used to produce the graph is a 3 column table (part of the file is shown below)  [what is the file name?]               \u2026  Column 1: the name of the sequence, Column 2: the position in the sequence, Column 1: the read depth at that position", 
            "title": "Add a plot"
        }, 
        {
            "location": "/modules/viral_genomes/#producing-a-draft-genome-sequence", 
            "text": "", 
            "title": "Producing a draft genome sequence"
        }, 
        {
            "location": "/modules/viral_genomes/#section-overview_3", 
            "text": "Produce draft genome sequence for the new viral isolate.", 
            "title": "Section overview:"
        }, 
        {
            "location": "/modules/viral_genomes/#examine-the-mapped-reads", 
            "text": "[or title]  What is the minimum read depth used by Snippy to call a SNP?   Hint: Go back to Snippy on Galaxy - look at the information below the \u2018Execute\u2019 button   Would Snippy call a SNP at positions 1 \u2192 5 ?  What is the maximum read depth?  What do we know about the sequence of the new isolate in the regions where there is low read coverage?  [close first Artemis window?]   Unzip  17: snippy on data 4, data 3, and data 2 out dir   This makes an  out  folder containing some files including the consensus file.    In Artemis, open  snps.consensus.fa    This is a file that is based on the reference sequence and includes any confirmed SNPs called by Snippy.  If we were going to use this sequence to produce the draft sequence of the new isolate, what bases would you have at positions 1\u2192 5?", 
            "title": "Examine the mapped reads"
        }, 
        {
            "location": "/modules/viral_genomes/#getting-an-overview-of-the-difference-between-strain-1-151-and-our-new-isolate", 
            "text": "Simplest overview: view the bam file with Artemis  Open  MVEV.gbk  in Artemis and load the  snps.bam  via the File menu to \u201cRead BAM / VCF\u201d  Once loaded, differences between reads and the reference sequence can be highlighted by right/command click in the bam view window. Select \u2018Show   SNP marks\u2019.", 
            "title": "Getting an Overview of the Difference between strain 1-151 and our new isolate"
        }, 
        {
            "location": "/modules/viral_genomes/#getting-more-detail-looking-at-the-table-of-snps", 
            "text": "Located in the out folder there is a html file that contains a table with information about each of the SNPs called by Snippy.  Included in the table is a column that provides a prediction about the impact each SNP will have on annotated protein coding regions. The genbank file provides the annotation information used by Snippy to make the predictions.  A total of 790 SNP differences were call by Snippy  Open snps.html in your web browser  [screenshot]  Summary: 663/790 SNPs do not result a difference in the encoded polyprotein  Is this pattern of variable genome sequence and more conserved protein sequence normal in viruses? What might be the cause?", 
            "title": "Getting more detail: looking at the table of SNPs"
        }, 
        {
            "location": "/modules/abricate/", 
            "text": "Finding antibiotic-resistant genes\n\n\nOverview\n\n\n\n\nImport an assembled bacterial genome\n\n\nFind antibiotic-resistant (ABR) genes\n\n\n\n\nImport data\n\n\n\n\nGo to your Galaxy instance.\n\n\n\n\nSet up a new History for this Activity.\n\n\n\n\nIn the History panel, click on the cog icon, select \nCreate New\n.\n\n\nA new empty history should appear; click on \nUnnamed history\n and re-name it (e.g. ABR genes).\n\n\n\n\n\n\n\n\n\n\nImport an assembled genome (or use one from your history).\n\n\n\n\nCopy this URL for a previously-assembled genome:  \nhttps://swift.rc.nectar.org.au:8888/v1/AUTH_377/public/Microbial_tutorials/SPAdes_contigs.fasta\n\n\nFrom the Galaxy tool panel, click on \nGet Data \n Upload File\n  \n\n\nClick the \nPaste/Fetch data\n button  \n\n\nPaste the URL into the box.\n\n\nClick the \nStart\n button.  \n\n\nOnce the progress bar reaches 100%, click the \nClose\n button  \n\n\nThe file will now upload to your current history.\n\n\nRe-name it with the pencil icon to \ncontigs.fasta\n.\n\n\n\n\n\n\n\n\nFind antibiotic-resistance genes\n\n\n\n\nWe will use the tool called \nABRicate\n to find antibiotic resistance genes in the (draft) genome.\n\n\nABRicate uses a \ndatabase\n of these genes called \nResFinder\n.\n\n\n\n\nIn the tools panel, go to \nNGS Analysis: NGS Annotation: ABRicate\n.\n\n\n\n\nFor \nSelect fasta file\n choose \ncontigs.fasta\n (or the name of your own assembly file.)\n\n\nClick \nExecute\n.\n\n\n\n\nThere is one output file. Click on the eye icon to view. It should look like this, although likely with a different number of rows.\n\n\n\n\nThis shows a table with one line for each antibiotic resistance gene found, in which contig, at which position, and the % coverage.\n\n\n\n\n\n\nNext\n\n\nIn the output from Abricate, column 5 has the list of the antibiotic-resistant gene names. Some of these may be complete, exact matches, and some may have a gap/mutation in their sequence which can affect whether that protein is actually expressed.\n\n\nTo find out more about what type of ABR genes these are, you can search \nGenbank\n with the gene name (e.g. aadD).", 
            "title": "Finding antibiotic-resistant genes"
        }, 
        {
            "location": "/modules/abricate/#finding-antibiotic-resistant-genes", 
            "text": "", 
            "title": "Finding antibiotic-resistant genes"
        }, 
        {
            "location": "/modules/abricate/#overview", 
            "text": "Import an assembled bacterial genome  Find antibiotic-resistant (ABR) genes", 
            "title": "Overview"
        }, 
        {
            "location": "/modules/abricate/#import-data", 
            "text": "Go to your Galaxy instance.   Set up a new History for this Activity.   In the History panel, click on the cog icon, select  Create New .  A new empty history should appear; click on  Unnamed history  and re-name it (e.g. ABR genes).      Import an assembled genome (or use one from your history).   Copy this URL for a previously-assembled genome:   https://swift.rc.nectar.org.au:8888/v1/AUTH_377/public/Microbial_tutorials/SPAdes_contigs.fasta  From the Galaxy tool panel, click on  Get Data   Upload File     Click the  Paste/Fetch data  button    Paste the URL into the box.  Click the  Start  button.    Once the progress bar reaches 100%, click the  Close  button    The file will now upload to your current history.  Re-name it with the pencil icon to  contigs.fasta .", 
            "title": "Import data"
        }, 
        {
            "location": "/modules/abricate/#find-antibiotic-resistance-genes", 
            "text": "We will use the tool called  ABRicate  to find antibiotic resistance genes in the (draft) genome.  ABRicate uses a  database  of these genes called  ResFinder .   In the tools panel, go to  NGS Analysis: NGS Annotation: ABRicate .   For  Select fasta file  choose  contigs.fasta  (or the name of your own assembly file.)  Click  Execute .   There is one output file. Click on the eye icon to view. It should look like this, although likely with a different number of rows.   This shows a table with one line for each antibiotic resistance gene found, in which contig, at which position, and the % coverage.", 
            "title": "Find antibiotic-resistance genes"
        }, 
        {
            "location": "/modules/abricate/#next", 
            "text": "In the output from Abricate, column 5 has the list of the antibiotic-resistant gene names. Some of these may be complete, exact matches, and some may have a gap/mutation in their sequence which can affect whether that protein is actually expressed.  To find out more about what type of ABR genes these are, you can search  Genbank  with the gene name (e.g. aadD).", 
            "title": "Next"
        }, 
        {
            "location": "/modules/workflows/", 
            "text": "Galaxy workflows\n\n\nThis tutorial assumes you have used Galaxy before.\n\n\nAlthough we can use tools in Galaxy to analyse data and create a history, there is also a way to create a workflow of files, tools, settings and outputs. You can then input different datasets and run the workflow.\n\n\nThis tutorial covers building a workflow to analyse a bacterial genome, from input Fastq sequencing reads to assembly, annotation, and visualization.\n\n\nStart\n\n\nGo to your Galaxy instance and Register/Login.\n\n\nImport a history of data files:\n\n\n\n\nClick on the \nHistory\n cog \n\n\nSelect \nImport from File\n\n\nIn the box called \nArchived History URL\n, paste in this link address to the Galaxy history of input files:\n\n\n\n\nhttps://swift.rc.nectar.org.au:8888/v1/AUTH_377/public/Microbial_tutorials/Galaxy_history_input_files.tar.gz\n\n\n\n\nClick \nSubmit\n\n\nWait a few seconds.\n\n\nClick on the \nView all histories\n button \n\n\nSee if the Galaxy history has been imported: it will be called \nimported from archive: Data\n\n\nAbove that pane, click on the \nSwitch to\n button.\n\n\nThen click \nDone\n (in the top left corner).\n\n\n\n\nYou should now have a list of five files in your current history.\n\n\n\n\n\n\nRe-name this history \nWorkflows\n.\n\n\n\n\n\n\nBuild a workflow\n\n\nWe will first write a workflow for genome assembly.\n\n\n\n\nIn the top menu bar in Galaxy, click on \nWorkflow\n.\n\n\n\n\n\n\n\n\nClick on \nCreate new workflow\n\n\n\n\n\n\n\n\n\n\nUnder \nWorkflow Name:\n put in \nReads to Annotation\n.\n\n\n\n\n\n\nClick \nCreate\n\n\n\n\n\n\nThis will bring up the \nWorkflow Canvas\n, a grid where you can arrange the workflow.\n\n\n\n\n\n\nAdd inputs\n\n\n\n\n\n\nIn the Tools panel, click \nInputs: Input datset\n twice (at the very top of the list).\n\n\n\n\n\n\nA box will appear: drag it to the left and there will be another box underneath it. Drag this also to the left. Your workflow canvas should look like this:\n\n\n\n\n\n\n\n\n\n\nClick on the first box. Look in the right hand panel (now called \nDetails\n) and change the name of the Input dataset to \nR1.fastq\n. Press Enter for the change to be saved.\n\n\n\n\n\n\n\n\nRepeat for the second input dataset box, naming that one \nR2.fastq\n.\n\n\n\n\nAdd the tool \nspades\n\n\n\n\nIn the tools panel, click on \nNGS Analysis: NGS Assembly: spades\n.\nThis puts the spades box onto the workflow canvas.\n\n\n\n\n\n\n\n\n\n\nClick on the spades box and look in the Details pane on the right. This shows all the options in spades. Choose:\n\n\n\n\n\n\nRun only Assembly\n: \nYes\n [the \nYes\n button should be darker grey]\n\n\n\n\nKmers to use separated by commas:\n \n33,55,91\n  [note: no spaces]  \n\n\nCoverage cutoff:\n \nauto\n  \n\n\n\n\nJoin inputs to the tool\n\n\nNow tell spades which input files to use.\n\n\n\n\n\n\nLook at the input dataset box called \nR1.fastq\n and find the small arrow: \n\n\n\n\n\n\nClick on this and drag the arrow over to the spades box input arrow \n next to \nLibraries 1 \n Files 1 \n Forward reads\n.\n\n\n\n\n\n\n\n\n\n\nRepeat for the dataset box \nR2.fastq\n, joining to the spades box next to \nLibraries 1 \n Files 1 \n Reverse reads\n.\n\n\n\n\nSave it and run\n\n\n\n\nClick on the cog at the top right of the workflow canvas and \nSave\n.\n\n\n\n\n\n\n\n\n\n\nClick the cog again and choose \nRun\n.\n\n\n\n\n\n\nThis brings up a window where you specify the input datasets to use in the workflow.\n\n\n\n\nUnder \nStep1: Input dataset\n choose \nmutant_R1.fastq\n.\n\n\nUnder \nStep2: Input dataset\n choose \nmutant_R2.fastq\n.\n\n\n\n\n\n\n\n\nClick \nRun workflow\n.\n\n\n\n\n\n\nThis will run the workflow (spades) and save the output to the top of your current history in the right hand panel.\n\n\n\n\nView some of the output files with the eye icon to check that the workflow (in this case, just spades) ran correctly.\n\n\n\n\nAdd to the worfklow\n\n\nWe will add another tool to the workflow.\n\n\n\n\n\n\nGo to the top Galaxy panel and click \nWorkflow\n.\n\n\n\n\n\n\nYour workflow \nReads to Annotation\n should be in the list. Click on the drop-down arrow next to this workflow and choose \nEdit\n.\n\n\n\n\n\n\nThis will bring up the Workflow Canvas where we can add more inputs and tools.\n\n\n\n\n\n\nIn the Tools panel, click on \nNGS Annotation: Prokka\n. This will add a Prokka box to the workflow canvas.\n\n\n\n\n\n\nWe need to tell Prokka which genome assembly) to annotate. Join the spades output called \nout_contigs(fasta)\n to the Prokka input called \nContigs to annotate\n.\n\n\n\n\n\n\n\n\n\n\n\n\nClick on the Prokka box and change some of the settings in the right hand Details panel:\n\n\n\n\nSet the following parameters (leave everything else unchanged):\n\n\nLocus tag prefix (\nlocustag)\n: P\n\n\nForce GenBank/ENA/DDJB compliance (\ncompliant)\n: \nNo\n\n\nSequencing Centre ID (\ncentre)\n: V\n\n\nUse genus-specific BLAST database\n \nNo\n  \n\n\n\n\n\n\n\n\nClick on the cog to the top right of the workflow canvas to save.\n\n\n\n\n\n\nClick on the cog again to run.\n\n\n\n\nAgain, choose the input files: \nmutant_R1.fastq\n and \nmutant_R2.fastq\n, and then click \nRun workflow\n.\n\n\n\n\n\n\n\n\nThe output from the workflow (files from spades and prokka) will appear at the top of the History panel.\n\n\n\n\n\n\nClick on the eye icon for some files to verify the workflow ran correctly.      \n\n\n\n\n\n\nAdd more to the workflow\n\n\nWe will add a visualization tool to view the genome annotation.\n\n\n\n\n\n\nGo to the top Galaxy panel and click \nWorkflow\n.\n\n\n\n\n\n\nYour workflow \nReads to Annotation\n should be in the list. Click on the drop-down arrow next to this workflow and choose \nEdit\n.\n\n\n\n\n\n\nThis will bring up the Workflow Canvas where we can add more inputs and tools.\n\n\n\n\n\n\nIn the Tools panel, click on \nStatistics and Visualisation: Graph/Display Data: JBrowse\n. This will add a JBrowse box to the workflow canvas.\n\n\n\n\n\n\nClick on the JBrowse box. In the Details pane:\n\n\n\n\n\n\nUnder \nJBrowse-in-Galaxy Action\n choose \nNew JBrowse Instance\n.\n\n\n\n\n\n\nUnder \nReference genome to display\n choose \nUse a genome from history\n.\n\n\n\n\n\n\nFor \nProduce a Standalone Instance\n select \nYes\n.\n\n\n\n\n\n\nFor \nGenetic Code\n choose \n11: The Bacterial, Archaeal and Plant Plastid Code\n.\n\n\n\n\n\n\nClick \nInsert Track Group\n\n\n\n\n\n\nUnder \nTrack Category\n type in \ngene annotations\n.\n\n\n\n\n\n\nClick \nInsert Annotation Track\n\n\n\n\n\n\nFor \nTrack Type\n choose \nGFF/GFF3/BED/GBK Features\n\n\n\n\n\n\nUnder \nJBrowse Track Type[Advanced]\n select \nCanvas Features\n.\n\n\n\n\n\n\nClick on \nJBrowse Styling Options \n\n\n\n\n\n\nUnder \nJBrowse style.label\n correct the word \nprodcut\n to \nproduct\n.\n\n\n\n\n\n\nUnder \nTrack Visibility\n choose \nOn for new users\n.\n\n\n\n\n\n\n\n\n\n\nNow we need to tell JBrowse the input files to use.\n\n\n\n\n\n\nJoin the Prokka output \nout_fna (fasta)\n to the JBrowse input \nFasta sequences\n\n\n\n\n\n\nJoin the Prokka output \nout_gff (gff)\n to the JBrowse input \nTrack Group 1\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nClick on the cog to save; again to run; choose input files; \nRun workflow\n; examine output files in current history.\n\n\n\n\n\n\nThe workflow will now assemble and annotate the genome, and create a JBrowse view of the annotations.\n\n\n\n\n\n\nJBrowse will produce one output file.\n\n\n\n\nClick on the eye icon to view.\n\n\nIn the centre drop down box, choose contig 6.\n\n\nUnder \nAvailable Tracks\n on the left, tick the boxes.\n\n\nZoom in and out with the plus and minus icons.\n\n\nThe blue blocks are the genome annotations.\n\n\n\n\n\n\n\n\n\n\n\n\n\nSummary\n\n\n\n\n\n\nOur workflow is now:\n\n\n\n\nFastq\n sequence reads to Spades for assembly\n\n\nSpades \ncontigs fasta file\n to Prokka for annotation\n\n\nProkka \nfasta file\n and \n.gff file\n to JBrowse for visualisation.\n\n\n\n\n\n\n\n\nWe can re-run this workflow with different input Fastq files.\n\n\n\n\n\n\nOther workflow options\n\n\nSaving outputs\n\n\nTo save only some output files:\n\n\n\n\nGo to the workflow canvas.\n\n\nFind the star next to the outputs.\n\n\nClick on the star for any outputs you want to save.\n\n\n\n\n\n\nTo save these starred files from the workflow output as a new history:\n\n\n\n\nBefore you click \nRun workflow\n, tick the box above to \nSend results to a new history\n.\n\n\n\n\nImport a workflow\n\n\nTo import an existing Galaxy Workflow:\n\n\n\n\nGo to the Workflow tab in the top panel.\n\n\nAt the top right, click on \nUpload or import workflow\n.\n\n\n\n\nExtract a workflow\n\n\nYou can extract a workflow from an existing Galaxy history.\n\n\n\n\nGo to your Galaxy history\n\n\nClick on the History cog icon and choose \nExtract Workflow\n.\n\n\nGive it a name and click \nCreate Workflow\n.\n\n\nTo edit, go to the Workflow tab, select the workflow, and choose \nEdit\n from the drop down menu. You can then edit the steps on the Workflow Canvas.\n\n\n\n\nA note on workflow tabs\n\n\nWe have been using the top Workflow tab. There is another tab at the bottom of the tool panel called Workflows. Click on \nWorkflows: All Workflows\n. This gives a similar view with a list of workflows, and you can also click on the top right tab \nswitch to workflow management view\n.\n\n\nTo return to the main galaxy window click on the Analyze Data tab in the top panel.\n\n\nLinks\n\n\nIntroduction to workflows:\n\nhttps://wiki.galaxyproject.org/Learn/AdvancedWorkflow\n\n\nAnother tutorial on workflows:\n\nhttp://vlsci.github.io/lscc_docs/tutorials/galaxy-workflows/galaxy-workflows/\n\n\nGalaxy published workflows:\n\nhttps://usegalaxy.org/workflow/list_published", 
            "title": "Galaxy workflows"
        }, 
        {
            "location": "/modules/workflows/#galaxy-workflows", 
            "text": "This tutorial assumes you have used Galaxy before.  Although we can use tools in Galaxy to analyse data and create a history, there is also a way to create a workflow of files, tools, settings and outputs. You can then input different datasets and run the workflow.  This tutorial covers building a workflow to analyse a bacterial genome, from input Fastq sequencing reads to assembly, annotation, and visualization.", 
            "title": "Galaxy workflows"
        }, 
        {
            "location": "/modules/workflows/#start", 
            "text": "Go to your Galaxy instance and Register/Login.  Import a history of data files:   Click on the  History  cog   Select  Import from File  In the box called  Archived History URL , paste in this link address to the Galaxy history of input files:   https://swift.rc.nectar.org.au:8888/v1/AUTH_377/public/Microbial_tutorials/Galaxy_history_input_files.tar.gz   Click  Submit  Wait a few seconds.  Click on the  View all histories  button   See if the Galaxy history has been imported: it will be called  imported from archive: Data  Above that pane, click on the  Switch to  button.  Then click  Done  (in the top left corner).   You should now have a list of five files in your current history.    Re-name this history  Workflows .", 
            "title": "Start"
        }, 
        {
            "location": "/modules/workflows/#build-a-workflow", 
            "text": "We will first write a workflow for genome assembly.   In the top menu bar in Galaxy, click on  Workflow .     Click on  Create new workflow      Under  Workflow Name:  put in  Reads to Annotation .    Click  Create    This will bring up the  Workflow Canvas , a grid where you can arrange the workflow.", 
            "title": "Build a workflow"
        }, 
        {
            "location": "/modules/workflows/#add-inputs", 
            "text": "In the Tools panel, click  Inputs: Input datset  twice (at the very top of the list).    A box will appear: drag it to the left and there will be another box underneath it. Drag this also to the left. Your workflow canvas should look like this:      Click on the first box. Look in the right hand panel (now called  Details ) and change the name of the Input dataset to  R1.fastq . Press Enter for the change to be saved.     Repeat for the second input dataset box, naming that one  R2.fastq .", 
            "title": "Add inputs"
        }, 
        {
            "location": "/modules/workflows/#add-the-tool-spades", 
            "text": "In the tools panel, click on  NGS Analysis: NGS Assembly: spades .\nThis puts the spades box onto the workflow canvas.      Click on the spades box and look in the Details pane on the right. This shows all the options in spades. Choose:    Run only Assembly :  Yes  [the  Yes  button should be darker grey]   Kmers to use separated by commas:   33,55,91   [note: no spaces]    Coverage cutoff:   auto", 
            "title": "Add the tool \"spades\""
        }, 
        {
            "location": "/modules/workflows/#join-inputs-to-the-tool", 
            "text": "Now tell spades which input files to use.    Look at the input dataset box called  R1.fastq  and find the small arrow:     Click on this and drag the arrow over to the spades box input arrow   next to  Libraries 1   Files 1   Forward reads .      Repeat for the dataset box  R2.fastq , joining to the spades box next to  Libraries 1   Files 1   Reverse reads .", 
            "title": "Join inputs to the tool"
        }, 
        {
            "location": "/modules/workflows/#save-it-and-run", 
            "text": "Click on the cog at the top right of the workflow canvas and  Save .      Click the cog again and choose  Run .    This brings up a window where you specify the input datasets to use in the workflow.   Under  Step1: Input dataset  choose  mutant_R1.fastq .  Under  Step2: Input dataset  choose  mutant_R2.fastq .     Click  Run workflow .    This will run the workflow (spades) and save the output to the top of your current history in the right hand panel.   View some of the output files with the eye icon to check that the workflow (in this case, just spades) ran correctly.", 
            "title": "Save it and run"
        }, 
        {
            "location": "/modules/workflows/#add-to-the-worfklow", 
            "text": "We will add another tool to the workflow.    Go to the top Galaxy panel and click  Workflow .    Your workflow  Reads to Annotation  should be in the list. Click on the drop-down arrow next to this workflow and choose  Edit .    This will bring up the Workflow Canvas where we can add more inputs and tools.    In the Tools panel, click on  NGS Annotation: Prokka . This will add a Prokka box to the workflow canvas.    We need to tell Prokka which genome assembly) to annotate. Join the spades output called  out_contigs(fasta)  to the Prokka input called  Contigs to annotate .       Click on the Prokka box and change some of the settings in the right hand Details panel:   Set the following parameters (leave everything else unchanged):  Locus tag prefix ( locustag) : P  Force GenBank/ENA/DDJB compliance ( compliant) :  No  Sequencing Centre ID ( centre) : V  Use genus-specific BLAST database   No        Click on the cog to the top right of the workflow canvas to save.    Click on the cog again to run.   Again, choose the input files:  mutant_R1.fastq  and  mutant_R2.fastq , and then click  Run workflow .     The output from the workflow (files from spades and prokka) will appear at the top of the History panel.    Click on the eye icon for some files to verify the workflow ran correctly.", 
            "title": "Add to the worfklow"
        }, 
        {
            "location": "/modules/workflows/#add-more-to-the-workflow", 
            "text": "We will add a visualization tool to view the genome annotation.    Go to the top Galaxy panel and click  Workflow .    Your workflow  Reads to Annotation  should be in the list. Click on the drop-down arrow next to this workflow and choose  Edit .    This will bring up the Workflow Canvas where we can add more inputs and tools.    In the Tools panel, click on  Statistics and Visualisation: Graph/Display Data: JBrowse . This will add a JBrowse box to the workflow canvas.    Click on the JBrowse box. In the Details pane:    Under  JBrowse-in-Galaxy Action  choose  New JBrowse Instance .    Under  Reference genome to display  choose  Use a genome from history .    For  Produce a Standalone Instance  select  Yes .    For  Genetic Code  choose  11: The Bacterial, Archaeal and Plant Plastid Code .    Click  Insert Track Group    Under  Track Category  type in  gene annotations .    Click  Insert Annotation Track    For  Track Type  choose  GFF/GFF3/BED/GBK Features    Under  JBrowse Track Type[Advanced]  select  Canvas Features .    Click on  JBrowse Styling Options     Under  JBrowse style.label  correct the word  prodcut  to  product .    Under  Track Visibility  choose  On for new users .      Now we need to tell JBrowse the input files to use.    Join the Prokka output  out_fna (fasta)  to the JBrowse input  Fasta sequences    Join the Prokka output  out_gff (gff)  to the JBrowse input  Track Group 1         Click on the cog to save; again to run; choose input files;  Run workflow ; examine output files in current history.    The workflow will now assemble and annotate the genome, and create a JBrowse view of the annotations.    JBrowse will produce one output file.   Click on the eye icon to view.  In the centre drop down box, choose contig 6.  Under  Available Tracks  on the left, tick the boxes.  Zoom in and out with the plus and minus icons.  The blue blocks are the genome annotations.", 
            "title": "Add more to the workflow"
        }, 
        {
            "location": "/modules/workflows/#summary", 
            "text": "Our workflow is now:   Fastq  sequence reads to Spades for assembly  Spades  contigs fasta file  to Prokka for annotation  Prokka  fasta file  and  .gff file  to JBrowse for visualisation.     We can re-run this workflow with different input Fastq files.", 
            "title": "Summary"
        }, 
        {
            "location": "/modules/workflows/#other-workflow-options", 
            "text": "", 
            "title": "Other workflow options"
        }, 
        {
            "location": "/modules/workflows/#saving-outputs", 
            "text": "To save only some output files:   Go to the workflow canvas.  Find the star next to the outputs.  Click on the star for any outputs you want to save.    To save these starred files from the workflow output as a new history:   Before you click  Run workflow , tick the box above to  Send results to a new history .", 
            "title": "Saving outputs"
        }, 
        {
            "location": "/modules/workflows/#import-a-workflow", 
            "text": "To import an existing Galaxy Workflow:   Go to the Workflow tab in the top panel.  At the top right, click on  Upload or import workflow .", 
            "title": "Import a workflow"
        }, 
        {
            "location": "/modules/workflows/#extract-a-workflow", 
            "text": "You can extract a workflow from an existing Galaxy history.   Go to your Galaxy history  Click on the History cog icon and choose  Extract Workflow .  Give it a name and click  Create Workflow .  To edit, go to the Workflow tab, select the workflow, and choose  Edit  from the drop down menu. You can then edit the steps on the Workflow Canvas.", 
            "title": "Extract a workflow"
        }, 
        {
            "location": "/modules/workflows/#a-note-on-workflow-tabs", 
            "text": "We have been using the top Workflow tab. There is another tab at the bottom of the tool panel called Workflows. Click on  Workflows: All Workflows . This gives a similar view with a list of workflows, and you can also click on the top right tab  switch to workflow management view .  To return to the main galaxy window click on the Analyze Data tab in the top panel.", 
            "title": "A note on workflow tabs"
        }, 
        {
            "location": "/modules/workflows/#links", 
            "text": "Introduction to workflows: https://wiki.galaxyproject.org/Learn/AdvancedWorkflow  Another tutorial on workflows: http://vlsci.github.io/lscc_docs/tutorials/galaxy-workflows/galaxy-workflows/  Galaxy published workflows: https://usegalaxy.org/workflow/list_published", 
            "title": "Links"
        }, 
        {
            "location": "/modules/pacbio/", 
            "text": "Assembly with PacBio data and SMRT Portal\n\n\nKeywords: de novo assembly, PacBio, PacificBiosciences, HGAP, SMRT Portal, Microbial Genomics Virtual Laboratory\n\n\nThis tutorial will show you how to assemble a bacterial genome \nde novo\n, using the PacBio SMRT Portal on the mGVL. We will use an analysis pipeline called HGAP, the Hierarchical Genome Assembly Process.\n\n\n\n\n\n[How to get data =\n GVL]\n\n\nStart\n\n\n\n\nOpen your mGVL dashboard.\n\n\nYou should see SMRT Portal as one of the instance services on your GVL dashboard.\n\n\nOpen up the SMRT portal web link (to the right) and register/log on.\n\n\n\n\nInput\n\n\n\n\n\nWe will use a dataset from a \nStreptococcus pyogenes\n bacteria.\n\n\nIf this has already been loaded onto SMRT portal (e.g. for use during a workshop), proceed to the next step (\nAssembly\n).\n\n\nOtherwise:\n\n\n\n\nLoad the PacBio data (your own, or the training dataset) onto your GVL.\n\n\nIn the SMRT Portal, go to \nDesign Job\n, the top left tab.\n\n\nGo to \nImport and Manage\n.\n\n\n\nClick \nImport SMRT cells\n.\n\n\n\n\n\nWork out where you put the data on your GVL, and make sure the file path is showing.\n\n\n\n\nIf not, click \nAdd\n and enter the file path to the data.\n\n\nA SMRT cell is the collection of data from a particular cell in the machine. It includes .bax.h5 files.\n\n\n\n\n\n\n\n\nClick on the file path and then \nScan\n to check for new data.\n\n\n\n\n\n\nAssembly\n\n\nHGAP process overview\n\n\nWe will use the Hierarchical Genome Assembly Process (HGAP). This flowchart shows the steps in the process:\n\n\n\n\nSet up job\n\n\n\n\nIn the SMRT Portal, go to the top left tab, \nDesign Job\n.\n\n\nGo to \nCreate New\n.\n\n\nAn \nAnalysis\n window should appear. Tick all the boxes, then \nNext\n.\n\n\nUnder \nJob Name\n enter a name.\n\n\nTo the right, under \nGroups\n choose \nall\n.\n\n\nUnder \nProtocols\n choose \nRS_HGAP_Assembly.3\n.\n\n\nThere is an ellipsis underneath \nProtocols\n - click on the ellipsis.\n\n\n\n\n\n\nThis brings up the settings. Click on \nAssembly\n.\n\n\n\n\n\n\nFor \nCompute Minimum Seed Read Length\n: ensure box is ticked\n\n\n\n\n\n\n\nFor \nNumber of Seed Read Chunks\n: enter \n12\n\n\n\n\nChange the \nGenome Size\n to an approximately correct size for the species. For \nS. pyogenes\n, enter 1800000.\n\n\nFor \nTarget Coverage\n: enter \n10\n\n\nFor \nOverlapper Error Rate\n: enter \n0.04\n\n\nLeave all other settings as they are.\n\n\nClick \nApply\n\n\n\n\nYour protocol window should look like this:\n\n\n\n\n\n\n\n\nClick \nOk\n.  \n\n\n\n\n\n\nIn the \nSMRT Cells Available\n window, select the file to be used. Click on the arrow to transfer these files to the SMRT Cells in Job window.\n\n\n\n\nYou can drag the column widths of the \nUrl\n column so that you can see the URLs of the file paths better.\n\n\n\n\n\n\n\n\nClick \nSave\n (bottom right hand side).\n\n\nNext to \nSave\n, click \nStart\n.\n\n\nThe \nMonitor Jobs\n window should open.\n\n\nAs each step proceeds, new items will appear under the \nReports\n and \nData\n tabs on the left.\n\n\n\n\n\n\n\n\n\n\nInputs and Outputs\n\n\nThe connections between the names of assembly stages and outputs is not always clear. This flowchart shows how each stage of the HGAP process corresponds to protocol window names and outputs:\n\n\n\n\n\n\nResults\n\n\nIf the job is still running, click on the centre tab \nMonitor Jobs\n. Otherwise, click on the top right tab, \nView Data\n.\n\n\n\n\nDouble click on the job name to open its reports.\n\n\nClick on different \nReports\n in the left hand panel.\n\n\n\n\nThings to look at:\n\n\nGeneral: Filtering (polymerase reads)\n\n\n\n\nnumber of reads post-filter\n\n\nread length (=average)\n\n\n\n\nGeneral: Subread Filtering (subreads)\n\n\n\n\nnumber of reads post-filter\n\n\nread length (average)\n\n\n\n\nAssembly: Pre-Assembly (pre-assembled reads)\n\n\n\n\nlength cutoff (the computed minimum seed read length)\n\n\nread length (average)\n\n\n\n\nAssembly: Corrections\n\n\nConsensus calling results:\n\n\n\n\nConsensus concordance should be \n 99%.\n\n\n\n\nGraph: corrections across reference:\n\n\n\n\nWith the first run of polishing, we expect a lot of corrections but they should be randomly distributed.\n\n\n\n\nAssembly: Top Corrections\n\n\nThis is a list of all the corrections made.\n\n\n\n\n\nResequencing: Coverage\n\n\nCoverage across reference:\n\n\n\n\ndiscard contigs \n20X coverage\n\n\nothers should have fairly consistent coverage.\n\n\nspikes could be collapsed repeats.\n\n\nvalleys could be mis-assembly - e.g. draft assembly was incorrect and so remapped reads didn\nt support this part of the assembly.\n\n\n\n\nGraph: Depth of Coverage:\n\n\nNumber\n of reference regions vs coverage. \n\n\nAssembly: Polished Assembly\n\n\n\n\nnumber of contigs\n\n\nmax contig length\n\n\ngraph: confidence vs depth. multi-copy plasmids may have higher coverage.\n\n\n\n\n\n\n\nOutput\n\n\nThe polished assembly as a FASTA file.\n\n\n\n\ndownload to local computer; or\n\n\nopen file in (GVL) Galaxy; or\n\n\nopen file in GVL command line: and perform further analysis.\n\n\n\n\nCorrect with short reads\n\n\nIf you have Illumina reads for the same sample, the assembly can be further polished.\n\n\n\n\nDownload the FASTA assembly to your computer.\n\n\nOpen Galaxy\n\n\nUpload the FASTA assembly\n\n\nUpload the Illumina reads to galaxy\n\n\nchange datatype to fastqsanger\nngs mapping - map with bwa mem\n\n\n\n\nuse genome from history - the smrt portal fasta file\nR1 and R2 files\nexecute\nrefresh\n\n\n\n\n\n\nPolish with Pilon.\n\n\n\n\n\n\npilon\nuse a genome from history : the smrt portal fasta file\ninput bam file - from step above\nvariant calling mode - no\ncreate changes file - yes\nadvanced options:\npaired end : yes\nfix - select all\nmindepth 0.5\n\n\noutput = polished assembly\n\n\nNext\n\n\nFurther options:\n\n\n\n\ncircularise eg with circlator\n\n\ntrims off overhang\n\n\n\n\nthis would be best done before the pilon polishing step\n\n\n\n\n\n\nannotate the polished assembly\n\n\n\n\neg with Prokka\n\n\n\n\nLinks to more information\n\n\nPacBio \nE. coli\n data set\n\n\nHGAP overview\n\n\nA full ist of reports and terminology\n\n\nVideo overview of HGAP on SMRT portal\n\n\nMore about the SMRT bell template", 
            "title": "PacBio assembly with SMRT portal"
        }, 
        {
            "location": "/modules/pacbio/#assembly-with-pacbio-data-and-smrt-portal", 
            "text": "Keywords: de novo assembly, PacBio, PacificBiosciences, HGAP, SMRT Portal, Microbial Genomics Virtual Laboratory  This tutorial will show you how to assemble a bacterial genome  de novo , using the PacBio SMRT Portal on the mGVL. We will use an analysis pipeline called HGAP, the Hierarchical Genome Assembly Process.   [How to get data =  GVL]", 
            "title": "Assembly with PacBio data and SMRT Portal"
        }, 
        {
            "location": "/modules/pacbio/#start", 
            "text": "Open your mGVL dashboard.  You should see SMRT Portal as one of the instance services on your GVL dashboard.  Open up the SMRT portal web link (to the right) and register/log on.", 
            "title": "Start"
        }, 
        {
            "location": "/modules/pacbio/#input", 
            "text": "We will use a dataset from a  Streptococcus pyogenes  bacteria.  If this has already been loaded onto SMRT portal (e.g. for use during a workshop), proceed to the next step ( Assembly ).  Otherwise:   Load the PacBio data (your own, or the training dataset) onto your GVL.  In the SMRT Portal, go to  Design Job , the top left tab.  Go to  Import and Manage .  Click  Import SMRT cells .   Work out where you put the data on your GVL, and make sure the file path is showing.   If not, click  Add  and enter the file path to the data.  A SMRT cell is the collection of data from a particular cell in the machine. It includes .bax.h5 files.     Click on the file path and then  Scan  to check for new data.", 
            "title": "Input"
        }, 
        {
            "location": "/modules/pacbio/#assembly", 
            "text": "", 
            "title": "Assembly"
        }, 
        {
            "location": "/modules/pacbio/#hgap-process-overview", 
            "text": "We will use the Hierarchical Genome Assembly Process (HGAP). This flowchart shows the steps in the process:", 
            "title": "HGAP process overview"
        }, 
        {
            "location": "/modules/pacbio/#set-up-job", 
            "text": "In the SMRT Portal, go to the top left tab,  Design Job .  Go to  Create New .  An  Analysis  window should appear. Tick all the boxes, then  Next .  Under  Job Name  enter a name.  To the right, under  Groups  choose  all .  Under  Protocols  choose  RS_HGAP_Assembly.3 .  There is an ellipsis underneath  Protocols  - click on the ellipsis.    This brings up the settings. Click on  Assembly .    For  Compute Minimum Seed Read Length : ensure box is ticked    For  Number of Seed Read Chunks : enter  12   Change the  Genome Size  to an approximately correct size for the species. For  S. pyogenes , enter 1800000.  For  Target Coverage : enter  10  For  Overlapper Error Rate : enter  0.04  Leave all other settings as they are.  Click  Apply   Your protocol window should look like this:     Click  Ok .      In the  SMRT Cells Available  window, select the file to be used. Click on the arrow to transfer these files to the SMRT Cells in Job window.   You can drag the column widths of the  Url  column so that you can see the URLs of the file paths better.     Click  Save  (bottom right hand side).  Next to  Save , click  Start .  The  Monitor Jobs  window should open.  As each step proceeds, new items will appear under the  Reports  and  Data  tabs on the left.", 
            "title": "Set up job"
        }, 
        {
            "location": "/modules/pacbio/#inputs-and-outputs", 
            "text": "The connections between the names of assembly stages and outputs is not always clear. This flowchart shows how each stage of the HGAP process corresponds to protocol window names and outputs:", 
            "title": "Inputs and Outputs"
        }, 
        {
            "location": "/modules/pacbio/#results", 
            "text": "If the job is still running, click on the centre tab  Monitor Jobs . Otherwise, click on the top right tab,  View Data .   Double click on the job name to open its reports.  Click on different  Reports  in the left hand panel.   Things to look at:  General: Filtering (polymerase reads)   number of reads post-filter  read length (=average)   General: Subread Filtering (subreads)   number of reads post-filter  read length (average)   Assembly: Pre-Assembly (pre-assembled reads)   length cutoff (the computed minimum seed read length)  read length (average)   Assembly: Corrections  Consensus calling results:   Consensus concordance should be   99%.   Graph: corrections across reference:   With the first run of polishing, we expect a lot of corrections but they should be randomly distributed.   Assembly: Top Corrections  This is a list of all the corrections made.   Resequencing: Coverage  Coverage across reference:   discard contigs  20X coverage  others should have fairly consistent coverage.  spikes could be collapsed repeats.  valleys could be mis-assembly - e.g. draft assembly was incorrect and so remapped reads didn t support this part of the assembly.   Graph: Depth of Coverage:  Number  of reference regions vs coverage.   Assembly: Polished Assembly   number of contigs  max contig length  graph: confidence vs depth. multi-copy plasmids may have higher coverage.", 
            "title": "Results"
        }, 
        {
            "location": "/modules/pacbio/#output", 
            "text": "The polished assembly as a FASTA file.   download to local computer; or  open file in (GVL) Galaxy; or  open file in GVL command line: and perform further analysis.", 
            "title": "Output"
        }, 
        {
            "location": "/modules/pacbio/#correct-with-short-reads", 
            "text": "If you have Illumina reads for the same sample, the assembly can be further polished.   Download the FASTA assembly to your computer.  Open Galaxy  Upload the FASTA assembly  Upload the Illumina reads to galaxy  change datatype to fastqsanger\nngs mapping - map with bwa mem   use genome from history - the smrt portal fasta file\nR1 and R2 files\nexecute\nrefresh    Polish with Pilon.    pilon\nuse a genome from history : the smrt portal fasta file\ninput bam file - from step above\nvariant calling mode - no\ncreate changes file - yes\nadvanced options:\npaired end : yes\nfix - select all\nmindepth 0.5  output = polished assembly", 
            "title": "Correct with short reads"
        }, 
        {
            "location": "/modules/pacbio/#next", 
            "text": "Further options:   circularise eg with circlator  trims off overhang   this would be best done before the pilon polishing step    annotate the polished assembly   eg with Prokka", 
            "title": "Next"
        }, 
        {
            "location": "/modules/pacbio/#links-to-more-information", 
            "text": "PacBio  E. coli  data set  HGAP overview  A full ist of reports and terminology  Video overview of HGAP on SMRT portal  More about the SMRT bell template", 
            "title": "Links to more information"
        }, 
        {
            "location": "/modules/cmdline_assembly/", 
            "text": "Pacbio reads: assembly with command line tools\n\n\nKeywords: de novo assembly, PacBio, PacificBiosciences, Illumina, command line, Canu, Circlator, BWA, Spades, Pilon, Microbial Genomics Virtual Laboratory\n\n\nThis tutorial demonstrates how to use long Pacbio sequence reads to assemble a bacterial genome and plasmids, including correcting the assembly with short Illumina reads.\n\n\nLearning objectives\n\n\nAt the end of this tutorial, be able to use command line tools to produce a bacterial genome assembly using the following workflow:\n\n\n\n\nget data\n\n\nassemble long (Pacbio) reads\n\n\ntrim overhangs and circularise\n\n\nsearch for smaller plasmids\n\n\ncorrect with short (Illumina) reads\n\n\n\n\nOverview\n\n\nSimplified version of workflow:\n\n\n\n\nGet data\n\n\n\n\nOpen the mGVL command line\n\n\nNavigate to or create the directory in which you want to work.\ne.g.\n\n\n\n\nmkdir staph\ncd staph\n\n\n\n\nIf you already have the files ready, skip forward to next section, \nAssemble\n.\n\n\nFind the Pacbio files for this sample\n\n\n\n\nIf the files are already on your server, you can symlink by using\n\n\n\n\nln -s real_file_path chosen_symlink_name\n\n\n\n\n\n\nAlternatively, obtain the input files from elsewhere, e.g. from the BPA portal. (You will need a password.)\n\n\nPacbio files are often stored in the format: Sample_name/Cell_name/Analysis_Results/long_file_name_1.fastq.gz\n\n\nWe will use the \nlongfilename.subreads.fastq.gz\n files.\n\n\nThe reads are usually split into three separate files because they are so large.\n\n\nRight click on the first \nsubreads.fastq.gz\n file and \ncopy link address\n.\n\n\nIn the command line, type:\n\n\n\n\nwget --user username --password password [paste link URL for file]\n\n\n\n\n\n\nRepeat for the other two \nsubreads.fastq.gz\n files.\n\n\n\n\nJoin Pacbio fastq files\n\n\n\n\nIf the files are gzipped, type:\n\n\n\n\ncat filepath/filep0.*.subreads.fastq.gz \n subreads.fastq.gz\n\n\n\n\n\n\nIf the files are not gzipped, type:\n\n\n\n\ncat filepath/filep0.*.subreads.fastq | gzip \n subreads.fastq.gz\n\n\n\n\n\n\nWe now have a file called \nsubreads.fastq.gz\n.\n\n\n\n\nFind the Illumina files for this sample\n\n\n\n\nWe will also use 2 x Illumina (Miseq) fastq.gz files.\n\n\nThese are the \nR1.fastq.gz\n and \nR2.fastq.gz\n files.\n\n\nRight click on the file name and \ncopy link address\n.\n\n\nIn the command line, type:\n\n\n\n\nwget --user username --password password [paste link URL for file]\n\n\n\n\n\n\nRepeat for the other read.fastq.gz file.\n\n\nShorten the name of each of these files:\n\n\n\n\nmv longfilename_R1.fastq.gz R1.fastq.gz\nmv longfilename_R2.fastq.gz R2.fastq.gz\n\n\n\n\nView files\n\n\n\n\nType \nls\n to display the folder contents.\n\n\n\n\nls\n\n\n\n\n\n\nThe 3 files we will use in this analysis are:\n\n\nsubreads.fastq.gz\n (the Pacbio reads)\n\n\nR1.fastq.gz\n and \nR2.fastq.gz\n (the Illumina reads)\n\n\n\n\n\n\n\n\n\n\n\n\n\nIn this tutorial we will use \nStaphylococcus aureus\n sample 25745.\n\n\n\n\nAssemble\n\n\n\n\nWe will use the assembly software called \nCanu\n.\n\n\nRun Canu with these commands:\n\n\n\n\ncanu -p staph -d output genomeSize=2.8m -pacbio-raw subreads.fastq\n\n\n\n\n\n\nstaph\n is the prefix given to output files\n\n\noutput\n is the name of the output directory\n\n\ngenomeSize\n only has to be approximate.\n\n\ne.g. \nStaphylococcus aureus\n, 2.8m\n\n\ne.g. \nStreptococcus pyogenes\n, 1.8m\n\n\n\n\n\n\n\n\nthe \nreads\n can be unzipped or .gz\n\n\n\n\n\n\nCanu will correct, trim and assemble the reads.\n\n\n\n\nThis will take ~ 30 minutes.\n\n\n\n\nCheck the output\n\n\ncd output\n\n\n\n\n\n\nThe \nstaph.contigs.fasta\n are the assembled sequences.\n\n\nThe \nstaph.unassembled.fasta\n are the reads that could not be assembled.\n\n\nThe \nstaph.correctedReads.fasta.gz\n are the corrected Pacbio reads that were used in the assembly.\n\n\nThe \nstaph.file.gfa\n is the graph of the assembly.\n\n\nDisplay summary information about the contigs:\n\n\n\n\ninfoseq staph.contigs.fasta\n\n\n\n\n\n\n\n\n(infoseq is a tool from \nEMBOSS\n)\n\n\n\n\n\n\nThis will show the number of contigs, e.g.\n\n\n\n\n\n\n    - tig00000000   dna 2746242\n    - tig00000001   dna 48500\n\n\n\n\nChange Canu parameters if required\n\n\n\n\nIf the assembly is poor with many contigs, re-run Canu with extra sensitivity parameters; e.g.\n\n\n\n\ncanu -p prefix -d outdir corMhapSensitivity=high corMinCoverage=0 genomeSize=2.8m -pacbio-raw subreads.fastq\n\n\n\n\nTrim and circularise\n\n\nRun Circlator\n\n\nCirclator identifies and trims overhangs (on chromosomes and plasmids) and orients the start position at an appropriate gene (e.g. dnaA). It takes in the assembled contigs from Canu, as well as the corrected reads prepared by Canu.\n\n\nTo run:\n\n\ncirclator all --threads 8 --verbose --b2r_length_cutoff 20000 ../staph.contigs.fasta ../staph.corrected.reads.fastq.gz circlator_all_output\n\n\n\n\n\n\nthreads\n is the number of cores\n\n\nverbose\n prints progress information to the screen\n\n\nb2r_length_cutoff\n using approximately 2X average read length (could be omitted at first; if all contigs don\nt circularise, include this option to see if any improvement)\n\n\n../staph.contigs.fasta\n is the file path to the input multi-fasta assembly\n\n\n../staph.corrected.reads.fastq.gz\n is the file path to the corrected Pacbio reads\n\n\ncirclator_all_output\n is the name of the output directory.\n\n\n\n\nCheck the output: were the contigs circularised:\n\n\nless 04.merge.circularise.log\n\n\n\n\nWhere were the contigs oriented (which gene):\n\n\nless 06.fixstart.log\n\n\n\n\nWhat are the trimmed contig sizes:\n\n\ninfoseq 06.fixstart.fasta\n\n\n\n\nThe trimmed contigs are in the file called \n06.fixstart.fasta\n. Re-name it \ncontig_1_2.fa\n:\n\n\nmv 06.fixstart.fasta contig_1_2.fa\n\n\n\n\nFind smaller plasmids\n\n\nPacbio reads are long, and may have been longer than small plasmids. We will look for any small plasmids using the Illumina reads.\n\n\nThis section involves several steps:\n\n\n\n\nUse the multifasta canu-circlator output of trimmed assembly contigs.\n\n\nMap all the Illumina reads against these Pacbio assembled contigs.\n\n\nExtract any reads that \ndidn\nt\n map and assemble them together: this could be a plasmid, or part of a plasmid.\n\n\nLook for overhang: if found, trim. If not, continue:\n\n\nSearch Genbank for any matching proteins: a replication protein found.  \n\n\nAssemble all the Illumina reads and produce an assembly graph.\n\n\nSearch the graph for a match to the replication protein and its adjoining regions.\n\n\nExtract this longer sequence from the Illumina assembly: this is the small plasmid.\n\n\nCheck for overhang in this plasmid and trim.\n\n\n\n\nAlign Illumina with BWA\n\n\n\n\nAlign illumina reads to these contigs\n\n\nFirst, index the contigs file\n\n\n\n\nbwa index contig_1_2.fa\n\n\n\n\n\n\nthen, align using bwa mem\n\n\n\n\nbwa mem -t 8 contig_1_2.fa R1.fastq.gz R2.fastq.gz | samtools sort \n aln.bam\n\n\n\n\n\n\nbwa mem\n is the alignment tool\n\n\n-t 8\n is the number of cores\n\n\ncontig_1_2.fa\n is the input assembly file\n\n\nR1.fastq.gz R2.fastq.gz\n are the Illumina reads\n\n\n | samtools sort\n pipes the output to samtools to sort\n\n\n aln.bam\n sends the alignment to the file \naln.bam\n\n\n\n\nExtract unmapped Illumina reads\n\n\n\n\nIndex the alignment file\n\n\n\n\nsamtools index aln.bam\n\n\n\n\n\n\nextract the fastq files from the bam alignment - those reads that were unmapped to the Pacbio alignment - and save them in various \nunmapped\n files:\n\n\n\n\nsamtools fastq -f 4 -1 unmapped.R1.fastq -2 unmapped.R2.fastq -s unmapped.RS.fastq aln.bam\n\n\n\n\n\n\nfastq\n is a command that coverts a \n.bam\n file into fastq format\n\n\n-f 4\n : only output unmapped reads\n\n\n-1\n : put R1 reads into a file called \nunmapped.R1.fastq\n\n\n-2\n : put R2 reads into a file called \nunmapped.R2.fastq\n\n\n-s\n : put singleton reads into a file called \nunmapped.RS.fastq\n\n\naln.bam\n : input alignment file\n\n\n\n\nWe now have three files of the unampped reads:\n\n\n\n\n unmapped.R1.fastq\n\n\n unmapped.R2.fastq\n\n\n unmapped.RS.fastq\n\n\n\n\nAssemble the unmapped reads\n\n\n\n\nassemble with spades\n\n\n\n\nspades.py -1 unmapped.R1.fastq -2 unmapped.R2.fastq -s unmapped.RS.fastq --careful --cov-cutoff auto -o spades_assembly\n\n\n\n\n\n\n-1\n is input file forward\n\n\n-2\n is input file reverse\n\n\n-s\n is unpaired\n\n\n careful\n : minimizes mismatches and short indels\n\n\n cov-cutoff auto\n : computes the coverage threshold (rather than the default setting, \noff\n)\n\n\n-o\n is the output directory\n\n\n\n\ncd spades_assembly\ninfoseq contigs.fasta\n\n\n\n\n\n\nshows how many assembled:\n\n\ne.g. no=135\n\n\nmax = 2229\n\n\n\n\n\n\nsort fasta by size of seqs:\n\n\n\n\nsizeseq\ninput sequence set: contigs.fasta\nreturn longest sequence first [N]: Y\noutput sequence(s) [contigs.fasta]: sorted_contigs.fasta\n\n\n\n\nPrint the first row of each seq to see coverage:\n\n\ngrep cov sorted_contigs.fasta  \n\n\n\n\n\n\nresult: NODE_1_length_2229_cov_610.583\n\n\nlongest contig is 2229 and high coverage\n\n\n\n\n\n\nall the nodes are listed\n\n\nsee if any other nodes have high coverage\n\n\ne.g. NODE_135_length_78_cov_579\n\n\n\n\n\n\nlook at the sequence of this contig:\n\n\n\n\ntail sorted_contigs.fasta\n\n\n\n\n\n\nThis is a homopolymer, so disregard.\n\n\nWe will extract the first sequence (NODE_1):\n\n\n\n\nsamtools faidx sorted_contigs.fasta\nsamtools faidx sorted_contigs.fasta NODE_1_length_2229_cov_610.583 \n contig3.fa\n\n\n\n\n\n\nthis is now saved as \ncontig3.fa\n\n\nopen this file in nano, make the header \ncontig3\n, save.\n\n\n\n\nInvestigate the small plasmid (contig3)\n\n\n\n\nBlast the start of contig3 against itself\n\n\nTake the start of the contig:\n\n\n\n\nhead -n 10 contig3.fa \n contig3.fa.head\n\n\n\n\n\n\nWe want to see if it matches the end (overhang)\n\n\nFormat the assembly file for blast:\n\n\n\n\nmakeblastdb -in contig3.fa -dbtype nucl\n\n\n\n\n\n\nblast the start of the assembly (.head file) against all of the assembly:\n\n\n\n\nblastn -query contig3.fa.head -db contig3.fa -evalue 1e-3 -dust no -out contig3.bls\n\n\n\n\n\n\nlook at \ncontig3.bls\n to see hits:\n\n\n\n\nless contig3.bls\n\n\n\n\n\n\nthe first hit is against itself, as expected\n\n\nthere are no few further hits, so we assume there is no overhang that needs trimming.\n\n\nhowever, the sequence is likely then to be longer than this.\n\n\n\n\nless contig3.fa\n\n\n\n\n\n\nCopy the sequence\n\n\nGo to NCBI: \nhttps://blast.ncbi.nlm.nih.gov/Blast.cgi\n; choose blastx\n\n\nPaste the sequence from contig3.fa\n\n\nChoose genetic code = 11\n\n\nBlast\n\n\n\nThis hits a replication (plasmid) protein. Hypothesise that   this is a small plasmid; search for the entire sequence within the assembly of all the Illumina reads (next step).\n\n\n\n\nAssemble \nall\n the illumina reads\n\n\n\n\nAssemble all the Illumina reads with spades (not just those reads that did not map to the Pacbio assembly).\n\n\n\n\nspades.py -1 R1.fastq -2 R2.fastq --careful --cov-cutoff auto -o spades_assembly_all_illumina\n\n\n\n\n\n\n\nNavigate to the output:\n\n\ncd spades_assembly_all_illumina\n\n\n\n\n\n\nin here is the \nassembly_graph.fastg\n\n\nTransfer this file to your local computer (e.g. using the file transfer program \nCyberduck\n).\n\n\nExamine the assembly in the program \nBandage\n.\n\n\nFile: Load graph: \nassembly_graph.fastg\n\n\nIn the left hand panel, click \nDraw graph\n\n\nYour assembly graph may look like this:\n\n\n\n\n\n\n\n\n\nBlast the small plasmid sequence in this assembly\n\n\n\n\nIn the left hand panel: Blast: create/view BLAST search\n\n\nBuild blast database\n\n\nPaste in the sequence of contig3\n\n\nBlast\n\n\nThe main hit is around node 10.\n\n\n\n\n\n\n\n\nGo to the main Bandage window\n\n\n\n\nfind nodes\n in right hand panel - 10\n\n\nThis node is slightly longer: 2373: this could be the plasmid\n\n\nExtract this node in fasta format: In the top panel, go to Output: Save selected node sequences; save as \ncontig3b.fa\n\n\nOpen this file in nano and change the header to \ncontig3b\n, save.\n\n\n\n\n\n\n\n\nTrim small plasmid\n\n\n\n\nTake the start of the sequence and see if it matches the end:\n\n\n\n\nhead -n 10 contig3b.fa \n contig3b.fa.head\nmakeblastdb -in contig3b.fa -dbtype nucl\nblastn -query contig3b.fa.head -db contig3b.fa -evalue 1e-3 -dust no -out contig3b.bls\nless contig3b.bls\n\n\n\n\n\n\nThe first hit is against the start of the chromosome, as expected.\n\n\nThe last hit starts at position 2253; we will trim the plasmid to position 2252\n\n\nIndex the contig3b.fa file:\n\n\n\n\nsamtools faidx contig3b.fa\n\n\n\n\n\n\nTrim:\n\n\n\n\nsamtools faidx contig3b.fa contig3b:1-2252 \n contig3b.fa.trimmed\n\n\n\n\n\n\nOpen this file in nano and change the header to \ncontig3b\n, save.\n\n\nWe now have a trimmed contig3b.\n\n\n\n\nCollect all contigs in one file\n\n\ncat contig_1_2.fa contig3b.fa.trimmed \n all_contigs.fa\n\n\n\n\n\n\nSee the three contigs and sizes:\n\n\n\n\ninfoseq all_contigs.fa\n\n\n\n\nCorrect\n\n\nWe will correct the Pacbio assembly with Illumina reads.\n\n\n\n\n\nAlign the Illumina reads (R1 and R2) to the draft PacBio assembly, e.g. \ncontigs.fasta\n:\n\n\nbwa index contigs.fasta\nbwa mem -t 32 contigs.fasta R1.fastq.gz R2.fastq.gz | samtools sort \n aln.bam\nsamtools index aln.bam\nsamtools faidx contigs.fasta\n\n\n\n\n\n\n-t\n is the number of cores (e.g. 8)\n\n\nto find out how many you have, grep -c processor /proc/cpuinfo\n\n\n\n\n\n\nnow we have an alignment file to use in pilon: \naln.bam\n\n\n\n\nLook at how the illumina reads are aligned:\n\n\nsamtools tview -p contig1 aln.bam contigs.fasta\n\n\n\n\nnote: \ncontig1\n is the name of the contig to view; e.g. tig00000000.\n\n\nRun pilon:\n\n\npilon --genome contigs.fa --frags aln.bam --output pilon1 --fix all --mindepth 0.5 --changes --verbose\n\n\n\n\n\n\ngenome\n is the name of the input assembly to be corrected\n\n\nfrags\n is the alignment of the reads against the assembly\n\n\noutput\n is the name of the output prefix\n\n\nfix\n is an option for types of corrections\n\n\nmindepth\n gives a minimum read depth to use\n\n\nchanges\n produces an output file of the changes made\n\n\nverbose\n prints information to the screen during the run\n\n\nif you are using pilon on a different machine and you want to specify the number of CPUs, type in \nthreads\n number (e.g. 32).\n\n\n\n\nLook at the changes file:\n\n\nless pilon1.changes\n\n\n\n\n\n\n\nLook at the fasta file:\n\n\nless pilon1.fasta\n\n\n\n\nLook at the details of the fasta file:\n\n\ninfoseq pilon1.fasta\n\n\n\n\nIf there are more than 2 changes, run Pilon again, using the pilon1.fasta file as the input assembly, and the Illumina reads to correct.\n\n\nFinal output:\n\n\n\n\nthe corrected genome assembly of \nStaphylococcus aureus\n in .fasta format, containing three contigs: chromosome, large plasmid and small plasmid.  \n\n\n\n\nNext\n\n\nFurther analyses:\n\n\n\n\nAnnotate with Prokka.\n\n\nComparative genomics, e.g. with Roary.\n\n\n\n\nLinks:\n\n\n\n\nDetails of bas.h5 files\n\n\nCanu \nmanual\n and \ngitub repository\n\n\nCirclator \narticle\n and \ngithub repository\n\n\nPilon \narticle\n and \ngithub repository\n\n\nNotes on \nfinishing\n and \nevaluating\n assemblies.", 
            "title": "PacBio assembly with command line tools"
        }, 
        {
            "location": "/modules/cmdline_assembly/#pacbio-reads-assembly-with-command-line-tools", 
            "text": "Keywords: de novo assembly, PacBio, PacificBiosciences, Illumina, command line, Canu, Circlator, BWA, Spades, Pilon, Microbial Genomics Virtual Laboratory  This tutorial demonstrates how to use long Pacbio sequence reads to assemble a bacterial genome and plasmids, including correcting the assembly with short Illumina reads.", 
            "title": "Pacbio reads: assembly with command line tools"
        }, 
        {
            "location": "/modules/cmdline_assembly/#learning-objectives", 
            "text": "At the end of this tutorial, be able to use command line tools to produce a bacterial genome assembly using the following workflow:   get data  assemble long (Pacbio) reads  trim overhangs and circularise  search for smaller plasmids  correct with short (Illumina) reads", 
            "title": "Learning objectives"
        }, 
        {
            "location": "/modules/cmdline_assembly/#overview", 
            "text": "Simplified version of workflow:", 
            "title": "Overview"
        }, 
        {
            "location": "/modules/cmdline_assembly/#get-data", 
            "text": "Open the mGVL command line  Navigate to or create the directory in which you want to work.\ne.g.   mkdir staph\ncd staph  If you already have the files ready, skip forward to next section,  Assemble .", 
            "title": "Get data"
        }, 
        {
            "location": "/modules/cmdline_assembly/#find-the-pacbio-files-for-this-sample", 
            "text": "If the files are already on your server, you can symlink by using   ln -s real_file_path chosen_symlink_name   Alternatively, obtain the input files from elsewhere, e.g. from the BPA portal. (You will need a password.)  Pacbio files are often stored in the format: Sample_name/Cell_name/Analysis_Results/long_file_name_1.fastq.gz  We will use the  longfilename.subreads.fastq.gz  files.  The reads are usually split into three separate files because they are so large.  Right click on the first  subreads.fastq.gz  file and  copy link address .  In the command line, type:   wget --user username --password password [paste link URL for file]   Repeat for the other two  subreads.fastq.gz  files.", 
            "title": "Find the Pacbio files for this sample"
        }, 
        {
            "location": "/modules/cmdline_assembly/#join-pacbio-fastq-files", 
            "text": "If the files are gzipped, type:   cat filepath/filep0.*.subreads.fastq.gz   subreads.fastq.gz   If the files are not gzipped, type:   cat filepath/filep0.*.subreads.fastq | gzip   subreads.fastq.gz   We now have a file called  subreads.fastq.gz .", 
            "title": "Join Pacbio fastq files"
        }, 
        {
            "location": "/modules/cmdline_assembly/#find-the-illumina-files-for-this-sample", 
            "text": "We will also use 2 x Illumina (Miseq) fastq.gz files.  These are the  R1.fastq.gz  and  R2.fastq.gz  files.  Right click on the file name and  copy link address .  In the command line, type:   wget --user username --password password [paste link URL for file]   Repeat for the other read.fastq.gz file.  Shorten the name of each of these files:   mv longfilename_R1.fastq.gz R1.fastq.gz\nmv longfilename_R2.fastq.gz R2.fastq.gz", 
            "title": "Find the Illumina files for this sample"
        }, 
        {
            "location": "/modules/cmdline_assembly/#view-files", 
            "text": "Type  ls  to display the folder contents.   ls   The 3 files we will use in this analysis are:  subreads.fastq.gz  (the Pacbio reads)  R1.fastq.gz  and  R2.fastq.gz  (the Illumina reads)       In this tutorial we will use  Staphylococcus aureus  sample 25745.", 
            "title": "View files"
        }, 
        {
            "location": "/modules/cmdline_assembly/#assemble", 
            "text": "We will use the assembly software called  Canu .  Run Canu with these commands:   canu -p staph -d output genomeSize=2.8m -pacbio-raw subreads.fastq   staph  is the prefix given to output files  output  is the name of the output directory  genomeSize  only has to be approximate.  e.g.  Staphylococcus aureus , 2.8m  e.g.  Streptococcus pyogenes , 1.8m     the  reads  can be unzipped or .gz    Canu will correct, trim and assemble the reads.   This will take ~ 30 minutes.", 
            "title": "Assemble"
        }, 
        {
            "location": "/modules/cmdline_assembly/#check-the-output", 
            "text": "cd output   The  staph.contigs.fasta  are the assembled sequences.  The  staph.unassembled.fasta  are the reads that could not be assembled.  The  staph.correctedReads.fasta.gz  are the corrected Pacbio reads that were used in the assembly.  The  staph.file.gfa  is the graph of the assembly.  Display summary information about the contigs:   infoseq staph.contigs.fasta    (infoseq is a tool from  EMBOSS )    This will show the number of contigs, e.g.        - tig00000000   dna 2746242\n    - tig00000001   dna 48500", 
            "title": "Check the output"
        }, 
        {
            "location": "/modules/cmdline_assembly/#change-canu-parameters-if-required", 
            "text": "If the assembly is poor with many contigs, re-run Canu with extra sensitivity parameters; e.g.   canu -p prefix -d outdir corMhapSensitivity=high corMinCoverage=0 genomeSize=2.8m -pacbio-raw subreads.fastq", 
            "title": "Change Canu parameters if required"
        }, 
        {
            "location": "/modules/cmdline_assembly/#trim-and-circularise", 
            "text": "", 
            "title": "Trim and circularise"
        }, 
        {
            "location": "/modules/cmdline_assembly/#run-circlator", 
            "text": "Circlator identifies and trims overhangs (on chromosomes and plasmids) and orients the start position at an appropriate gene (e.g. dnaA). It takes in the assembled contigs from Canu, as well as the corrected reads prepared by Canu.  To run:  circlator all --threads 8 --verbose --b2r_length_cutoff 20000 ../staph.contigs.fasta ../staph.corrected.reads.fastq.gz circlator_all_output   threads  is the number of cores  verbose  prints progress information to the screen  b2r_length_cutoff  using approximately 2X average read length (could be omitted at first; if all contigs don t circularise, include this option to see if any improvement)  ../staph.contigs.fasta  is the file path to the input multi-fasta assembly  ../staph.corrected.reads.fastq.gz  is the file path to the corrected Pacbio reads  circlator_all_output  is the name of the output directory.   Check the output: were the contigs circularised:  less 04.merge.circularise.log  Where were the contigs oriented (which gene):  less 06.fixstart.log  What are the trimmed contig sizes:  infoseq 06.fixstart.fasta  The trimmed contigs are in the file called  06.fixstart.fasta . Re-name it  contig_1_2.fa :  mv 06.fixstart.fasta contig_1_2.fa", 
            "title": "Run Circlator"
        }, 
        {
            "location": "/modules/cmdline_assembly/#find-smaller-plasmids", 
            "text": "Pacbio reads are long, and may have been longer than small plasmids. We will look for any small plasmids using the Illumina reads.  This section involves several steps:   Use the multifasta canu-circlator output of trimmed assembly contigs.  Map all the Illumina reads against these Pacbio assembled contigs.  Extract any reads that  didn t  map and assemble them together: this could be a plasmid, or part of a plasmid.  Look for overhang: if found, trim. If not, continue:  Search Genbank for any matching proteins: a replication protein found.    Assemble all the Illumina reads and produce an assembly graph.  Search the graph for a match to the replication protein and its adjoining regions.  Extract this longer sequence from the Illumina assembly: this is the small plasmid.  Check for overhang in this plasmid and trim.", 
            "title": "Find smaller plasmids"
        }, 
        {
            "location": "/modules/cmdline_assembly/#align-illumina-with-bwa", 
            "text": "Align illumina reads to these contigs  First, index the contigs file   bwa index contig_1_2.fa   then, align using bwa mem   bwa mem -t 8 contig_1_2.fa R1.fastq.gz R2.fastq.gz | samtools sort   aln.bam   bwa mem  is the alignment tool  -t 8  is the number of cores  contig_1_2.fa  is the input assembly file  R1.fastq.gz R2.fastq.gz  are the Illumina reads   | samtools sort  pipes the output to samtools to sort   aln.bam  sends the alignment to the file  aln.bam", 
            "title": "Align Illumina with BWA"
        }, 
        {
            "location": "/modules/cmdline_assembly/#extract-unmapped-illumina-reads", 
            "text": "Index the alignment file   samtools index aln.bam   extract the fastq files from the bam alignment - those reads that were unmapped to the Pacbio alignment - and save them in various  unmapped  files:   samtools fastq -f 4 -1 unmapped.R1.fastq -2 unmapped.R2.fastq -s unmapped.RS.fastq aln.bam   fastq  is a command that coverts a  .bam  file into fastq format  -f 4  : only output unmapped reads  -1  : put R1 reads into a file called  unmapped.R1.fastq  -2  : put R2 reads into a file called  unmapped.R2.fastq  -s  : put singleton reads into a file called  unmapped.RS.fastq  aln.bam  : input alignment file   We now have three files of the unampped reads:    unmapped.R1.fastq   unmapped.R2.fastq   unmapped.RS.fastq", 
            "title": "Extract unmapped Illumina reads"
        }, 
        {
            "location": "/modules/cmdline_assembly/#assemble-the-unmapped-reads", 
            "text": "assemble with spades   spades.py -1 unmapped.R1.fastq -2 unmapped.R2.fastq -s unmapped.RS.fastq --careful --cov-cutoff auto -o spades_assembly   -1  is input file forward  -2  is input file reverse  -s  is unpaired   careful  : minimizes mismatches and short indels   cov-cutoff auto  : computes the coverage threshold (rather than the default setting,  off )  -o  is the output directory   cd spades_assembly\ninfoseq contigs.fasta   shows how many assembled:  e.g. no=135  max = 2229    sort fasta by size of seqs:   sizeseq\ninput sequence set: contigs.fasta\nreturn longest sequence first [N]: Y\noutput sequence(s) [contigs.fasta]: sorted_contigs.fasta  Print the first row of each seq to see coverage:  grep cov sorted_contigs.fasta     result: NODE_1_length_2229_cov_610.583  longest contig is 2229 and high coverage    all the nodes are listed  see if any other nodes have high coverage  e.g. NODE_135_length_78_cov_579    look at the sequence of this contig:   tail sorted_contigs.fasta   This is a homopolymer, so disregard.  We will extract the first sequence (NODE_1):   samtools faidx sorted_contigs.fasta\nsamtools faidx sorted_contigs.fasta NODE_1_length_2229_cov_610.583   contig3.fa   this is now saved as  contig3.fa  open this file in nano, make the header  contig3 , save.", 
            "title": "Assemble the unmapped reads"
        }, 
        {
            "location": "/modules/cmdline_assembly/#investigate-the-small-plasmid-contig3", 
            "text": "Blast the start of contig3 against itself  Take the start of the contig:   head -n 10 contig3.fa   contig3.fa.head   We want to see if it matches the end (overhang)  Format the assembly file for blast:   makeblastdb -in contig3.fa -dbtype nucl   blast the start of the assembly (.head file) against all of the assembly:   blastn -query contig3.fa.head -db contig3.fa -evalue 1e-3 -dust no -out contig3.bls   look at  contig3.bls  to see hits:   less contig3.bls   the first hit is against itself, as expected  there are no few further hits, so we assume there is no overhang that needs trimming.  however, the sequence is likely then to be longer than this.   less contig3.fa   Copy the sequence  Go to NCBI:  https://blast.ncbi.nlm.nih.gov/Blast.cgi ; choose blastx  Paste the sequence from contig3.fa  Choose genetic code = 11  Blast  This hits a replication (plasmid) protein. Hypothesise that   this is a small plasmid; search for the entire sequence within the assembly of all the Illumina reads (next step).", 
            "title": "Investigate the small plasmid (contig3)"
        }, 
        {
            "location": "/modules/cmdline_assembly/#assemble-all-the-illumina-reads", 
            "text": "Assemble all the Illumina reads with spades (not just those reads that did not map to the Pacbio assembly).   spades.py -1 R1.fastq -2 R2.fastq --careful --cov-cutoff auto -o spades_assembly_all_illumina   Navigate to the output:  cd spades_assembly_all_illumina   in here is the  assembly_graph.fastg  Transfer this file to your local computer (e.g. using the file transfer program  Cyberduck ).  Examine the assembly in the program  Bandage .  File: Load graph:  assembly_graph.fastg  In the left hand panel, click  Draw graph  Your assembly graph may look like this:     Blast the small plasmid sequence in this assembly   In the left hand panel: Blast: create/view BLAST search  Build blast database  Paste in the sequence of contig3  Blast  The main hit is around node 10.     Go to the main Bandage window   find nodes  in right hand panel - 10  This node is slightly longer: 2373: this could be the plasmid  Extract this node in fasta format: In the top panel, go to Output: Save selected node sequences; save as  contig3b.fa  Open this file in nano and change the header to  contig3b , save.", 
            "title": "Assemble all the illumina reads"
        }, 
        {
            "location": "/modules/cmdline_assembly/#trim-small-plasmid", 
            "text": "Take the start of the sequence and see if it matches the end:   head -n 10 contig3b.fa   contig3b.fa.head\nmakeblastdb -in contig3b.fa -dbtype nucl\nblastn -query contig3b.fa.head -db contig3b.fa -evalue 1e-3 -dust no -out contig3b.bls\nless contig3b.bls   The first hit is against the start of the chromosome, as expected.  The last hit starts at position 2253; we will trim the plasmid to position 2252  Index the contig3b.fa file:   samtools faidx contig3b.fa   Trim:   samtools faidx contig3b.fa contig3b:1-2252   contig3b.fa.trimmed   Open this file in nano and change the header to  contig3b , save.  We now have a trimmed contig3b.", 
            "title": "Trim small plasmid"
        }, 
        {
            "location": "/modules/cmdline_assembly/#collect-all-contigs-in-one-file", 
            "text": "cat contig_1_2.fa contig3b.fa.trimmed   all_contigs.fa   See the three contigs and sizes:   infoseq all_contigs.fa", 
            "title": "Collect all contigs in one file"
        }, 
        {
            "location": "/modules/cmdline_assembly/#correct", 
            "text": "We will correct the Pacbio assembly with Illumina reads.   Align the Illumina reads (R1 and R2) to the draft PacBio assembly, e.g.  contigs.fasta :  bwa index contigs.fasta\nbwa mem -t 32 contigs.fasta R1.fastq.gz R2.fastq.gz | samtools sort   aln.bam\nsamtools index aln.bam\nsamtools faidx contigs.fasta   -t  is the number of cores (e.g. 8)  to find out how many you have, grep -c processor /proc/cpuinfo    now we have an alignment file to use in pilon:  aln.bam   Look at how the illumina reads are aligned:  samtools tview -p contig1 aln.bam contigs.fasta  note:  contig1  is the name of the contig to view; e.g. tig00000000.  Run pilon:  pilon --genome contigs.fa --frags aln.bam --output pilon1 --fix all --mindepth 0.5 --changes --verbose   genome  is the name of the input assembly to be corrected  frags  is the alignment of the reads against the assembly  output  is the name of the output prefix  fix  is an option for types of corrections  mindepth  gives a minimum read depth to use  changes  produces an output file of the changes made  verbose  prints information to the screen during the run  if you are using pilon on a different machine and you want to specify the number of CPUs, type in  threads  number (e.g. 32).   Look at the changes file:  less pilon1.changes   Look at the fasta file:  less pilon1.fasta  Look at the details of the fasta file:  infoseq pilon1.fasta  If there are more than 2 changes, run Pilon again, using the pilon1.fasta file as the input assembly, and the Illumina reads to correct.  Final output:   the corrected genome assembly of  Staphylococcus aureus  in .fasta format, containing three contigs: chromosome, large plasmid and small plasmid.", 
            "title": "Correct"
        }, 
        {
            "location": "/modules/cmdline_assembly/#next", 
            "text": "Further analyses:   Annotate with Prokka.  Comparative genomics, e.g. with Roary.   Links:   Details of bas.h5 files  Canu  manual  and  gitub repository  Circlator  article  and  github repository  Pilon  article  and  github repository  Notes on  finishing  and  evaluating  assemblies.", 
            "title": "Next"
        }, 
        {
            "location": "/modules/dge/", 
            "text": "Differential Gene Expression\n\n\nKeywords: differential gene expression, DGE, RNA, RNA-Seq, transcriptomics, Degust, voom, limma, Galaxy, Microbial Genomics Virtual Laboratory.\n\n\nThis tutorial is about differential gene expression in bacteria, using Galaxy tools and Degust (web).\n\n\n\n\n\nBackground\n\n\nDifferential Gene Expression (DGE) is the process of determining whether any genes were expressed at a different level between two conditions. For example, the conditions could be wildtype versus mutant, or two growth conditions. Usually multiple biological replicates are done for each condition - these are needed to separate variation within the condition from that between the conditions.\n\n\nLearning Objectives\n\n\nAt the end of this tutorial you should be able to:\n\n\n\n\nAlign RNA-Seq data to a reference genome  \n\n\nCount transcripts for each sample\n\n\nPerform statistical analysis to obtain a list of differentially expressed genes\n\n\nVisualize and interpret the results\n\n\n\n\nInput data: reads and reference\n\n\nRNA-Seq reads\n\n\nA typical experiment will have 2 conditions each with 3 replicates, for a total of 6 samples.\n\n\n\n\nOur RNA-seq reads are from 6 samples in \nFASTQ\n format.\n\n\nWe have single-end reads; so one file per sample.\n\n\nData could also be paired-end reads, and there would be two files per sample.\n\n\n\n\n\n\nThese have been reduced to 1% of their original size for this tutorial.\n\n\nThe experiment used the bacteria \nE. coli\n grown in two conditions.\n\n\nFiles labelled \nLB\n are the wildtype\n\n\nFiles labelled \nMG\n have been exposed to 0.5% \nMG - alpha methyglucoside (a sugar solution).\n\n\n\n\n\n\n\n\n\n\n\nReference genome\n\n\nThe reference genomes is in \nFASTA\n format and the gene annotations are in \nGTF\n format.\n\n\n\n\nThe \nFASTA\n file contains the DNA sequence(s) that make up the genome; e.g. the chromosome and any plasmids.\n\n\nThe \nGTF\n file lists the coordinates (position) of each feature. Commonly-annotated features are genes, transcripts and protein-coding sequences.\n\n\n\n\n\n\n\nUpload files to Galaxy\n\n\n\n\nLog in to your Galaxy server.\n\n\nIn the \nHistory\n pane, click on the cog\nicon, and select \nImport from File\n (at the bottom of the list).\n\n\nUnder \nArchived History URL\n paste:\n\nhttps://swift.rc.nectar.org.au:8888/v1/AUTH_377/public/Microbial_tutorials/Galaxy-History-BacterialDGE.tar.gz\n\n\nIn the \nHistory\n pane, click on the view\nicon and find the uploaded history.\n\n\n(This may take a minute. Refresh the page.)\n\n\n\n\n\n\nClick \nSwitch to\n that history, then \nDone\n.\n\n\nThe files should now be ready to use in your current History pane.\n\n\n\n\n\n\nAlign reads to reference\n\n\nThe RNA-Seq reads are fragmented and are not complete transcripts. To determine the transcripts from which the reads originated (and therefore, to which gene they correspond) we can map them to a reference genome.\n\n\nIn Galaxy:\n\n\n\n\nGo to \nTools \n NGS Analysis \n NGS: Mapping \n Map with BWA-MEM\n\n\nUnder \nWill you select a reference genome from your history or use a built-in index?\n: \nUse a genome from history and build index\n\n\nUse the following dataset as the reference sequence\n: \nEcoli_k12.fasta\n\n\nSingle or Paired-end reads\n: \nsingle\n\n\nSelect fastq dataset\n:\n\n\nClick on the \nMultiple Datasets\n icon in centre\n\n\nSelect all 6 \nFASTQ\n files (they turn blue; use side-scroll bar to check all have been selected)\n\n\nThis will map each set of reads to the reference genome\n\n\n\n\n\n\n\n\nYour tool interface should look like this:\n\n\n\n\n\n\nClick \nExecute\n\n\nClick \nRefresh\n in the history pane to see if the analysis has finished.\n\n\n\n\nOutput: 6 \nbam\n files of reads mapped to the reference genome.\n\n\n\n\n\n\nRe-name the output files:\n\n\n\n\nThese are called \nMap with BWA-MEM on data x and data x\n.\n\n\nClick on the pencil icon next to each of these and re-name them as their sample name (e.g. LB1, LB2 etc.).\n\n\nClick \nSave\n.\n\n\n\n\n\n\n\n\nCount reads per gene\n\n\nWe now need to count how many reads overlap with particular genes. The information about gene names is from the annotations in the GTF file.\n\n\nIn Galaxy:\n\n\n\n\nGo to \nTools \n NGS Analysis \n NGS: RNA Analysis \n SAM/BAM to count matrix\n.\n\n\nNote: Don\nt select the tool called \nhtseq-count\n. The \nSAM/BAM to count matrix\n also uses that tool but allows an input of multiple bam files, which is what we want.\n\n\n\n\n\n\nFor \nGene model (GFF) file to count reads over from your current history\n, select the \nGTF\n file.\n\n\nFor \nReads are stranded\n select \nYes\n (box turns dark grey)\n\n\nFor \nGTF feature type for counting reads\n select \ntranscript\n.\n\n\nFor \nbam/sam file from your history\n choose the 6 \nbam\n files.\n\n\n\n\nYour tool interface should look like this:\n\n\n\n\n\n\nClick \nExecute\n\n\nClick \nRefresh\n in the history pane to see if the analysis has finished.\n\n\n\n\nOutput:\n\n\n\n\nThere is one output file: \nbams to DGE count matrix\n.\n\n\nClick on the file name to expand the information in the History pane.\n\n\nClick on the file \nicon underneath to download it to your computer for use later on in this tutorial.\n\n\nClick on the eye icon to see this file.\n\n\n\n\n\n\n\n\nEach row is a gene (or feature) and each column is a sample, with counts against each gene.\n\n\nHave a look at how the counts vary between samples, per gene.\n\n\nWe can\nt just compare the counts directly; they need to be normalized before comparison, and this will be done as part of the DGE analysis in the next step.\n\n\n\n\nDGE in Degust\n\n\nDegust is a tool on the web that can analyse the counts files produced in the step above, to test for differential gene expression.\n\n\n(Degust can also display the results from DGE analyses performed elsewhere.)\n\n\nUpload counts file\n\n\nGo to the \nDegust web page\n. Click \nGet Started\n.\n\n\n\n\n\n\nClick on \nChoose File\n.\n\n\nSelect the \nhtseq output file. tabular\n (that you previously downloaded to your computer from Galaxy) and click \nOpen\n.\n\n\nClick \nUpload\n.\n\n\n\n\nA Configuation page will appear.\n\n\n\n\nFor \nName\n type \nDGE in E coli\n\n\nFor \nInfo columns\n select \nContig\n\n\nFor \nAnalyze server side\n leave box checked.\n\n\nFor \nMin read count\n put \n10\n.\n\n\nClick \nAdd condition\n\n\nAdd a condition called \nControl\n and select the LB columns.\n\n\nAdd a condition called \nTreament\n and select the MG columns.\n\n\n\n\n\n\n\n\nYour Configuration page should look like this:\n\n\n\n\n\n\nSave changes\n\n\nView\n - this brings up the Degust viewing window.\n\n\n\n\nOverview of Degust sections\n\n\n\n\nTop black panel with \nConfigure\n settings at right.\n\n\nLeft: Conditions: Control and Treatment.\n\n\nLeft: Method selection for DGE.\n\n\nTop centre: Plots, with options at right.\n\n\nWhen either of the expression plots are selected, a heatmap appears below.\n\n\nA table of genes (or features); expression in treatment relative to control (Treatment column); and significance (FDR column).  \n\n\n\n\n\n\nAnalyze gene expression\n\n\n\n\nUnder \nMethod\n, make sure that \nVoom/Limma\n is selected.\n\n\nClick \nApply\n. This runs Voom/Limma on the uploaded counts.\n\n\n\n\nMDS plot\n\n\nFirst, look at the MDS plot.\n\n\n\n\n\n\nThis is a multidimensional scaling plot which represents the variation between samples.\n\n\nIdeally:\n\n\nAll the LB samples would be close to each other\n\n\nAll the MG samples would be close to each other\n\n\nThe LB and MG groups would be far apart\n\n\n\n\n\n\nThe x-axis is the dimension with the highest magnitude. The control/treatment samples should be split along this axis.\n\n\nOur LB samples are on the left and the MG samples are on the right, which means they are well separated on their major MDS dimension, which looks correct.\n\n\n\n\nExpression - MA plot\n\n\nEach dot shows the change in expression in one gene.\n\n\n\n\nThe average expression (over both condition and treatment samples) is represented on the x-axis.\n\n\nPlot points should be symmetrical around the x-axis.\n\n\nWe can see that many genes are expressed at a low level, and some are highly expressed.\n\n\n\n\n\n\nThe fold change is represented on the y axis.\n\n\nIf expression is significantly different between treatment and control, the dots are red. If not, they are blue. (In Degust, significant means FDR \n0.05).\n\n\nAt low levels of gene expression (low values of the x axis), fold changes are less likely to be significant.\n\n\n\n\n\n\n\n\nClick on the dot to see the gene name.     \n\n\n\n\nExpression - Parallel Coordinates and heatmap\n\n\nEach line shows the change in expression in one gene, between control and treatment.\n\n\n\n\nGo to \nOptions\n at the right.\n\n\nFor \nFDR cut-off\n set at 0.001.\n\n\nThis is a significance level (an adjusted p value). We will set it quite low in this example, to ensure we only examine key differences.\n\n\n\n\n\n\n\n\nLook at the Parallel Coordinates plot. There are two axes:\n\n\n\n\nLeft: \nControl\n: Gene expression in the control samples. All values are set at zero.\n\n\nRight: \nTreatment\n Gene expression in the treatment samples, relative to expression in the control.\n\n\n\n\n\n\n\n\nThe blocks of blue and red underneath the plot are called a heatmap.\n\n\n\n\nEach block is a gene. Click on a block to see its line in the plot above.\n\n\nLook at the row for the Treatment. Relative to the control, genes expressed more are red; genes expressed less are blue.\n\n\n\n\n\n\n\n\n\n\nNote:\n\n\n\n\nfor an experiment with multiple treatments, the various treatment axes can be dragged to rearrange. There is no natural order (such as a time series).\n\n\n\n\nTable of genes\n\n\n\n\nContig\n: names of genes. Note that gene names are sometimes specific to a species, or they may be only named as a locus ID (a chromosomal location specified in the genome annotation).\n\n\nFDR\n: False Discovery Rate. This is an adjusted p value to show the significance of the difference in gene expression between two conditions. Click on column headings to sort. By default, this table is sorted by FDR.\n\n\nControl\n and \nTreatment\n: log2(Fold Change) of gene expression. The default display is of fold change in the treatment relative to the control. Therefore, values in the \nControl\n column are zero. This can be changed in the \nOptions\n panel at the top right.\n\n\nIn some cases, a large fold change will be meaningful but in others, even a small fold change can be important biologically.\n\n\n\n\nTable of genes and expression:\n\n\n\n\n\n\n\nDGE in Galaxy\n\n\nDifferential gene expression can also be analyzed in Galaxy. The input is the count matrix produced by a tool such as HTSeq-Count (see section above: \nCount reads per gene\n).\n\n\n\n\nGo to \nTools \n NGS Analysis \n NGS: RNA Analysis \n Differential Count models\n\n\nThis has options to use edgeR, DESeq, or Voom. Here we will use Voom.\n\n\n\n\n\n\nFor \nSelect an input matrix\n choose the \ncount matrix\n file generated in the previous step.\n\n\nFor \nTitle for job outputs\n enter \nDGE using voom\n.\n\n\nFor \nSelect columns containing treatment\n tick boxes for the MG samples.\n\n\nFor \nSelect columns containing control\n tick boxes for the LB samples.\n\n\nUnder \nRun this model using edgeR\n choose \nDo not run edgeR\n.\n\n\nUnder \nRun the same model with DESeq2 and compare findings\n choose \nDo not run DESeq2\n.\n\n\nUnder \nRun the same model with Voom/limma and compare findings\n choose \nRun VOOM\n.\n\n\n\n\nYour tool interface should look like this:\n\n\n\n\n\n\nClick \nExecute\n.\n\n\n\n\nThere are two output files.\n\n\nView the file called \nDGEusingvoom.html\n.\n\n\n\n\nScroll down to \nVOOM log output\n and \n#VOOM top 50\n.\n\n\nThe \nContig\n column has the gene names.\n\n\nLook at the \nadj.P.Val\n column. This is an adjusted p value to show the significance of the gene expression difference, accounting for the effect of multiple testing. Also known as False Discovery Rate. The table is ordered by the values in this column.\n\n\nLook at the \nlogFC\n column. This is log2(Fold Change) of relative gene expression between the treatment samples and the control samples.\n\n\n\n\nView the file called \nDEGusingvoom_topTable_VOOM.xls\n.\n\n\n\n\nThis is a list of all the genes that had transcripts mapped, and associated statistics.\n\n\n\n\nWhat next?\n\n\nTo learn more about the differentially-expressed genes:\n\n\n\n\nGo to \nthe NCBI website.\n\n\nUnder \nAll Databases\n, click on \nGene\n\n\nEnter the gene name in the search bar; e.g. ptsG\n\n\nClick on the first result that matches the species (e.g. in this case, \nE. coli\n).\n\n\nThis provides information about the gene, and may also show further references (e.g. in this case, a link to the EcoGene resource).\n\n\n\n\n\n\n\n\nSome of the most (statistically) significant differentially-expressed genes in this experiment are:\n\n\n\n\nptsG\n: a glucose-specific transporter.\n\n\nsetA\n: a sugar efflux transporter; is induced by glucose-phosphate stress.\n\n\nsucD\n: the alpha subunit of the the gene for succinyl-CoA synthetase; involved in ATP production.\n\n\nsucB\n: a component of the 2-oxoglutarate dehydrogenase complex; catalyzes a step in the Krebs cycle.\n\n\ndeoC\n: 2-deoxyribose-5-phosphate aldolase; binds selenium; may be involved in selenium transport.\n\n\n\n\nNext steps: Investigate the biochemical pathways involving the genes of interest.\n\n\nMore information\n\n\n\n\nLink to Degust.\n\n\nLink to Voom paper.", 
            "title": "Differential gene expression"
        }, 
        {
            "location": "/modules/dge/#differential-gene-expression", 
            "text": "Keywords: differential gene expression, DGE, RNA, RNA-Seq, transcriptomics, Degust, voom, limma, Galaxy, Microbial Genomics Virtual Laboratory.  This tutorial is about differential gene expression in bacteria, using Galaxy tools and Degust (web).", 
            "title": "Differential Gene Expression"
        }, 
        {
            "location": "/modules/dge/#background", 
            "text": "Differential Gene Expression (DGE) is the process of determining whether any genes were expressed at a different level between two conditions. For example, the conditions could be wildtype versus mutant, or two growth conditions. Usually multiple biological replicates are done for each condition - these are needed to separate variation within the condition from that between the conditions.", 
            "title": "Background"
        }, 
        {
            "location": "/modules/dge/#learning-objectives", 
            "text": "At the end of this tutorial you should be able to:   Align RNA-Seq data to a reference genome    Count transcripts for each sample  Perform statistical analysis to obtain a list of differentially expressed genes  Visualize and interpret the results", 
            "title": "Learning Objectives"
        }, 
        {
            "location": "/modules/dge/#input-data-reads-and-reference", 
            "text": "RNA-Seq reads  A typical experiment will have 2 conditions each with 3 replicates, for a total of 6 samples.   Our RNA-seq reads are from 6 samples in  FASTQ  format.  We have single-end reads; so one file per sample.  Data could also be paired-end reads, and there would be two files per sample.    These have been reduced to 1% of their original size for this tutorial.  The experiment used the bacteria  E. coli  grown in two conditions.  Files labelled  LB  are the wildtype  Files labelled  MG  have been exposed to 0.5%  MG - alpha methyglucoside (a sugar solution).      Reference genome  The reference genomes is in  FASTA  format and the gene annotations are in  GTF  format.   The  FASTA  file contains the DNA sequence(s) that make up the genome; e.g. the chromosome and any plasmids.  The  GTF  file lists the coordinates (position) of each feature. Commonly-annotated features are genes, transcripts and protein-coding sequences.    Upload files to Galaxy   Log in to your Galaxy server.  In the  History  pane, click on the cog icon, and select  Import from File  (at the bottom of the list).  Under  Archived History URL  paste: https://swift.rc.nectar.org.au:8888/v1/AUTH_377/public/Microbial_tutorials/Galaxy-History-BacterialDGE.tar.gz  In the  History  pane, click on the view icon and find the uploaded history.  (This may take a minute. Refresh the page.)    Click  Switch to  that history, then  Done .  The files should now be ready to use in your current History pane.", 
            "title": "Input data: reads and reference"
        }, 
        {
            "location": "/modules/dge/#align-reads-to-reference", 
            "text": "The RNA-Seq reads are fragmented and are not complete transcripts. To determine the transcripts from which the reads originated (and therefore, to which gene they correspond) we can map them to a reference genome.  In Galaxy:   Go to  Tools   NGS Analysis   NGS: Mapping   Map with BWA-MEM  Under  Will you select a reference genome from your history or use a built-in index? :  Use a genome from history and build index  Use the following dataset as the reference sequence :  Ecoli_k12.fasta  Single or Paired-end reads :  single  Select fastq dataset :  Click on the  Multiple Datasets  icon in centre  Select all 6  FASTQ  files (they turn blue; use side-scroll bar to check all have been selected)  This will map each set of reads to the reference genome     Your tool interface should look like this:    Click  Execute  Click  Refresh  in the history pane to see if the analysis has finished.   Output: 6  bam  files of reads mapped to the reference genome.    Re-name the output files:   These are called  Map with BWA-MEM on data x and data x .  Click on the pencil icon next to each of these and re-name them as their sample name (e.g. LB1, LB2 etc.).  Click  Save .", 
            "title": "Align reads to reference"
        }, 
        {
            "location": "/modules/dge/#count-reads-per-gene", 
            "text": "We now need to count how many reads overlap with particular genes. The information about gene names is from the annotations in the GTF file.  In Galaxy:   Go to  Tools   NGS Analysis   NGS: RNA Analysis   SAM/BAM to count matrix .  Note: Don t select the tool called  htseq-count . The  SAM/BAM to count matrix  also uses that tool but allows an input of multiple bam files, which is what we want.    For  Gene model (GFF) file to count reads over from your current history , select the  GTF  file.  For  Reads are stranded  select  Yes  (box turns dark grey)  For  GTF feature type for counting reads  select  transcript .  For  bam/sam file from your history  choose the 6  bam  files.   Your tool interface should look like this:    Click  Execute  Click  Refresh  in the history pane to see if the analysis has finished.   Output:   There is one output file:  bams to DGE count matrix .  Click on the file name to expand the information in the History pane.  Click on the file  icon underneath to download it to your computer for use later on in this tutorial.  Click on the eye icon to see this file.     Each row is a gene (or feature) and each column is a sample, with counts against each gene.  Have a look at how the counts vary between samples, per gene.  We can t just compare the counts directly; they need to be normalized before comparison, and this will be done as part of the DGE analysis in the next step.", 
            "title": "Count reads per gene"
        }, 
        {
            "location": "/modules/dge/#dge-in-degust", 
            "text": "Degust is a tool on the web that can analyse the counts files produced in the step above, to test for differential gene expression.  (Degust can also display the results from DGE analyses performed elsewhere.)", 
            "title": "DGE in Degust"
        }, 
        {
            "location": "/modules/dge/#upload-counts-file", 
            "text": "Go to the  Degust web page . Click  Get Started .    Click on  Choose File .  Select the  htseq output file. tabular  (that you previously downloaded to your computer from Galaxy) and click  Open .  Click  Upload .   A Configuation page will appear.   For  Name  type  DGE in E coli  For  Info columns  select  Contig  For  Analyze server side  leave box checked.  For  Min read count  put  10 .  Click  Add condition  Add a condition called  Control  and select the LB columns.  Add a condition called  Treament  and select the MG columns.     Your Configuration page should look like this:    Save changes  View  - this brings up the Degust viewing window.", 
            "title": "Upload counts file"
        }, 
        {
            "location": "/modules/dge/#overview-of-degust-sections", 
            "text": "Top black panel with  Configure  settings at right.  Left: Conditions: Control and Treatment.  Left: Method selection for DGE.  Top centre: Plots, with options at right.  When either of the expression plots are selected, a heatmap appears below.  A table of genes (or features); expression in treatment relative to control (Treatment column); and significance (FDR column).", 
            "title": "Overview of Degust sections"
        }, 
        {
            "location": "/modules/dge/#analyze-gene-expression", 
            "text": "Under  Method , make sure that  Voom/Limma  is selected.  Click  Apply . This runs Voom/Limma on the uploaded counts.", 
            "title": "Analyze gene expression"
        }, 
        {
            "location": "/modules/dge/#mds-plot", 
            "text": "First, look at the MDS plot.    This is a multidimensional scaling plot which represents the variation between samples.  Ideally:  All the LB samples would be close to each other  All the MG samples would be close to each other  The LB and MG groups would be far apart    The x-axis is the dimension with the highest magnitude. The control/treatment samples should be split along this axis.  Our LB samples are on the left and the MG samples are on the right, which means they are well separated on their major MDS dimension, which looks correct.", 
            "title": "MDS plot"
        }, 
        {
            "location": "/modules/dge/#expression-ma-plot", 
            "text": "Each dot shows the change in expression in one gene.   The average expression (over both condition and treatment samples) is represented on the x-axis.  Plot points should be symmetrical around the x-axis.  We can see that many genes are expressed at a low level, and some are highly expressed.    The fold change is represented on the y axis.  If expression is significantly different between treatment and control, the dots are red. If not, they are blue. (In Degust, significant means FDR  0.05).  At low levels of gene expression (low values of the x axis), fold changes are less likely to be significant.     Click on the dot to see the gene name.", 
            "title": "Expression - MA plot"
        }, 
        {
            "location": "/modules/dge/#expression-parallel-coordinates-and-heatmap", 
            "text": "Each line shows the change in expression in one gene, between control and treatment.   Go to  Options  at the right.  For  FDR cut-off  set at 0.001.  This is a significance level (an adjusted p value). We will set it quite low in this example, to ensure we only examine key differences.     Look at the Parallel Coordinates plot. There are two axes:   Left:  Control : Gene expression in the control samples. All values are set at zero.  Right:  Treatment  Gene expression in the treatment samples, relative to expression in the control.     The blocks of blue and red underneath the plot are called a heatmap.   Each block is a gene. Click on a block to see its line in the plot above.  Look at the row for the Treatment. Relative to the control, genes expressed more are red; genes expressed less are blue.      Note:   for an experiment with multiple treatments, the various treatment axes can be dragged to rearrange. There is no natural order (such as a time series).", 
            "title": "Expression - Parallel Coordinates and heatmap"
        }, 
        {
            "location": "/modules/dge/#table-of-genes", 
            "text": "Contig : names of genes. Note that gene names are sometimes specific to a species, or they may be only named as a locus ID (a chromosomal location specified in the genome annotation).  FDR : False Discovery Rate. This is an adjusted p value to show the significance of the difference in gene expression between two conditions. Click on column headings to sort. By default, this table is sorted by FDR.  Control  and  Treatment : log2(Fold Change) of gene expression. The default display is of fold change in the treatment relative to the control. Therefore, values in the  Control  column are zero. This can be changed in the  Options  panel at the top right.  In some cases, a large fold change will be meaningful but in others, even a small fold change can be important biologically.   Table of genes and expression:", 
            "title": "Table of genes"
        }, 
        {
            "location": "/modules/dge/#dge-in-galaxy", 
            "text": "Differential gene expression can also be analyzed in Galaxy. The input is the count matrix produced by a tool such as HTSeq-Count (see section above:  Count reads per gene ).   Go to  Tools   NGS Analysis   NGS: RNA Analysis   Differential Count models  This has options to use edgeR, DESeq, or Voom. Here we will use Voom.    For  Select an input matrix  choose the  count matrix  file generated in the previous step.  For  Title for job outputs  enter  DGE using voom .  For  Select columns containing treatment  tick boxes for the MG samples.  For  Select columns containing control  tick boxes for the LB samples.  Under  Run this model using edgeR  choose  Do not run edgeR .  Under  Run the same model with DESeq2 and compare findings  choose  Do not run DESeq2 .  Under  Run the same model with Voom/limma and compare findings  choose  Run VOOM .   Your tool interface should look like this:    Click  Execute .   There are two output files.  View the file called  DGEusingvoom.html .   Scroll down to  VOOM log output  and  #VOOM top 50 .  The  Contig  column has the gene names.  Look at the  adj.P.Val  column. This is an adjusted p value to show the significance of the gene expression difference, accounting for the effect of multiple testing. Also known as False Discovery Rate. The table is ordered by the values in this column.  Look at the  logFC  column. This is log2(Fold Change) of relative gene expression between the treatment samples and the control samples.   View the file called  DEGusingvoom_topTable_VOOM.xls .   This is a list of all the genes that had transcripts mapped, and associated statistics.", 
            "title": "DGE in Galaxy"
        }, 
        {
            "location": "/modules/dge/#what-next", 
            "text": "To learn more about the differentially-expressed genes:   Go to  the NCBI website.  Under  All Databases , click on  Gene  Enter the gene name in the search bar; e.g. ptsG  Click on the first result that matches the species (e.g. in this case,  E. coli ).  This provides information about the gene, and may also show further references (e.g. in this case, a link to the EcoGene resource).     Some of the most (statistically) significant differentially-expressed genes in this experiment are:   ptsG : a glucose-specific transporter.  setA : a sugar efflux transporter; is induced by glucose-phosphate stress.  sucD : the alpha subunit of the the gene for succinyl-CoA synthetase; involved in ATP production.  sucB : a component of the 2-oxoglutarate dehydrogenase complex; catalyzes a step in the Krebs cycle.  deoC : 2-deoxyribose-5-phosphate aldolase; binds selenium; may be involved in selenium transport.   Next steps: Investigate the biochemical pathways involving the genes of interest.", 
            "title": "What next?"
        }, 
        {
            "location": "/modules/dge/#more-information", 
            "text": "Link to Degust.  Link to Voom paper.", 
            "title": "More information"
        }, 
        {
            "location": "/modules/xtandem/", 
            "text": "Protein identification using X!Tandem\n\n\nIntroduction\n\n\nThe high-throughput nature of proteomics mass spectrometry is enabled by a productive combination of data acquisition protocols and the computational tools used to interpret the resulting spectra (list of peaks). One of the key components in mainstream protocols is the generation of tandem mass (MS/MS) spectra by peptide fragmentation. This approach is currently used in the large majority of proteomics experiments to routinely identify hundreds to thousands of proteins from single mass spectrometry runs. In order to do that multiple tools have to be employed: \nLC-MS/MS\n to segregate components of proteomic samples associated with \nprotein identification\n (see \nFigure 1\n) softwares, \nX!Tandem\n[^xtand], \nMascot\n or \nSEQUEST\n all of which perform protein identification but with different algorithms.\n\n\n\n\n\n\nFigure 1\n \n \nGeneral overview of the experimental steps and flow of data in protein identification using shotgun proteomics experiment.\n[^figure1].\n\n\n\n\nFigure 1\n shows a general overview of the experimental steps in protein identification. Sample proteins are first cleaved into peptides, which are then separated using chromatography (e.g. HPLC). The peptides are then ionised and then selected ions are fragmented to produce signature tandem mass spectrometry (MS/MS) spectra. Peptides are identified from the MS/MS spectra by using programs such as X!Tandem, which search against a database of known peptides. Sequences of the identified peptides are used to infer which proteins are present in the original sample.\n\n\nBackground\n\n\nLC-MS/MS Analysis\n\n\nLiquid Chromatography\n (LC) is a technique used to separate molecules in the solvent (mobile phase). Nowadays liquid chromatography utilising high pressure to force the solvent through the columns packed with porous particles (stationary phase) is referred as High Pressure Liquid Chromatography (HPLC) \n see \nFigure 2\n. After purifying the proteomic cell content, LC is able to separate the different proteins which are injected in the mass spectrometer. Each peak from the results will be analysed by mass spectrometry.\n\n\n\n\n\n\nFigure 2\n \n \nSchema of High Pressure Liquid Chromatography (HPLC)[^figure3].\n Compounds of the mixture are separated in the HPLC column according to various parameters (polarity, charge, affinity etc). The type of separation depends on the column being used). A detector flow cell is used to detect the separated compounds band.\n\n\n\n\nMass spectrometry\n (MS) \n see \nFigure 3\n \n has been widely used to analyse biological samples and has evolved into an indispensable tool for proteomics research. Fundamentally, MS measures the mass-to-charge ratio (m/z) of gas-phase ions. Mass spectrometers consist of an ion source that converts analyte molecules into gas-phase ions, a mass analyser that separates ionised analytes on the basis of m/z ratio and a detector that records the number of ions at each m/z value.\n\n\n\n\n\n\nFigure 3\n \n \nSchema of mass specter\n. \nA mass spectrometer consists of three components: an ion source, a mass analyzer, and a detector. The ionizer converts a portion of the sample into ions. There is a wide variety of ionization techniques, depending on the phase (solid, liquid, gas) of the sample and the efficiency of various ionization mechanisms for the unknown species. An extraction system removes ions from the sample, which are then targeted through the mass analyzer and onto the detector. The differences in masses of the fragments allows the mass analyzer to sort the ions by their mass-to-charge ratio. The detector measures the value of an indicator quantity and thus provides data for calculating the abundances of each ion present.\n [^figure4]\n\n\n\n\nTandem mass spectrometry\n (MS/MS) \n see \nFigure 4\n \n is a key technique for protein or peptide sequencing and post-translational modifications analysis. Collision-induced dissociation (CID) has been the most widely used MS/MS technique in proteomics research. In this method, gas-phase peptide/protein cations are internally heated by multiple collisions with rare gas atoms. The result is fragmented ions that, after the detection phase and reconstitution, reveal the amino-acid chains.\n\n\n\n\n\n\nFigure 4\n \n \nSchema of a tandem mass spectrometry associated with liquid chromatography (LC-MS/MS)\n. This technique combine separation form liquid chromatography and m/z ratio analyse of the tandem mass spectrometry in order to generate spectra.\n\n\n\n\nFile formats\n : During a full proteomics analysis, as seen in \nFigure 5\n, many files are created. Every step has it\ns own multiples files formats :\n\n\n\n\n\n\nFigure 5\n \n \nMultiple formats during MS treatment\n[^MS file format]. From the sample processing to the final file, various file formats can be used. This schema shows the different processes and file formats that are generated during a full MS experiment.\n\n\n\n\nFor this tutorial we will focus on the \nInformatics Analysis\n part using the following file formats:\n\n\n\n\nfasta\n: fasta files are mainly used for representing either nucleotide sequences or peptide sequences, using single-letter codes.\n\n\nMGF\n : Mascot Generic Format (MGF) file is the most common format for MS/MS data encoding in the form of a peak list[^MGF]. This file encodes multiple MS/MS spectra in a single file listing the [m/z, intensity] pairs separated by headers \n see \nFigure 6\n. More precisely each query represents a complete MS/MS spectrum delimited by BEGIN IONS and END IONS statements. Embedded parameters[^embedded_parameters] can be found after each BEGIN IONS statement. An example entry is shown in the figure below:\n\n\n\n\n\n\n\n\nFigure 6\n \n \nSample of a MGF file\n. MGF files are used for enconding MS results, multiple spectra can be enconded in one MGF. Every spectrum begins with the \nBEGINS IONS\n assessment and finishes with \nEND IONS\n. MGF files can be divided in 2 parts :\n    \n The header : containing information about the embedded Search Parameters.\n    \n Ions information : the first figure is the ion mass, the second is the ion charge.\n\n\n\n\nX!Tandem\n\n\nX!Tandem\n is an open source software that can match tandem mass spectra (usually the experiment) with peptide sequences from a database. This process allows identification of proteins in one or more samples.\n\n\nThe X!Tandem search engine calculates a statistical confidence (expectation value) for all of the individual spectrum-to-sequence assignments. Some spectra might map to more than one protein, in this case X!Tandem will pick the best match with the highest confidence score (see \nFigure 7\n). The output is a lists all of the high confidence assignments.\n\n\n\n\n\n\nFigure 7\n \n \nSchema of the X!Tandem analysis\n[^figure1]. After LC-MS/MS analysis the experimental spectrum is compared to a theoretical spectrum made from a protein database. This comparison leads to a list of peptide match ranked by score.\n\n\n\n\nGALAXY\n\n\nGALAXY[^galaxy] is an open source, web-based platform for biomedical research. GALAXY allows users to perform multi-omics data analyses: genomics, proteomics, transcriptomics and more. Numerous tools are available to achieve various analyses. This tutorial will focus on proteomics identification: matching the experimental data, spectra from LC-MS/MS analysis against data from a protein database using X!Tandem.\n\n\nBefore starting, a quick overview of the GALAXY interface \n see \nFigure 8\n. The interface is divided into three parts:\n\n\n\n\nLeft panel\n:  List the tools that are available.  A search textbox is at the top of the panel in order to find the tool you want.\n\n\nRight panel\n: Is the history of all the data outputs from previous steps and subsequently becoming the input for the next step. For example, the figure below shows the data imported ready for the next step. This panel allows the user to follow the different steps of the  analysis.\n\n\nCentral panel\n: Is the main screen, showing the details and options of the selected tool.\n\n\n\n\n\n\n\n\nFigure 8\n \n \nGalaxy interface\n. Divided in 3 parts Galaxy\ns interface go from the left selecting the tools to the right where the results are displayed.\n\n\n\n\n\n\nTutorial\n\n\nThis tutorial describes how to identify a list of proteins from tandem mass spectrometry data.\n\n\nAnalyses of this type are a fundamental part of most proteomics studies. The basic idea is to match tandem MS spectra obtained from a sample with equivalent theoretical spectra against a reference protein database. The process is referred to as \nprotein identification\n, although amino acid sequences are not obtained \nde novo\n with this method.\n\n\nObjectives\n\n\nThe objective of this tutorial is to perform protein identification from MS/MS spectra data using the X!Tandem tool in GALAXY \n see \nFigure 9\n. The basic steps involved are:\n\n\n\n\nLoading UniProt[^uniprot] proteome data in GALAXY (fasta file format)\n\n\nLoading your MS/MS spectra in GALAXY\n\n\nRun X!Tandem proteomics search\n\n\nSorting and analysing the results\n\n\n\n\nThe tutorial will finish with an exercise where you repeat the same protocol \nbut\n with your own proteome as the reference database instead of using UniProt.\n\n\n\n\n\n\nFigure 9\n - \nGeneral flowchart of this training\n. The first part is to upload datasets to be investigated. Then the training will cover the key parts of the configuration of a X!Tandem search. Finally, we look at sorting and analysing the results.\n\n\n\n\nThe aim of the training will be to create a list of all proteins that can be confidently said to be present in the sample.\n\n\nThis tutorial uses the following open source tools:\n\n\n\n\nX!Tandem search engine\n\n\nTrans Proteomic Pipeline[^tpp]\n\n\nGALAXY platform with tools already installed\n\n\n\n\nThis tutorial uses an \nE. Coli\n MS/MS spectra dataset that can be downloaded from: \nEColi K12 Dataset\n\n\nOriginal source : \nhttp://www.marcottelab.org/MSdata/\n\n\nSTEP 1: Data import\n\n\n\n\nBefore importing data, \nName\n your history. \nClick\n on the \nUnnamed history\n on the top of the right panel until you get the cursor. \nDelete\n and \ntype\n in \nProtein Identificaiton E.coli K12\n or a more meaningful name. You \nmust\n \nhit Enter\n, otherwise the name will not be saved.\n\n\n\n\n\n\n\n\nNext, \nimport\n data into GALAXY. On the left panel \nclick\n on the upload button as shown below:\n\n\n\n\n\n\n\n\nA new window will open, where you can select a method to upload your data: Choose local file, Choose FTP file, Paste/Fetch data. \nClick\n on \nPaste/Fetch data\n then copy and paste the URL of the mass spectrometer file: into the textbox: EColi_K12_MS_Spectra.mgf\n\n\n\n\n\n\nTip\n : You can also use the \nGet Data \n Upload file\n tool to obtain the same result. Here you want to upload your MS/MS spectra.\n\n\n\n\n\n\n\n\nWarning\n : X!Tandem only accepts mgf files in GALAXY.  Other file formats have to be converted beforehand. A useful tool for that is msconvert\n^msconvert\n.\n\n\n\n\nSTEP 2: Import Reference Data\n\n\nWe will first use the UniProt Database as our reference data to search against.\n\n\n\n\nSelect the tool named \nProtein Database Downloader\n\n\nChoose the database: \nUniProtKB\n\n\nSelect the organism of interest: \nEscherichia Coli (strain K12)\n\n\n\n\nClick on \nExecute\n\n\n\n\n\n\nYou will see your history update with the new data imports\n\n\n\n\n\n\n\n\n\n\nRename your \nProtein Database\n by clicking on \n icon.\n\n\nSelect \nEdit Attributes\n\n\nIn \nName\n, type in \nEColi_K12_UniProt_Database\n\n\nClick \nSave\n\n\n\n\n\n\nSTEP 3: X!Tandem MS/MS Search\n\n\nThis part of the tutorial is to perform the X!Tandem MS/MS search.\n\n\n\n\nThe tool can be found in the left panel under the section \nProteomics Tools \n X!Tandem MSMS Search\n\n\nIn the central section, you should see the following options. Below the key parameters are explained in detail.\n\n\n\n\n\n\nX!Tandem proposes many options, the key options of interest are:\n\n\n\n\nUploaded FASTA file\n: this parameter is to select the fasta file that will be used as the proteins database.\n\n\nMSMS File\n : select the spectra file to analyse.\n\n\nVariable Modifications\n: this option considers possible modification on each residue (which impact the MS/MS spectra).\n\n\nFixed Modifications\n: this option allows you to specify any known modification.\n\n\nMissed Cleavages Allowed\n: \nwhen a cleavage reagent (either chemical or enzymatic) is used to cleave the peptide backbone of a protein to produce peptides, different sites along the backbone will have different reaction rates and kinetics. Therefore, there may be some sites that should be cleaved by the reagent that are not completely cleaved during the course of the experiment. The value of this parameter represents the maximum number of missed cleavage sites allowed within a peptide.\n\n\nEnzyme\n: specify the enzyme that has been used to cleave the proteins (affecting the interpretation of the spectrum).\n\n\nFragment ion tolerance\n: define the minimum weight (in Da) of the fragmented ions, default value is 0.5.\n\n\nPrecursor ion tolerance\n: define the minimum weight (in Da) of the precursor ions.\n\n\n\n\nIn this tutorial, we are using the following parameters:\n\n\n\n\n\n\n\n\nParameters Name\n\n\nValue\n\n\nDefault Value\n\n\n\n\n\n\n\n\n\n\nUploaded FASTA file\n\n\nEColi_K12_UniProt_Database\n\n\n\n\n\n\n\n\nMSMS File\n\n\nEColi_K12_MS_Spectra.mgf\n\n\n\n\n\n\n\n\nVariable Modifications\n\n\nOxidation M\n\n\n\n\n\n\n\n\nFixed Modifications\n\n\nCarbamidomethyl C\n\n\n\n\n\n\n\n\nMissed Cleavages Allowed\n\n\n2\n\n\n2\n\n\n\n\n\n\nEnzyme\n\n\nTrypsin\n\n\nTrypsin\n\n\n\n\n\n\nFragment ion tolerance\n\n\n0.5\n\n\n0.5\n\n\n\n\n\n\nPrecursor ion tolerance\n\n\n10 ppm\n\n\n10 ppm\n\n\n\n\n\n\n\n\n\n\nLeave all other parameters as their default settings.\n\n\n\n\nClick on \nExecute\n\n\n\n\n\n\nThe history should update with a new entry, the output file of the X!Tandem\n\n\n\n\nRename the output by clicking on the \n  icon\n\n\n\n\n\n\n\n\nYou can view the output by click on the name in the history panel.\n\n\n\n\nSTEP 4: Convert X!Tandem XML to Table\n\n\nThe output of X!Tandem is an XML format, which is not easy to decipher. In order to get a more readable file, we will convert the XML format to a table. This is a two step process:\n\n\n\n\nSelect \nProteomics Tools \n Tandem to pepXML\n\n\nSelect your \ntandem\n file in the \nInput File\n field\n\n\nClick on \nExecute\n\n\nThe history should update with a new \npepXML\n file. The pepXML file is still a XML file and needs to be converted to a tabular.\n\n\nSelect \nProteomics Tools \n PepXML to Table\n\n\nSelect your \npepXML\n file in the \nInput File\n field\n\n\nThis history should update with a new file\n\n\n\n\n\n\nAfter the X!Tandem search we obtain a list of proteins present in the sample data from Step 1:\n\n\n\n\n\n\n\n\nTabular name\n\n\nTandem file XML designation\n\n\nDefinition\n\n\n\n\n\n\n\n\n\n\nProtein\n\n\nlabel\n\n\nProtein name according to the database used for the MS/MS search\n\n\n\n\n\n\nPeptide\n\n\nseq\n\n\nPeptide sequence\n\n\n\n\n\n\nAssumed_charge\n\n\nz\n\n\nParent ion mass (plus a proton) from the spectrum\n\n\n\n\n\n\nCalc_neutral_pep_mass\n\n\nmh (+mass of a proton)\n\n\nParent ion mass calculated from the spectrum\n\n\n\n\n\n\nNeutral_mass\n\n\nmh (+mass of a proton)\n\n\nCalculated peptide mass (plus a proton)\n\n\n\n\n\n\nRetention_time\n\n\nrt\n\n\nLength of time between injection and position of the target compound peak.[^rt]\n\n\n\n\n\n\nStart_scan\n\n\nid\n\n\nid of the group treated (where the analysis starts)\n\n\n\n\n\n\nEnd_scan\n\n\nid\n\n\nid of the domain treated (usually the same as start_scan, no consideration of the doted name in the original XML file)\n\n\n\n\n\n\nSearch_engine\n\n\n\n\nName of the search engine used, in our case X!Tandem (associated with the scoring method : \nk-score\n)\n\n\n\n\n\n\nRaw_score\n\n\nexpect\n\n\nExpectation value for the top ranked protein identified with this spectrum\n\n\n\n\n\n\n\n\n\n\nNote:\n You can find all the details on the X!Tandem output file here: \nThe file format for X! series search engines\n. The tandem XML file contains more information than the tabular format which can also be of further use (e.i. the score for the different ions \nx, y, z, a, b, c\n \n)\n\n\n\n\nExercise\n\n\n\n\nRepeat the tutorial but instead of uploading a UniProt database in Step 2, upload your own database. You can use the \nE. Coli\n dataset : \nE. Coli Annotated Genome\n and compare the two outputs.\n\n\n\n\n\n\nReferences\n\n\n[^xtand]: X!Tandem website: http://www.thegpm.org/tandem/. X!Tandem documentation : http://www.thegpm.org/TANDEM/api/. Craig, R., and R. C. Beavis. 2004. \n\u201cTANDEM: matching proteins with tandem mass spectra.\u201d\n Bioinformatics 20, no. 9 (June): 1466-67. http://dx.doi.org/10.1093/bioinformatics/bth092.\n\n\n[^figure1]: Nesvizhskii, Alexey I. \nProtein Identification By Tandem Mass Spectrometry And Sequence Database Searching\n. Mass Spectrometry Data Analysis in Proteomics 87-120.\n \n \nMass Spectrometry Data Analysis in Proteomics\n\n\n[^galaxy]: GALAXY platform : https://usegalaxy.org/. You can also find a more extensive documentation here : https://galaxyproject.org/.\nAfgan, Enis et al. \nThe Galaxy Platform For Accessible, Reproducible And Collaborative Biomedical Analyses: 2016 Update\n. Nucleic Acids Res 44.W1 (2016): W3-W10.\n \n \nThe Galaxy platform for accessible, reproducible and collaborative biomedical analyses: 2016 update\n\n\n[^uniprot]: UniProt : http://www.uniprot.org/. Apweiler, R. \nUniprot: The Universal Protein Knowledgebase\n. Nucleic Acids Research 32.90001 (2004): 115D-119.\n \n \nUniProt: the Universal Protein knowledgebase\n\n\n[^figure3]: High-performance liquid chromatography (HPLC): \nHow Does High Performance Liquid Chromatography Work ?\n Mant, Colin T. et al. \nHPLC Analysis And Purification Of Peptides\n. Peptide Characterization and Application Protocols (2007): 3-55.\n\n\n[^figure4]: Aebersold, Ruedi and Matthias Mann. \nMass Spectrometry-Based Proteomics\n. Nature 422.6928 (2003): 198-207.\n \n \nMass Spectrometry-Based Proteomics\n\n\n[^MS file format]: Deutsch, E. W. \nFile Formats Commonly Used In Mass Spectrometry Proteomics\n. Molecular \n Cellular Proteomics 11.12 (2012): 1612-1621.\n \n \nFile Formats Commonly Used in Mass Spectrometry Proteomics\n\n\n[^MGF]: Mascot Generic Format (MGF) file is likely the most common text format for MS/MS data encoding in the form of a peak list. This file encodes multiple MS/MS spectra in a single file via m/z, intensity pairs separated by headers.\n \n \nMGF file format\n\n\n[^embedded_parameters]: The MGF format allows parameters that can be found after the BEGIN IONS statement.\n \n \nEmbedded Parameters\n\n\n[^rt]: The retention time of a peak can be used as means of qualitative identification. The length of time between injection and position of the target compound peak.\n \n \nRetention Time Parameters\n\n \n \nRetention Time explained for GC/MS\n\n\n[^tpp]: The Trans-Proteomic Pipeline (TPP) website : http://tools.proteomecenter.org/wiki/index.php?title=Software:TPP. Deutsch, Eric W. et al. \nA Guided Tour Of The Trans-Proteomic Pipeline\n. Proteomics 10.6 (2010): 1150-1159.\n \n \nA Guided Tour of the Trans-Proteomic Pipeline\n\n\n[^msconvert]: ProteoWizard Tools website : http://proteowizard.sourceforge.net/tools.shtml. Holman, Jerry D., David L. Tabb, and Parag Mallick. \nEmploying Proteowizard To Convert Raw Mass Spectrometry Data\n. Current Protocols in Bioinformatics (2014): 13.24.1-13.24.9.\n\n \nEmploying ProteoWizard to Convert Raw Mass Spectrometry Data", 
            "title": "Protein Identification"
        }, 
        {
            "location": "/modules/xtandem/#protein-identification-using-xtandem", 
            "text": "", 
            "title": "Protein identification using X!Tandem"
        }, 
        {
            "location": "/modules/xtandem/#introduction", 
            "text": "The high-throughput nature of proteomics mass spectrometry is enabled by a productive combination of data acquisition protocols and the computational tools used to interpret the resulting spectra (list of peaks). One of the key components in mainstream protocols is the generation of tandem mass (MS/MS) spectra by peptide fragmentation. This approach is currently used in the large majority of proteomics experiments to routinely identify hundreds to thousands of proteins from single mass spectrometry runs. In order to do that multiple tools have to be employed:  LC-MS/MS  to segregate components of proteomic samples associated with  protein identification  (see  Figure 1 ) softwares,  X!Tandem [^xtand],  Mascot  or  SEQUEST  all of which perform protein identification but with different algorithms.    Figure 1     General overview of the experimental steps and flow of data in protein identification using shotgun proteomics experiment. [^figure1].   Figure 1  shows a general overview of the experimental steps in protein identification. Sample proteins are first cleaved into peptides, which are then separated using chromatography (e.g. HPLC). The peptides are then ionised and then selected ions are fragmented to produce signature tandem mass spectrometry (MS/MS) spectra. Peptides are identified from the MS/MS spectra by using programs such as X!Tandem, which search against a database of known peptides. Sequences of the identified peptides are used to infer which proteins are present in the original sample.", 
            "title": "Introduction"
        }, 
        {
            "location": "/modules/xtandem/#background", 
            "text": "", 
            "title": "Background"
        }, 
        {
            "location": "/modules/xtandem/#lc-msms-analysis", 
            "text": "Liquid Chromatography  (LC) is a technique used to separate molecules in the solvent (mobile phase). Nowadays liquid chromatography utilising high pressure to force the solvent through the columns packed with porous particles (stationary phase) is referred as High Pressure Liquid Chromatography (HPLC)   see  Figure 2 . After purifying the proteomic cell content, LC is able to separate the different proteins which are injected in the mass spectrometer. Each peak from the results will be analysed by mass spectrometry.    Figure 2     Schema of High Pressure Liquid Chromatography (HPLC)[^figure3].  Compounds of the mixture are separated in the HPLC column according to various parameters (polarity, charge, affinity etc). The type of separation depends on the column being used). A detector flow cell is used to detect the separated compounds band.   Mass spectrometry  (MS)   see  Figure 3    has been widely used to analyse biological samples and has evolved into an indispensable tool for proteomics research. Fundamentally, MS measures the mass-to-charge ratio (m/z) of gas-phase ions. Mass spectrometers consist of an ion source that converts analyte molecules into gas-phase ions, a mass analyser that separates ionised analytes on the basis of m/z ratio and a detector that records the number of ions at each m/z value.    Figure 3     Schema of mass specter .  A mass spectrometer consists of three components: an ion source, a mass analyzer, and a detector. The ionizer converts a portion of the sample into ions. There is a wide variety of ionization techniques, depending on the phase (solid, liquid, gas) of the sample and the efficiency of various ionization mechanisms for the unknown species. An extraction system removes ions from the sample, which are then targeted through the mass analyzer and onto the detector. The differences in masses of the fragments allows the mass analyzer to sort the ions by their mass-to-charge ratio. The detector measures the value of an indicator quantity and thus provides data for calculating the abundances of each ion present.  [^figure4]   Tandem mass spectrometry  (MS/MS)   see  Figure 4    is a key technique for protein or peptide sequencing and post-translational modifications analysis. Collision-induced dissociation (CID) has been the most widely used MS/MS technique in proteomics research. In this method, gas-phase peptide/protein cations are internally heated by multiple collisions with rare gas atoms. The result is fragmented ions that, after the detection phase and reconstitution, reveal the amino-acid chains.    Figure 4     Schema of a tandem mass spectrometry associated with liquid chromatography (LC-MS/MS) . This technique combine separation form liquid chromatography and m/z ratio analyse of the tandem mass spectrometry in order to generate spectra.   File formats  : During a full proteomics analysis, as seen in  Figure 5 , many files are created. Every step has it s own multiples files formats :    Figure 5     Multiple formats during MS treatment [^MS file format]. From the sample processing to the final file, various file formats can be used. This schema shows the different processes and file formats that are generated during a full MS experiment.   For this tutorial we will focus on the  Informatics Analysis  part using the following file formats:   fasta : fasta files are mainly used for representing either nucleotide sequences or peptide sequences, using single-letter codes.  MGF  : Mascot Generic Format (MGF) file is the most common format for MS/MS data encoding in the form of a peak list[^MGF]. This file encodes multiple MS/MS spectra in a single file listing the [m/z, intensity] pairs separated by headers   see  Figure 6 . More precisely each query represents a complete MS/MS spectrum delimited by BEGIN IONS and END IONS statements. Embedded parameters[^embedded_parameters] can be found after each BEGIN IONS statement. An example entry is shown in the figure below:     Figure 6     Sample of a MGF file . MGF files are used for enconding MS results, multiple spectra can be enconded in one MGF. Every spectrum begins with the  BEGINS IONS  assessment and finishes with  END IONS . MGF files can be divided in 2 parts :\n      The header : containing information about the embedded Search Parameters.\n      Ions information : the first figure is the ion mass, the second is the ion charge.", 
            "title": "LC-MS/MS Analysis"
        }, 
        {
            "location": "/modules/xtandem/#xtandem", 
            "text": "X!Tandem  is an open source software that can match tandem mass spectra (usually the experiment) with peptide sequences from a database. This process allows identification of proteins in one or more samples.  The X!Tandem search engine calculates a statistical confidence (expectation value) for all of the individual spectrum-to-sequence assignments. Some spectra might map to more than one protein, in this case X!Tandem will pick the best match with the highest confidence score (see  Figure 7 ). The output is a lists all of the high confidence assignments.    Figure 7     Schema of the X!Tandem analysis [^figure1]. After LC-MS/MS analysis the experimental spectrum is compared to a theoretical spectrum made from a protein database. This comparison leads to a list of peptide match ranked by score.", 
            "title": "X!Tandem"
        }, 
        {
            "location": "/modules/xtandem/#galaxy", 
            "text": "GALAXY[^galaxy] is an open source, web-based platform for biomedical research. GALAXY allows users to perform multi-omics data analyses: genomics, proteomics, transcriptomics and more. Numerous tools are available to achieve various analyses. This tutorial will focus on proteomics identification: matching the experimental data, spectra from LC-MS/MS analysis against data from a protein database using X!Tandem.  Before starting, a quick overview of the GALAXY interface   see  Figure 8 . The interface is divided into three parts:   Left panel :  List the tools that are available.  A search textbox is at the top of the panel in order to find the tool you want.  Right panel : Is the history of all the data outputs from previous steps and subsequently becoming the input for the next step. For example, the figure below shows the data imported ready for the next step. This panel allows the user to follow the different steps of the  analysis.  Central panel : Is the main screen, showing the details and options of the selected tool.     Figure 8     Galaxy interface . Divided in 3 parts Galaxy s interface go from the left selecting the tools to the right where the results are displayed.", 
            "title": "GALAXY"
        }, 
        {
            "location": "/modules/xtandem/#tutorial", 
            "text": "This tutorial describes how to identify a list of proteins from tandem mass spectrometry data.  Analyses of this type are a fundamental part of most proteomics studies. The basic idea is to match tandem MS spectra obtained from a sample with equivalent theoretical spectra against a reference protein database. The process is referred to as  protein identification , although amino acid sequences are not obtained  de novo  with this method.", 
            "title": "Tutorial"
        }, 
        {
            "location": "/modules/xtandem/#objectives", 
            "text": "The objective of this tutorial is to perform protein identification from MS/MS spectra data using the X!Tandem tool in GALAXY   see  Figure 9 . The basic steps involved are:   Loading UniProt[^uniprot] proteome data in GALAXY (fasta file format)  Loading your MS/MS spectra in GALAXY  Run X!Tandem proteomics search  Sorting and analysing the results   The tutorial will finish with an exercise where you repeat the same protocol  but  with your own proteome as the reference database instead of using UniProt.    Figure 9  -  General flowchart of this training . The first part is to upload datasets to be investigated. Then the training will cover the key parts of the configuration of a X!Tandem search. Finally, we look at sorting and analysing the results.   The aim of the training will be to create a list of all proteins that can be confidently said to be present in the sample.  This tutorial uses the following open source tools:   X!Tandem search engine  Trans Proteomic Pipeline[^tpp]  GALAXY platform with tools already installed   This tutorial uses an  E. Coli  MS/MS spectra dataset that can be downloaded from:  EColi K12 Dataset  Original source :  http://www.marcottelab.org/MSdata/", 
            "title": "Objectives"
        }, 
        {
            "location": "/modules/xtandem/#step-1-data-import", 
            "text": "Before importing data,  Name  your history.  Click  on the  Unnamed history  on the top of the right panel until you get the cursor.  Delete  and  type  in  Protein Identificaiton E.coli K12  or a more meaningful name. You  must   hit Enter , otherwise the name will not be saved.     Next,  import  data into GALAXY. On the left panel  click  on the upload button as shown below:     A new window will open, where you can select a method to upload your data: Choose local file, Choose FTP file, Paste/Fetch data.  Click  on  Paste/Fetch data  then copy and paste the URL of the mass spectrometer file: into the textbox: EColi_K12_MS_Spectra.mgf    Tip  : You can also use the  Get Data   Upload file  tool to obtain the same result. Here you want to upload your MS/MS spectra.     Warning  : X!Tandem only accepts mgf files in GALAXY.  Other file formats have to be converted beforehand. A useful tool for that is msconvert ^msconvert .", 
            "title": "STEP 1: Data import"
        }, 
        {
            "location": "/modules/xtandem/#step-2-import-reference-data", 
            "text": "We will first use the UniProt Database as our reference data to search against.   Select the tool named  Protein Database Downloader  Choose the database:  UniProtKB  Select the organism of interest:  Escherichia Coli (strain K12)   Click on  Execute    You will see your history update with the new data imports      Rename your  Protein Database  by clicking on   icon.  Select  Edit Attributes  In  Name , type in  EColi_K12_UniProt_Database  Click  Save", 
            "title": "STEP 2: Import Reference Data"
        }, 
        {
            "location": "/modules/xtandem/#step-3-xtandem-msms-search", 
            "text": "This part of the tutorial is to perform the X!Tandem MS/MS search.   The tool can be found in the left panel under the section  Proteomics Tools   X!Tandem MSMS Search  In the central section, you should see the following options. Below the key parameters are explained in detail.    X!Tandem proposes many options, the key options of interest are:   Uploaded FASTA file : this parameter is to select the fasta file that will be used as the proteins database.  MSMS File  : select the spectra file to analyse.  Variable Modifications : this option considers possible modification on each residue (which impact the MS/MS spectra).  Fixed Modifications : this option allows you to specify any known modification.  Missed Cleavages Allowed :  when a cleavage reagent (either chemical or enzymatic) is used to cleave the peptide backbone of a protein to produce peptides, different sites along the backbone will have different reaction rates and kinetics. Therefore, there may be some sites that should be cleaved by the reagent that are not completely cleaved during the course of the experiment. The value of this parameter represents the maximum number of missed cleavage sites allowed within a peptide.  Enzyme : specify the enzyme that has been used to cleave the proteins (affecting the interpretation of the spectrum).  Fragment ion tolerance : define the minimum weight (in Da) of the fragmented ions, default value is 0.5.  Precursor ion tolerance : define the minimum weight (in Da) of the precursor ions.   In this tutorial, we are using the following parameters:     Parameters Name  Value  Default Value      Uploaded FASTA file  EColi_K12_UniProt_Database     MSMS File  EColi_K12_MS_Spectra.mgf     Variable Modifications  Oxidation M     Fixed Modifications  Carbamidomethyl C     Missed Cleavages Allowed  2  2    Enzyme  Trypsin  Trypsin    Fragment ion tolerance  0.5  0.5    Precursor ion tolerance  10 ppm  10 ppm      Leave all other parameters as their default settings.   Click on  Execute    The history should update with a new entry, the output file of the X!Tandem   Rename the output by clicking on the    icon     You can view the output by click on the name in the history panel.", 
            "title": "STEP 3: X!Tandem MS/MS Search"
        }, 
        {
            "location": "/modules/xtandem/#step-4-convert-xtandem-xml-to-table", 
            "text": "The output of X!Tandem is an XML format, which is not easy to decipher. In order to get a more readable file, we will convert the XML format to a table. This is a two step process:   Select  Proteomics Tools   Tandem to pepXML  Select your  tandem  file in the  Input File  field  Click on  Execute  The history should update with a new  pepXML  file. The pepXML file is still a XML file and needs to be converted to a tabular.  Select  Proteomics Tools   PepXML to Table  Select your  pepXML  file in the  Input File  field  This history should update with a new file    After the X!Tandem search we obtain a list of proteins present in the sample data from Step 1:     Tabular name  Tandem file XML designation  Definition      Protein  label  Protein name according to the database used for the MS/MS search    Peptide  seq  Peptide sequence    Assumed_charge  z  Parent ion mass (plus a proton) from the spectrum    Calc_neutral_pep_mass  mh (+mass of a proton)  Parent ion mass calculated from the spectrum    Neutral_mass  mh (+mass of a proton)  Calculated peptide mass (plus a proton)    Retention_time  rt  Length of time between injection and position of the target compound peak.[^rt]    Start_scan  id  id of the group treated (where the analysis starts)    End_scan  id  id of the domain treated (usually the same as start_scan, no consideration of the doted name in the original XML file)    Search_engine   Name of the search engine used, in our case X!Tandem (associated with the scoring method :  k-score )    Raw_score  expect  Expectation value for the top ranked protein identified with this spectrum      Note:  You can find all the details on the X!Tandem output file here:  The file format for X! series search engines . The tandem XML file contains more information than the tabular format which can also be of further use (e.i. the score for the different ions  x, y, z, a, b, c   )", 
            "title": "STEP 4: Convert X!Tandem XML to Table"
        }, 
        {
            "location": "/modules/xtandem/#exercise", 
            "text": "Repeat the tutorial but instead of uploading a UniProt database in Step 2, upload your own database. You can use the  E. Coli  dataset :  E. Coli Annotated Genome  and compare the two outputs.", 
            "title": "Exercise"
        }, 
        {
            "location": "/modules/xtandem/#references", 
            "text": "[^xtand]: X!Tandem website: http://www.thegpm.org/tandem/. X!Tandem documentation : http://www.thegpm.org/TANDEM/api/. Craig, R., and R. C. Beavis. 2004.  \u201cTANDEM: matching proteins with tandem mass spectra.\u201d  Bioinformatics 20, no. 9 (June): 1466-67. http://dx.doi.org/10.1093/bioinformatics/bth092.  [^figure1]: Nesvizhskii, Alexey I.  Protein Identification By Tandem Mass Spectrometry And Sequence Database Searching . Mass Spectrometry Data Analysis in Proteomics 87-120.\n    Mass Spectrometry Data Analysis in Proteomics  [^galaxy]: GALAXY platform : https://usegalaxy.org/. You can also find a more extensive documentation here : https://galaxyproject.org/.\nAfgan, Enis et al.  The Galaxy Platform For Accessible, Reproducible And Collaborative Biomedical Analyses: 2016 Update . Nucleic Acids Res 44.W1 (2016): W3-W10.\n    The Galaxy platform for accessible, reproducible and collaborative biomedical analyses: 2016 update  [^uniprot]: UniProt : http://www.uniprot.org/. Apweiler, R.  Uniprot: The Universal Protein Knowledgebase . Nucleic Acids Research 32.90001 (2004): 115D-119.\n    UniProt: the Universal Protein knowledgebase  [^figure3]: High-performance liquid chromatography (HPLC):  How Does High Performance Liquid Chromatography Work ?  Mant, Colin T. et al.  HPLC Analysis And Purification Of Peptides . Peptide Characterization and Application Protocols (2007): 3-55.  [^figure4]: Aebersold, Ruedi and Matthias Mann.  Mass Spectrometry-Based Proteomics . Nature 422.6928 (2003): 198-207.\n    Mass Spectrometry-Based Proteomics  [^MS file format]: Deutsch, E. W.  File Formats Commonly Used In Mass Spectrometry Proteomics . Molecular   Cellular Proteomics 11.12 (2012): 1612-1621.\n    File Formats Commonly Used in Mass Spectrometry Proteomics  [^MGF]: Mascot Generic Format (MGF) file is likely the most common text format for MS/MS data encoding in the form of a peak list. This file encodes multiple MS/MS spectra in a single file via m/z, intensity pairs separated by headers.\n    MGF file format  [^embedded_parameters]: The MGF format allows parameters that can be found after the BEGIN IONS statement.\n    Embedded Parameters  [^rt]: The retention time of a peak can be used as means of qualitative identification. The length of time between injection and position of the target compound peak.\n    Retention Time Parameters \n    Retention Time explained for GC/MS  [^tpp]: The Trans-Proteomic Pipeline (TPP) website : http://tools.proteomecenter.org/wiki/index.php?title=Software:TPP. Deutsch, Eric W. et al.  A Guided Tour Of The Trans-Proteomic Pipeline . Proteomics 10.6 (2010): 1150-1159.\n    A Guided Tour of the Trans-Proteomic Pipeline  [^msconvert]: ProteoWizard Tools website : http://proteowizard.sourceforge.net/tools.shtml. Holman, Jerry D., David L. Tabb, and Parag Mallick.  Employing Proteowizard To Convert Raw Mass Spectrometry Data . Current Protocols in Bioinformatics (2014): 13.24.1-13.24.9.   Employing ProteoWizard to Convert Raw Mass Spectrometry Data", 
            "title": "References"
        }, 
        {
            "location": "/modules/pathway_tools/annotation/", 
            "text": "Pathway prediction and annotations for new organisms\n\n\nConnect to mGVL using VNC\n\n\n\n\nGo to the mGVL dashboard\n\n\nClick on the link next to the \nLubuntu Destkop\n (http://your-mgvl-ip-address/vnc)\n\n\n\n\n\n\nA new browser will appear, enter your user credentials to login\n\n\n\n\nCreate a new Database\n\n\nOnce logged in, you should see the following desktop with the 3 Pathway tools icons on the left. Click on the first\nicon \nPathway Tools v1.9.5\n. This will bring up a new window.\n\n\n\n\n\n\nIn the \nPathway Tools\n window, click on \nTools\n menu item and then click on \nPathLogic\n\n\nIn the new window, at the top, click on \nDatabase\n and then \nCreate New\n\n\n\n\nProvide the metadata for the new database. In the \nDatabase(required)\n section, enter the following values:\n\n\n\n\nOrganism/Project ID:\n \nSEPSIS25707\n\n\nDatabase Name:\n \nSepsisCycl\n\n\n\n\nLeave the other parameters as the default values, that is:\n\n   Version: 1.0 (default)\n\n   DB Storage Type: File (default)\n\n\n\n\nUnder the \nTaxonomy (required)\n section:\n\n\n\n\nCheck Box if this is a multi-organism database: \nuncheck\n\n\nIn \nOrganism taxonomic class\n, type \n1314\n and click on \nSelect\n. The species name of Streptococcus pyogenes will appear and a popup window will also appear. Click on to close the window.\n\n\nCreate organism?: click \nyes\n\n\nStrain: \nHKU419(ARP)\n for sample (25707)\n\n\nGenome Source: \nARP\n\n\nNCBI taxonomy ID: \n1314\n (come back to this after Select \nStrain\n in next step)\n\n\nRank : Select \nStrain\n\n\n\n\nLeave all other fields as their default values:\n\n\n\n\nFull Species Name: autocomplete from the previous step\n\n\nAbbreviated Species Name: auto complete from the previous step\n\n\nSubspecies : leave it blank\n\n\nDefault Codon Table: 11 - Bacterial and Plant Plastid\n\n\nMitochondrial Codon Table : 0 - Unspecified\n\n\n\n\n\n\nLeave \nCredits(optional)\n section black.\n\n\n\n\nClick \nOK\n.\n\n\n\n\nAnother window will appear while processing. Wait for processing to complete, until you see the next window. Click on \nEnter Replicon Editor\n.\n\n\n\n\nSpecify Replicon details\n\n\nIn this view, you provide the details of the annotated assembly. Each chromosome will have a separate entry. For each chromosome, you need to provide the \nGBK\n and \nFNA\n annotation files from Prooka.\n\n\n\n\nName : \n1\n ( This is the chromosome name or number)\n\n\nCircular: \nchecked\n if circulator was performed or leave it unchecked\n\n\nSelect annotation file: select the gbk from prokka\n\n\nSelect sequence file: select the fna from prokka\n\n\n\n\nLeave other fields as their default value:\n\n\n\n\nType: Chromosome (default)\n\n\nCode: Bacterial, Archaeal and Plant Plastid (default)\n\n\nID: leave it blank (default)\n\n\nLinks to other database: NCBI Reference Sequences Database (default)\n\n\n\n\nRelationship : same Entity (default)\n\n\n\n\n\n\nClick \nOK\n\n\n\n\n\n\n\n\nThe metada for this database has now been created. Next we need to predict the pathways and annotate them.\n\n\nPredict and annotate the pathways\n\n\nStill on the previous window, from the top menu bar, click on \nBuild\n and then \nAutomated Build\n. This will take a while depending on the number of replicons that was included for this database.\n\n\n\n\nOnce the process has completed, a new window, \nPathway Scoring Parameters\n will appear. Leave the values as their default values.\n\n\n\n\nTaxonomic Pruning: Enabled (default)\n\n\nPathway Prediction Score Cutoff: 0.15 (default).\n\n\n\n\nA higher cutoff value for the \nprediction score\n will mean less pathways are predicted. This is the level of stringency imposed on the prediction.\n\n\nClick \nOK\n.\n\n\n\n\nAgain the process can take several minutes depending on the number of replicons included. Wait until the process is complete.\n\n\nClick on \nDatabase\n and then \nSave DB\n from the menu. The pathways have now been predicted, annotated and stored in the database.  \n\n\nVerify and test the new Database\n\n\nNow that the database has been created, we need to verify that it is available for use. First we check that it is present in the Pathway Tools. On the main screen, \nPathway Tools - Available Databases\n, you should see a new entry at the bottom of the pre-existing list, \nStreptococcus pyogenes HKU419(ARP)\n.\n\n\n\n\nTo see this newly created database in the Pathway Tools web-application, start up the Pathway Tools Web service (if not already running).\n\n\n\n\nYou can close all the windows, to exit Pathway Tools\n\n\nIf the web server is not already running, click on the \nPathway Tool Web server\n from the desktop, this is the third icon.\n\n\nOpen an internet brwoser and go to http://your-mgvl-ip-address:1555\n\n\n\n\n\n\nUsing the new database in Pathway Tools Web service\n\n\n\n\nOn the main screen, click on \nchange organism database\n at the top right corner, under the search box.\n\n\nA new window will appear, select the newly created species from the list\n\n\nClick \nOK\n\n\n\n\n\n\n\n\nA statistic table of the species will be available for overview.\n\n\n\n\nClick on the \nPathways\n link in the table, which will show the list of all predicted pathways in this database.\n\n\n\n\nYou can navigate through the list of pathways and highlight a pathway of interest. For example,\n\n\n\n\nClick on the \n+\n symbol next to \nDetoxification\n\n\nClick on the \n+\n symbol again next to \nAntibiotic Resistance\n\n\nClick on \npeptidoglycan biosynthesis V (beta-lactam resistance)\n which will bring up the pathway view  \n\n\n\n\n\n\nGo back to the previous screen with the statistics summary table and this time click on the \n1\n under the \nReplicon\n heading in the top table. The following genome browser will be shown.\n\n\n\n\nFrom here forward the user can explore using the Pathway Tools webservice.", 
            "title": "Pathway annotation and prediction"
        }, 
        {
            "location": "/modules/pathway_tools/annotation/#pathway-prediction-and-annotations-for-new-organisms", 
            "text": "", 
            "title": "Pathway prediction and annotations for new organisms"
        }, 
        {
            "location": "/modules/pathway_tools/annotation/#connect-to-mgvl-using-vnc", 
            "text": "Go to the mGVL dashboard  Click on the link next to the  Lubuntu Destkop  (http://your-mgvl-ip-address/vnc)    A new browser will appear, enter your user credentials to login", 
            "title": "Connect to mGVL using VNC"
        }, 
        {
            "location": "/modules/pathway_tools/annotation/#create-a-new-database", 
            "text": "Once logged in, you should see the following desktop with the 3 Pathway tools icons on the left. Click on the first\nicon  Pathway Tools v1.9.5 . This will bring up a new window.    In the  Pathway Tools  window, click on  Tools  menu item and then click on  PathLogic  In the new window, at the top, click on  Database  and then  Create New   Provide the metadata for the new database. In the  Database(required)  section, enter the following values:   Organism/Project ID:   SEPSIS25707  Database Name:   SepsisCycl   Leave the other parameters as the default values, that is:    Version: 1.0 (default)    DB Storage Type: File (default)   Under the  Taxonomy (required)  section:   Check Box if this is a multi-organism database:  uncheck  In  Organism taxonomic class , type  1314  and click on  Select . The species name of Streptococcus pyogenes will appear and a popup window will also appear. Click on to close the window.  Create organism?: click  yes  Strain:  HKU419(ARP)  for sample (25707)  Genome Source:  ARP  NCBI taxonomy ID:  1314  (come back to this after Select  Strain  in next step)  Rank : Select  Strain   Leave all other fields as their default values:   Full Species Name: autocomplete from the previous step  Abbreviated Species Name: auto complete from the previous step  Subspecies : leave it blank  Default Codon Table: 11 - Bacterial and Plant Plastid  Mitochondrial Codon Table : 0 - Unspecified    Leave  Credits(optional)  section black.   Click  OK .   Another window will appear while processing. Wait for processing to complete, until you see the next window. Click on  Enter Replicon Editor .", 
            "title": "Create a new Database"
        }, 
        {
            "location": "/modules/pathway_tools/annotation/#specify-replicon-details", 
            "text": "In this view, you provide the details of the annotated assembly. Each chromosome will have a separate entry. For each chromosome, you need to provide the  GBK  and  FNA  annotation files from Prooka.   Name :  1  ( This is the chromosome name or number)  Circular:  checked  if circulator was performed or leave it unchecked  Select annotation file: select the gbk from prokka  Select sequence file: select the fna from prokka   Leave other fields as their default value:   Type: Chromosome (default)  Code: Bacterial, Archaeal and Plant Plastid (default)  ID: leave it blank (default)  Links to other database: NCBI Reference Sequences Database (default)   Relationship : same Entity (default)    Click  OK     The metada for this database has now been created. Next we need to predict the pathways and annotate them.", 
            "title": "Specify Replicon details"
        }, 
        {
            "location": "/modules/pathway_tools/annotation/#predict-and-annotate-the-pathways", 
            "text": "Still on the previous window, from the top menu bar, click on  Build  and then  Automated Build . This will take a while depending on the number of replicons that was included for this database.   Once the process has completed, a new window,  Pathway Scoring Parameters  will appear. Leave the values as their default values.   Taxonomic Pruning: Enabled (default)  Pathway Prediction Score Cutoff: 0.15 (default).   A higher cutoff value for the  prediction score  will mean less pathways are predicted. This is the level of stringency imposed on the prediction.  Click  OK .   Again the process can take several minutes depending on the number of replicons included. Wait until the process is complete.  Click on  Database  and then  Save DB  from the menu. The pathways have now been predicted, annotated and stored in the database.", 
            "title": "Predict and annotate the pathways"
        }, 
        {
            "location": "/modules/pathway_tools/annotation/#verify-and-test-the-new-database", 
            "text": "Now that the database has been created, we need to verify that it is available for use. First we check that it is present in the Pathway Tools. On the main screen,  Pathway Tools - Available Databases , you should see a new entry at the bottom of the pre-existing list,  Streptococcus pyogenes HKU419(ARP) .   To see this newly created database in the Pathway Tools web-application, start up the Pathway Tools Web service (if not already running).   You can close all the windows, to exit Pathway Tools  If the web server is not already running, click on the  Pathway Tool Web server  from the desktop, this is the third icon.  Open an internet brwoser and go to http://your-mgvl-ip-address:1555", 
            "title": "Verify and test the new Database"
        }, 
        {
            "location": "/modules/pathway_tools/annotation/#using-the-new-database-in-pathway-tools-web-service", 
            "text": "On the main screen, click on  change organism database  at the top right corner, under the search box.  A new window will appear, select the newly created species from the list  Click  OK     A statistic table of the species will be available for overview.   Click on the  Pathways  link in the table, which will show the list of all predicted pathways in this database.   You can navigate through the list of pathways and highlight a pathway of interest. For example,   Click on the  +  symbol next to  Detoxification  Click on the  +  symbol again next to  Antibiotic Resistance  Click on  peptidoglycan biosynthesis V (beta-lactam resistance)  which will bring up the pathway view      Go back to the previous screen with the statistics summary table and this time click on the  1  under the  Replicon  heading in the top table. The following genome browser will be shown.   From here forward the user can explore using the Pathway Tools webservice.", 
            "title": "Using the new database in Pathway Tools Web service"
        }, 
        {
            "location": "/about/", 
            "text": "About\n\n\nThe Food and Health Flagship is an RDS-funded project to provide cloud-based data services and tools\nfor Australian Life Science Researchers to combine, analyse and interpret\ngenomic, transcriptomic, proteomic and metabolomic data. The data platform will incorporate the Bioplatforms Australia Antibiotic Resistant Pathogens Initiative (ABRPI).\n\n\nAuthors\n\n\n Anna Syme\n\n\n Torsten Seemann\n\n\n Simon Gladman\n\n\n Dieter Bulach\n\n\n Xin-Yi Chua\n\n\n Dominique Gorse\n\n\n Mike Thang\n\n\nSupport\n\n\n\n\nResearch Data Services\n\n\nBioplatforms Australia\n\n\nNectar\n\n\n\n\n\n\nThese training materials have been used for:\n\n\nMcGill Summer Institute in Infectious Diseases and Global Health, June 2016, Montreal, Canada\n\n\n\n\n\n\nGalaxy Community Conference 2016, Indiana, USA\n\n\n\n\n\n\nCLIMB UK Launch: Cloud Infrastructure for Microbial Bioinformatics, 2016", 
            "title": "About"
        }, 
        {
            "location": "/about/#about", 
            "text": "The Food and Health Flagship is an RDS-funded project to provide cloud-based data services and tools\nfor Australian Life Science Researchers to combine, analyse and interpret\ngenomic, transcriptomic, proteomic and metabolomic data. The data platform will incorporate the Bioplatforms Australia Antibiotic Resistant Pathogens Initiative (ABRPI).", 
            "title": "About"
        }, 
        {
            "location": "/about/#authors", 
            "text": "Anna Syme   Torsten Seemann   Simon Gladman   Dieter Bulach   Xin-Yi Chua   Dominique Gorse   Mike Thang", 
            "title": "Authors"
        }, 
        {
            "location": "/about/#support", 
            "text": "Research Data Services  Bioplatforms Australia  Nectar    These training materials have been used for:  McGill Summer Institute in Infectious Diseases and Global Health, June 2016, Montreal, Canada    Galaxy Community Conference 2016, Indiana, USA    CLIMB UK Launch: Cloud Infrastructure for Microbial Bioinformatics, 2016", 
            "title": "Support"
        }
    ]
}