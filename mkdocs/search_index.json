{
    "docs": [
        {
            "location": "/", 
            "text": "Welcome!\n\n\nABRPI training materials\n\n\nAntibiotic Resistant Pathogens Initiative\n\n\n\n\n\n\nThis site contains tutorials for using the analysis components of the \nomics.data.edu.au\n platform to perform various bioinformatics tasks on bacterial \u201comics\u201d data.\n\n\n\n\n\n\nTools covered by these tutorials include: \n\n\n\n\n\n\nthose within the \nMicrobial Genomics Virtual Lab\n (the mGVL), which can be accessed either through the \nhosted ABPRI-Galaxy service\n, or by setting up your own mGVL instance (see below) and accessing via the Unix command line.\n\n\n\n\n\n\nthose within the \nhosted ABPRI-PathwayTools service\n.\n\n\n\n\n\n\n\n\n\n\nTutorials are listed under the tabs in the top panel (Genomics, Transcriptomics, Proteomics, Metabolomics).\n\n\n\n\n\n\n\n\n\n\n\n\nIf you wish to set up your own instance (version) of the mGVL, follow the instructions \nhere\n.\n\n\n\n\nNote: at the stage where you select options in the GVL Launcher window, go to \nShow advanced startup options\n and under Flavor select \nMicrobial GVL with Tutorial Indices\n. In this mGVL instance, you can use both Galaxy and command line tools. If you wish to use the command line tools on a different computer (e.g. your local computer), you would need to make sure the required tools are installed (e.g. Canu, Circlator, Pilon, SPAdes, etc.).\n\n\n\n\n\n\n\n\nFor additional tutorials about how to use the Genomics Virtual Lab and Galaxy, see \nhttps://www.gvl.org.au/learn/", 
            "title": "Home"
        }, 
        {
            "location": "/#welcome", 
            "text": "", 
            "title": "Welcome!"
        }, 
        {
            "location": "/#abrpi-training-materials", 
            "text": "", 
            "title": "ABRPI training materials"
        }, 
        {
            "location": "/#antibiotic-resistant-pathogens-initiative", 
            "text": "This site contains tutorials for using the analysis components of the  omics.data.edu.au  platform to perform various bioinformatics tasks on bacterial \u201comics\u201d data.    Tools covered by these tutorials include:     those within the  Microbial Genomics Virtual Lab  (the mGVL), which can be accessed either through the  hosted ABPRI-Galaxy service , or by setting up your own mGVL instance (see below) and accessing via the Unix command line.    those within the  hosted ABPRI-PathwayTools service .      Tutorials are listed under the tabs in the top panel (Genomics, Transcriptomics, Proteomics, Metabolomics).       If you wish to set up your own instance (version) of the mGVL, follow the instructions  here .   Note: at the stage where you select options in the GVL Launcher window, go to  Show advanced startup options  and under Flavor select  Microbial GVL with Tutorial Indices . In this mGVL instance, you can use both Galaxy and command line tools. If you wish to use the command line tools on a different computer (e.g. your local computer), you would need to make sure the required tools are installed (e.g. Canu, Circlator, Pilon, SPAdes, etc.).     For additional tutorials about how to use the Genomics Virtual Lab and Galaxy, see  https://www.gvl.org.au/learn/", 
            "title": "Antibiotic Resistant Pathogens Initiative"
        }, 
        {
            "location": "/modules/workshop_overview/", 
            "text": "Genomics\n\n\nThe tutorials listed here under the Genomics tab include a set that can be run as a Genomics Workshop.\n\n\nGenomics workshop\n\n\n\n\n\n\nThe modules in this workshop cover microbial genomics, from assembly to annotation and variant calling:\n\n\n\n\nStarting with Galaxy\n\n\nTraining dataset\n\n\nQuality control\n\n\nGenome assembly with two tools - Velvet and Spades\n\n\nGenome annotation\n\n\nVariant finding\n\n\n\n\n\n\n\n\nThe analyses are conducted on the Galaxy platform, and links to training data are provided.\n\n\n\n\n\n\nThese modules can be delivered to a group workshop or used online independently.\n\n\n\n\n\n\nIf you have not yet used the Galaxy platform, we recommend following the modules in order.\n\n\n\n\n\n\nIf you are using these tutorials outside of a workshop and need access to Galaxy, you can follow the instructions on the homepage \nhere\n to obtain your own mGVL instance with Galaxy and command line tools.\n\n\n\n\n\n\nOther Genomics tutorials\n\n\n\n\nThere are also additional tutorials listed under the \nGenomics\n tab (such as PacBio assembly), but these may require different data sets and tools.", 
            "title": "Genomics workshop overview"
        }, 
        {
            "location": "/modules/workshop_overview/#genomics", 
            "text": "The tutorials listed here under the Genomics tab include a set that can be run as a Genomics Workshop.", 
            "title": "Genomics"
        }, 
        {
            "location": "/modules/workshop_overview/#genomics-workshop", 
            "text": "The modules in this workshop cover microbial genomics, from assembly to annotation and variant calling:   Starting with Galaxy  Training dataset  Quality control  Genome assembly with two tools - Velvet and Spades  Genome annotation  Variant finding     The analyses are conducted on the Galaxy platform, and links to training data are provided.    These modules can be delivered to a group workshop or used online independently.    If you have not yet used the Galaxy platform, we recommend following the modules in order.    If you are using these tutorials outside of a workshop and need access to Galaxy, you can follow the instructions on the homepage  here  to obtain your own mGVL instance with Galaxy and command line tools.", 
            "title": "Genomics workshop"
        }, 
        {
            "location": "/modules/workshop_overview/#other-genomics-tutorials", 
            "text": "There are also additional tutorials listed under the  Genomics  tab (such as PacBio assembly), but these may require different data sets and tools.", 
            "title": "Other Genomics tutorials"
        }, 
        {
            "location": "/modules/galaxy/", 
            "text": "Starting with Galaxy\n\n\nKeywords: Galaxy, Microbial Genomics Virtual Lab\n\n\nBackground\n\n\nGalaxy is a web-based analysis and workflow platform designed for biologists to analyse their own data. It can be used to run a variety of bioinformatics tools. The selection of bioinformatics tools installed on the Galaxy instance we are using today caters for the analysis of bacterial genomics data sets.\n\n\nGalaxy is an open, web-based platform. Details about the project can be found \nhere\n.\n\n\nThe Galaxy interface is separated into three parts. The \nTools\n list on the left, the \nViewing\n panel in the middle and the analysis and data \nHistory\n on the right.\n\n\n\n\nRegister\n\n\n\n\nUse Firefox, Chrome or Safari as your browser (not Internet Explorer).\n\n\nOpen a new tab. \n\n\nIn the address bar, type in the address of your galaxy server.\n\n\ne.g. \nhttp://galaxy-mel.genome.edu.au/galaxy\n or \nhttps://galaxy-qld.genome.edu.au/galaxy\n\n\n\n\n\n\n\n\n\n\nClick on \nUser\n button on the right.\n\n\n\n\n\n\nSelect: \nUser \n Register\n\n\nEnter your email, choose a password, and choose a user name.\n\n\n\n\nClick \nSubmit\n\n\n\n\n\n\nLogin, and refresh the page.\n\n\n\n\n\n\nImport a shared history\n\n\nFor Galaxy-mel/Galaxy-qld users, import the following history: \n\n\n\n\nIn Galaxy, go to the top menu bar\n\n\n\n\nClick on \nShared Data\n \n\n\n\n\n\n\nFrom the drop down menu, click on \nHistories\n\n\n\n\n\n\n\n\n\n\nFrom the list of Published Histories, click \nGenomics-workshop\n \n\n\n\n\n\n\n\n\nIn the top right, click on \nImport history\n\n\n\n\n\n\n\n\nThis history will now be in your \nCurrent history\n - the right hand pane in Galaxy. \n\n\nThere should be six files. (The number in front of the file name is not important.)\n\n\n\n\n\n\n\n\nWe will use these files for the Genomics Workshop. For additional ways to import histories, see below. \n\n\n\n\nHow to use Galaxy\n\n\n\n\n\n\nAvailable tools are in the left hand panel. Find the tool you want or use the search bar at the top of the tools. \n\n\n\n\n\n\nClick on the tool you want to use. \n\n\n\n\n\n\nThe tool interface will appear in the centre Galaxy panel. Check the settings. \n\n\n\n\n\n\nClick \nExecute\n.\n\n\n\n\n\n\nWhen the tool has finished, output file(s) will appear at the top of your \nCurrent History\n in the right hand panel. \n\n\n\n\n\n\nClick on the eye icon next to a file to view it. \n\n\n\n\n\n\nTo access older histories, use the button at the top right of the History panel. \n\n\n\n\n\n\nAlternative file import information\n\n\n\n\n\nCopy this link:\n\n\nhttps://swift.rc.nectar.org.au:8888/v1/AUTH_377/public/Microbial_tutorials/Galaxy_history_input_files.tar.gz\n\n\n\n\nClick on the \nHistory\n cog \n\n\nSelect \nImport from File\n\n\n\n\n\n\n\n\nIn the box called \nArchived History URL\n, paste in the link address to the Galaxy history (that you copied above).\n\n\nClick \nSubmit\n\n\nWait a few seconds.\n\n\nClick on the \nview all histories\n button \n\n\nSee if the Galaxy history has been imported: it will be called \nimported from archive: Data\n\n\nAbove that pane, click on the \nSwitch to\n button.\n\n\nThen click \nDone\n (in the top left corner).\n\n\nYou should now have a list of five files in your current history. We will use these for the Genomics Workshop; or see below for additional files.\n\n\n\n\n\n\nOther ways to import data into Galaxy\n\n\n\n\nUpload a file from your computer\n\n\nImport a shared history\n\n\nSee the \nnext section\n for more detailed information.", 
            "title": "Starting with Galaxy"
        }, 
        {
            "location": "/modules/galaxy/#starting-with-galaxy", 
            "text": "Keywords: Galaxy, Microbial Genomics Virtual Lab", 
            "title": "Starting with Galaxy"
        }, 
        {
            "location": "/modules/galaxy/#background", 
            "text": "Galaxy is a web-based analysis and workflow platform designed for biologists to analyse their own data. It can be used to run a variety of bioinformatics tools. The selection of bioinformatics tools installed on the Galaxy instance we are using today caters for the analysis of bacterial genomics data sets.  Galaxy is an open, web-based platform. Details about the project can be found  here .  The Galaxy interface is separated into three parts. The  Tools  list on the left, the  Viewing  panel in the middle and the analysis and data  History  on the right.", 
            "title": "Background"
        }, 
        {
            "location": "/modules/galaxy/#register", 
            "text": "Use Firefox, Chrome or Safari as your browser (not Internet Explorer).  Open a new tab.   In the address bar, type in the address of your galaxy server.  e.g.  http://galaxy-mel.genome.edu.au/galaxy  or  https://galaxy-qld.genome.edu.au/galaxy      Click on  User  button on the right.    Select:  User   Register  Enter your email, choose a password, and choose a user name.   Click  Submit    Login, and refresh the page.", 
            "title": "Register"
        }, 
        {
            "location": "/modules/galaxy/#import-a-shared-history", 
            "text": "For Galaxy-mel/Galaxy-qld users, import the following history:    In Galaxy, go to the top menu bar   Click on  Shared Data      From the drop down menu, click on  Histories      From the list of Published Histories, click  Genomics-workshop       In the top right, click on  Import history     This history will now be in your  Current history  - the right hand pane in Galaxy.   There should be six files. (The number in front of the file name is not important.)     We will use these files for the Genomics Workshop. For additional ways to import histories, see below.", 
            "title": "Import a shared history"
        }, 
        {
            "location": "/modules/galaxy/#how-to-use-galaxy", 
            "text": "Available tools are in the left hand panel. Find the tool you want or use the search bar at the top of the tools.     Click on the tool you want to use.     The tool interface will appear in the centre Galaxy panel. Check the settings.     Click  Execute .    When the tool has finished, output file(s) will appear at the top of your  Current History  in the right hand panel.     Click on the eye icon next to a file to view it.     To access older histories, use the button at the top right of the History panel.", 
            "title": "How to use Galaxy"
        }, 
        {
            "location": "/modules/galaxy/#alternative-file-import-information", 
            "text": "Copy this link:  https://swift.rc.nectar.org.au:8888/v1/AUTH_377/public/Microbial_tutorials/Galaxy_history_input_files.tar.gz   Click on the  History  cog   Select  Import from File     In the box called  Archived History URL , paste in the link address to the Galaxy history (that you copied above).  Click  Submit  Wait a few seconds.  Click on the  view all histories  button   See if the Galaxy history has been imported: it will be called  imported from archive: Data  Above that pane, click on the  Switch to  button.  Then click  Done  (in the top left corner).  You should now have a list of five files in your current history. We will use these for the Genomics Workshop; or see below for additional files.", 
            "title": "Alternative file import information"
        }, 
        {
            "location": "/modules/galaxy/#other-ways-to-import-data-into-galaxy", 
            "text": "Upload a file from your computer  Import a shared history  See the  next section  for more detailed information.", 
            "title": "Other ways to import data into Galaxy"
        }, 
        {
            "location": "/modules/data-dna/", 
            "text": "Dataset\n\n\nImport a Galaxy history\n\n\nCopy this link:\n\n\nhttps://swift.rc.nectar.org.au:8888/v1/AUTH_377/public/Microbial_tutorials/Galaxy_history_input_files.tar.gz\n\n\n\n\nGo to your Galaxy instance. Make sure you are registered and logged in. Refresh the page.\n\n\nClick on the \nHistory\n cog \n\n\nSelect \nImport from File\n\n\n\n\n\n\n\n\nIn the box called \nArchived History URL\n, paste in the link address to the Galaxy history (that you copied above).\n\n\nClick \nSubmit\n\n\nWait a few seconds.\n\n\nClick on the \nview all histories\n button \n\n\nSee if the Galaxy history has been imported: it will be called \nimported from archive: Data\n\n\nAbove that pane, click on the \nSwitch to\n button.\n\n\nThen click \nDone\n (in the top left corner).\n\n\nYou should now have a list of five files in your current history. We will use these for the Genomics Workshop; or see below for additional files.\n\n\n\n\n\n\nAdditional Galaxy histories\n\n\nIf you are using only part of the Genomics Workshop, you can upload any required histories listed here. Follow the instructions above.\n\n\nGalaxy history: FastQC\n\n\nhttps://swift.rc.nectar.org.au:8888/v1/AUTH_377/public/Microbial_tutorials/FastQChistory.tar.gz\n\n\nGalaxy history: Spades\n\n\nhttps://swift.rc.nectar.org.au:8888/v1/AUTH_377/public/Microbial_tutorials/Spadeshistory.tar.gz\n\n\nGalaxy history: Prokka\n\n\nhttps://swift.rc.nectar.org.au:8888/v1/AUTH_377/public/Microbial_tutorials/Prokkahistory.tar.gz\n\n\nGalaxy history: Snippy\n\n\nhttps://swift.rc.nectar.org.au:8888/v1/AUTH_377/public/Microbial_tutorials/Snippyhistory.tar.gz\n\n\nGalaxy history: Workflows\n\n\nhttps://swift.rc.nectar.org.au:8888/v1/AUTH_377/public/Microbial_tutorials/Galaxy-History-Workflows-history.tar.gz\n\n\nAdditional files\n\n\nIf you need individual files, you can upload any of the files listed here. The instructions are listed below.\n\n\nWildtype reference\n\n\n\n\nwildtype.fna\n\n\n\n\n https://swift.rc.nectar.org.au:8888/v1/AUTH_377/public/Microbial_tutorials/wildtype.fna\n\n\n\n\nwildtype.gbk\n\n\n\n\n https://swift.rc.nectar.org.au:8888/v1/AUTH_377/public/Microbial_tutorials/wildtype.gbk\n\n\n\n\nwildtype.gff\n\n\n\n\n https://swift.rc.nectar.org.au:8888/v1/AUTH_377/public/Microbial_tutorials/wildtype.gff\n\n\nMutant Illumina sequence\n\n\n\n\nmutant_R1.fastq.gz\n\n\n\n\n https://swift.rc.nectar.org.au:8888/v1/AUTH_377/public/Microbial_tutorials/mutant_R1.fastq.gz\n\n\n\n\nmutant_R2.fastq.gz\n\n\n\n\nhttps://swift.rc.nectar.org.au:8888/v1/AUTH_377/public/Microbial_tutorials/mutant_R2.fastq.gz\n\n\nAssembled contigs\n\n\n\n\nSPAdes_contigs.fasta\n\n\n\n\nhttps://swift.rc.nectar.org.au:8888/v1/AUTH_377/public/Microbial_tutorials/SPAdes_contigs.fasta\n\n\nUpload to Galaxy\n\n\nThere are two ways to upload these files to Galaxy. You can either download to your local computer and upload to Galaxy, or you can tell Galaxy to directly upload the file from an external source.\n\n\nDownload and upload:\n\n\n\n\nDownload required file(s) to your computer.\n\n\nFrom the Galaxy tool panel, click on \nGet Data \n Upload File\n  \n\n\nClick the \nChoose local file\n button  \n\n\nFind and select the \nfile\n you downloaded and click \nOpen\n  \n\n\nSet the \nType\n correctly.  \n\n\nClick the \nStart\n button.  \n\n\nOnce the progress bar reaches 100%, click the \nClose\n button  \n\n\nThe file will now upload to your current history.\n\n\n\n\nOr, tell Galaxy to find the file from an external source:\n\n\n\n\nFrom the Galaxy tool panel, click on \nGet Data \n Upload File\n  \n\n\nClick the \nPaste/Fetch data\n button  \n\n\nPaste the URL into the box.\n\n\nClick the \nStart\n button.  \n\n\nOnce the progress bar reaches 100%, click the \nClose\n button  \n\n\nThe file will now upload to your current history.", 
            "title": "Training dataset"
        }, 
        {
            "location": "/modules/data-dna/#dataset", 
            "text": "", 
            "title": "Dataset"
        }, 
        {
            "location": "/modules/data-dna/#import-a-galaxy-history", 
            "text": "Copy this link:  https://swift.rc.nectar.org.au:8888/v1/AUTH_377/public/Microbial_tutorials/Galaxy_history_input_files.tar.gz   Go to your Galaxy instance. Make sure you are registered and logged in. Refresh the page.  Click on the  History  cog   Select  Import from File     In the box called  Archived History URL , paste in the link address to the Galaxy history (that you copied above).  Click  Submit  Wait a few seconds.  Click on the  view all histories  button   See if the Galaxy history has been imported: it will be called  imported from archive: Data  Above that pane, click on the  Switch to  button.  Then click  Done  (in the top left corner).  You should now have a list of five files in your current history. We will use these for the Genomics Workshop; or see below for additional files.", 
            "title": "Import a Galaxy history"
        }, 
        {
            "location": "/modules/data-dna/#additional-galaxy-histories", 
            "text": "If you are using only part of the Genomics Workshop, you can upload any required histories listed here. Follow the instructions above.", 
            "title": "Additional Galaxy histories"
        }, 
        {
            "location": "/modules/data-dna/#galaxy-history-fastqc", 
            "text": "https://swift.rc.nectar.org.au:8888/v1/AUTH_377/public/Microbial_tutorials/FastQChistory.tar.gz", 
            "title": "Galaxy history: FastQC"
        }, 
        {
            "location": "/modules/data-dna/#galaxy-history-spades", 
            "text": "https://swift.rc.nectar.org.au:8888/v1/AUTH_377/public/Microbial_tutorials/Spadeshistory.tar.gz", 
            "title": "Galaxy history: Spades"
        }, 
        {
            "location": "/modules/data-dna/#galaxy-history-prokka", 
            "text": "https://swift.rc.nectar.org.au:8888/v1/AUTH_377/public/Microbial_tutorials/Prokkahistory.tar.gz", 
            "title": "Galaxy history: Prokka"
        }, 
        {
            "location": "/modules/data-dna/#galaxy-history-snippy", 
            "text": "https://swift.rc.nectar.org.au:8888/v1/AUTH_377/public/Microbial_tutorials/Snippyhistory.tar.gz", 
            "title": "Galaxy history: Snippy"
        }, 
        {
            "location": "/modules/data-dna/#galaxy-history-workflows", 
            "text": "https://swift.rc.nectar.org.au:8888/v1/AUTH_377/public/Microbial_tutorials/Galaxy-History-Workflows-history.tar.gz", 
            "title": "Galaxy history: Workflows"
        }, 
        {
            "location": "/modules/data-dna/#additional-files", 
            "text": "If you need individual files, you can upload any of the files listed here. The instructions are listed below.", 
            "title": "Additional files"
        }, 
        {
            "location": "/modules/data-dna/#wildtype-reference", 
            "text": "wildtype.fna    https://swift.rc.nectar.org.au:8888/v1/AUTH_377/public/Microbial_tutorials/wildtype.fna   wildtype.gbk    https://swift.rc.nectar.org.au:8888/v1/AUTH_377/public/Microbial_tutorials/wildtype.gbk   wildtype.gff    https://swift.rc.nectar.org.au:8888/v1/AUTH_377/public/Microbial_tutorials/wildtype.gff", 
            "title": "Wildtype reference"
        }, 
        {
            "location": "/modules/data-dna/#mutant-illumina-sequence", 
            "text": "mutant_R1.fastq.gz    https://swift.rc.nectar.org.au:8888/v1/AUTH_377/public/Microbial_tutorials/mutant_R1.fastq.gz   mutant_R2.fastq.gz   https://swift.rc.nectar.org.au:8888/v1/AUTH_377/public/Microbial_tutorials/mutant_R2.fastq.gz", 
            "title": "Mutant Illumina sequence"
        }, 
        {
            "location": "/modules/data-dna/#assembled-contigs", 
            "text": "SPAdes_contigs.fasta   https://swift.rc.nectar.org.au:8888/v1/AUTH_377/public/Microbial_tutorials/SPAdes_contigs.fasta", 
            "title": "Assembled contigs"
        }, 
        {
            "location": "/modules/data-dna/#upload-to-galaxy", 
            "text": "There are two ways to upload these files to Galaxy. You can either download to your local computer and upload to Galaxy, or you can tell Galaxy to directly upload the file from an external source.  Download and upload:   Download required file(s) to your computer.  From the Galaxy tool panel, click on  Get Data   Upload File     Click the  Choose local file  button    Find and select the  file  you downloaded and click  Open     Set the  Type  correctly.    Click the  Start  button.    Once the progress bar reaches 100%, click the  Close  button    The file will now upload to your current history.   Or, tell Galaxy to find the file from an external source:   From the Galaxy tool panel, click on  Get Data   Upload File     Click the  Paste/Fetch data  button    Paste the URL into the box.  Click the  Start  button.    Once the progress bar reaches 100%, click the  Close  button    The file will now upload to your current history.", 
            "title": "Upload to Galaxy"
        }, 
        {
            "location": "/modules/fastqc/", 
            "text": "FastQC in Galaxy\n\n\n\n\n\nAfter sequencing, the reads should be checked for their quality. This tutorial demonstrates how to use the tool called FastQC to examine bacterial paired-end Illumina sequence reads. The FastQC website is \nhere.\n\n\nLearning Objectives\n\n\nAt the end of this tutorial you should be able to:\n\n\n\n\nrun FastQC on input sequence reads, and\n\n\nexamine the FastQC output.\n\n\n\n\nInput files\n\n\nSee \nhere\n for information about how to start with Galaxy, and \nhere\n for the link to import the \nGalaxy history of input files\n for this tutorial, if you don\nt already have them in your history.\n\n\n\n\nWe will use the paired-end read set from our Galaxy history.\n\n\nThese are the files \nmutant_R1.fastq\n and \nmutant_R2.fastq\n.\n\n\nFASTQ is a file format for sequence reads that displays quality scores for each of the sequenced nucleotides. For more information about FASTQ format see this \nlink\n.\n\n\nWe will evaluate the \nmutant_R1.fastq\n reads using the FastQC tool.\n\n\n\n\nRun FastQC\n\n\n\n\nGo to \nTools \n NGS Analysis \n NGS: QC and Manipulation \n FastQC\n\n\n\n\n\n\n\n\nfor \nShort read data from your current history\n: \nmutant_R1.fastq\n\n\nClick \nExecute\n\n\nIn the History pane, click on the \nrefresh\n icon to see if the analysis has finished.\n\n\n\n\nExamine output files\n\n\nOnce finished, examine the output called \nFastQC on data1:webpage\n (Hint: click the eye icon). It has a summary at the top of the page and a number of graphs.\n\n\nLook at:\n\n\n\n\n\n\nBasic Statistics\n\n\n\n\nSequence length\n: will be important in setting maximum k-mer size value for assembly.\n\n\nEncoding\n: The quality encoding type is important for quality trimming software.\n\n\n% GC\n: high GC organisms don\u2019t tend to assemble well and may have an uneven read coverage distribution.\n\n\nTotal sequences\n: Total number of reads: gives you an idea of coverage.\n\n\n\n\n\n\n\n\nPer base sequence quality\n: Dips in quality near the beginning, middle or end of the reads: determines possible trimming/cleanup methods and parameters and may indicate technical problems with the sequencing process/machine run. In this case, all the reads are of relatively high quality across their length (150 bp).\n\n\n\n\n\n\n\n\n\n\n\n\nPer base N content\n: Presence of large numbers of Ns in reads may point to a poor quality sequencing run. You would need to trim these reads to remove Ns.\n\n\n\n\n\n\nKmer content\n: Presence of highly recurring k-mers: may point to contamination of reads with barcodes, adapter sequences etc. In this case, we have spikes in two types of kmers. \n\n\n\n\n\n\n\n\nWe have warnings for two outputs (per base sequence content; Kmer content). This would warrant more investigation.\n\n\nGeneral questions you might ask about your input reads include:\n\n\n\n\nHow good is my read set?\n\n\nDo I need to ask for a new sequencing run?  \n\n\nIs it suitable for the analysis I need to do?\n\n\n\n\nFor a fuller discussion of FastQC outputs and warnings, see the \nFastQC website link\n, including the section on each of the output \nreports\n, and examples of \ngood\n and \nbad\n Illumina data.\n\n\nWhat Next?\n\n\nAssemble the reads into a draft genome sequence\n.", 
            "title": "Quality control"
        }, 
        {
            "location": "/modules/fastqc/#fastqc-in-galaxy", 
            "text": "After sequencing, the reads should be checked for their quality. This tutorial demonstrates how to use the tool called FastQC to examine bacterial paired-end Illumina sequence reads. The FastQC website is  here.", 
            "title": "FastQC in Galaxy"
        }, 
        {
            "location": "/modules/fastqc/#learning-objectives", 
            "text": "At the end of this tutorial you should be able to:   run FastQC on input sequence reads, and  examine the FastQC output.", 
            "title": "Learning Objectives"
        }, 
        {
            "location": "/modules/fastqc/#input-files", 
            "text": "See  here  for information about how to start with Galaxy, and  here  for the link to import the  Galaxy history of input files  for this tutorial, if you don t already have them in your history.   We will use the paired-end read set from our Galaxy history.  These are the files  mutant_R1.fastq  and  mutant_R2.fastq .  FASTQ is a file format for sequence reads that displays quality scores for each of the sequenced nucleotides. For more information about FASTQ format see this  link .  We will evaluate the  mutant_R1.fastq  reads using the FastQC tool.", 
            "title": "Input files"
        }, 
        {
            "location": "/modules/fastqc/#run-fastqc", 
            "text": "Go to  Tools   NGS Analysis   NGS: QC and Manipulation   FastQC     for  Short read data from your current history :  mutant_R1.fastq  Click  Execute  In the History pane, click on the  refresh  icon to see if the analysis has finished.", 
            "title": "Run FastQC"
        }, 
        {
            "location": "/modules/fastqc/#examine-output-files", 
            "text": "Once finished, examine the output called  FastQC on data1:webpage  (Hint: click the eye icon). It has a summary at the top of the page and a number of graphs.  Look at:    Basic Statistics   Sequence length : will be important in setting maximum k-mer size value for assembly.  Encoding : The quality encoding type is important for quality trimming software.  % GC : high GC organisms don\u2019t tend to assemble well and may have an uneven read coverage distribution.  Total sequences : Total number of reads: gives you an idea of coverage.     Per base sequence quality : Dips in quality near the beginning, middle or end of the reads: determines possible trimming/cleanup methods and parameters and may indicate technical problems with the sequencing process/machine run. In this case, all the reads are of relatively high quality across their length (150 bp).       Per base N content : Presence of large numbers of Ns in reads may point to a poor quality sequencing run. You would need to trim these reads to remove Ns.    Kmer content : Presence of highly recurring k-mers: may point to contamination of reads with barcodes, adapter sequences etc. In this case, we have spikes in two types of kmers.      We have warnings for two outputs (per base sequence content; Kmer content). This would warrant more investigation.  General questions you might ask about your input reads include:   How good is my read set?  Do I need to ask for a new sequencing run?    Is it suitable for the analysis I need to do?   For a fuller discussion of FastQC outputs and warnings, see the  FastQC website link , including the section on each of the output  reports , and examples of  good  and  bad  Illumina data.", 
            "title": "Examine output files"
        }, 
        {
            "location": "/modules/fastqc/#what-next", 
            "text": "Assemble the reads into a draft genome sequence .", 
            "title": "What Next?"
        }, 
        {
            "location": "/modules/pear/", 
            "text": "Pear\n\n\nPear\n is a tool to merge paired-end sequencing reads, prior to downstream tasks such as assembly.\n\n\nGet data\n\n\nInput: paired-end reads.\n\n\n\n\nWe will use a set of Illumina MiSeq reads from the bacteria \nStaphylococcus aureus\n.\n\n\n\n\nGo to your Galaxy server.\n\n\n\n\nIn the tool panel, go to \nGet Data: Upload File\n\n\nSelect \nPaste/Fetch data\n\n\nIn the box, paste in:\n\n\n\n\nftp://ftp.sra.ebi.ac.uk/vol1/fastq/ERR171/008/ERR1712338/ERR1712338_2.fastq.gz\n\n\nftp://ftp.sra.ebi.ac.uk/vol1/fastq/ERR171/008/ERR1712338/ERR1712338_1.fastq.gz\n\n\n\n\nClick \nStart\n and then \nClose\n.\n\n\nThese two files will upload to your current Galaxy history.\n\n\nUsing the pencil icon, change the filetype to \nfastqsanger\n, and shorten the name of the file.\n\n\n\n\n\n\nRun Pear\n\n\nIn the tool panel, go to \nNGS Analysis: NGS QC and manipulation: Pear\n\n\n\n\nDataset type\n: \nPaired-end\n\n\nName of file that contains the forward paired-end reads\n: \nERR1712338_1.fastq\n\n\nName of file that contains the reverse paired-end reads\n: \nERR1712338_2.fastq\n\n\nLeave other settings as per defaults, except:\n\n\nMaximal proportion of uncalled bases in a read\n: \n0.01\n\n\nomits reads if \n1% of the reads is missing (N)\n\n\n\n\n\n\nOutput files\n: \nSelect all\n\n\n\n\nYour tool interface should look like this:\n\n\n\n\n\n\nClick \nExecute\n\n\n\n\nResults\n\n\nThere are four output files.\n\n\n\n\nAssembled reads\n: merged paired-end reads.\n\n\nUnassembled forward reads\n and \nUnassembled reverse reads\n: remaining, unmerged reads.\n\n\nDiscarded reads\n: Did not meet quality specified\n\n\n\n\nIn this case, most of the reads have been merged (~360MB); 90MB are unmerged, and 350 sequences have been discarded.\n\n\nNext\n\n\nRun Trimmomatic to trim sequences before assembling.\n\n\nLinks\n\n\nPear paper\n\n\nPear software", 
            "title": "Merge reads with Pear"
        }, 
        {
            "location": "/modules/pear/#pear", 
            "text": "Pear  is a tool to merge paired-end sequencing reads, prior to downstream tasks such as assembly.", 
            "title": "Pear"
        }, 
        {
            "location": "/modules/pear/#get-data", 
            "text": "Input: paired-end reads.   We will use a set of Illumina MiSeq reads from the bacteria  Staphylococcus aureus .   Go to your Galaxy server.   In the tool panel, go to  Get Data: Upload File  Select  Paste/Fetch data  In the box, paste in:   ftp://ftp.sra.ebi.ac.uk/vol1/fastq/ERR171/008/ERR1712338/ERR1712338_2.fastq.gz  ftp://ftp.sra.ebi.ac.uk/vol1/fastq/ERR171/008/ERR1712338/ERR1712338_1.fastq.gz   Click  Start  and then  Close .  These two files will upload to your current Galaxy history.  Using the pencil icon, change the filetype to  fastqsanger , and shorten the name of the file.", 
            "title": "Get data"
        }, 
        {
            "location": "/modules/pear/#run-pear", 
            "text": "In the tool panel, go to  NGS Analysis: NGS QC and manipulation: Pear   Dataset type :  Paired-end  Name of file that contains the forward paired-end reads :  ERR1712338_1.fastq  Name of file that contains the reverse paired-end reads :  ERR1712338_2.fastq  Leave other settings as per defaults, except:  Maximal proportion of uncalled bases in a read :  0.01  omits reads if  1% of the reads is missing (N)    Output files :  Select all   Your tool interface should look like this:    Click  Execute", 
            "title": "Run Pear"
        }, 
        {
            "location": "/modules/pear/#results", 
            "text": "There are four output files.   Assembled reads : merged paired-end reads.  Unassembled forward reads  and  Unassembled reverse reads : remaining, unmerged reads.  Discarded reads : Did not meet quality specified   In this case, most of the reads have been merged (~360MB); 90MB are unmerged, and 350 sequences have been discarded.", 
            "title": "Results"
        }, 
        {
            "location": "/modules/pear/#next", 
            "text": "Run Trimmomatic to trim sequences before assembling.", 
            "title": "Next"
        }, 
        {
            "location": "/modules/pear/#links", 
            "text": "Pear paper  Pear software", 
            "title": "Links"
        }, 
        {
            "location": "/modules/velvet/", 
            "text": "Assembly using Velvet\n\n\nKeywords: de novo assembly, Velvet, Galaxy, Microbial Genomics Virtual Lab\n\n\nBackground\n\n\nVelvet is one of a number of \nde novo\n assemblers that use short read sets as input (e.g. Illumina Reads), and the assembly method is based on de Bruijn graphs. For information about Velvet see this \nlink\n.\n\n\n\n\n\nIn this activity, we will perform a \nde novo\n assembly of a short read set using the Velvet assembler.\n\n\nLearning objectives\n\n\nAt the end of this tutorial you should be able to:\n\n\n\n\nassemble the reads using Velvet, and\n\n\nexamine the output assembly.\n\n\n\n\nImport and view data\n\n\nIf you have completed the previous tutorial on \nQuality Control\n, you should already have the required files in your current Galaxy history. If not, see how to get them \nhere\n.\n\n\n\n\n\nThe data\n\n\nThe read set for today is from an imaginary \nStaphylococcus aureus\n bacterium with a miniature genome. The whole genome shotgun method used to sequence our mutant strain read set was produced on an Illumina DNA sequencing instrument.\n\n\n\n\nThe files we need for assembly are the \nmutant_R1.fastq\n and \nmutant_R2.fastq\n.\n\n\n\n\n(We don\nt need the reference genome sequences for this tutorial).\n\n\n\n\n\n\nThe reads are paired-end.\n\n\n\n\n\n\nEach read is 150 bases long. \n\n\n\n\n\n\nThe number of bases sequenced is equivalent to 19x the genome sequence of the wildtype strain. (Read coverage 19x - rather low!).\n\n\n\n\n\n\n\n\n\n\n\nClick on the View Data button (the \n) next to one of the FASTQ sequence files.\n\n\n\n\n\n\n\nAssemble reads with Velvet\n\n\n\n\nWe will perform a \nde novo\n assembly of the mutant FASTQ reads into long contiguous sequences (in FASTA format.)\n\n\nVelvet requires the user to input a value of \nk\n for the assembly process. K-mers are fragments of sequence reads. Small k-mers will give greater connectivity, but large k-mers will give better specificity.\n\n\n\n\n\n\n\n\n\nGo to \nTools \n NGS Analysis \n NGS: Assembly \n velvet\n\n\n\n\nSet the following parameters (leave other settings as they are):\n\n\n\n\nK-mer\n: Enter the value for \nk\n that you have been assigned in the spreadsheet.\n\n\n\n\n\n\n\n\n\nInput file type\n: Fastq\n\n\nSingle or paired end reads\n: Paired\n\n\n Select first set of reads\n: \nmutant_R1.fastq\n  \n\n\n Select second set of reads\n: \nmutant_R2.fastq\n\n\n\n\n\n\n\n\nYour tool interface should look like this (you will most likely have a different value for k):\n\n\n\n\n\n\n\n\n\n\nClick \nExecute\n\n\n\n\nExamine the output\n\n\n\n\nGalaxy is now running velvet on the reads for you.\n\n\nPress the refresh button in the history pane to see if it has finished.\n\n\n\n\nWhen it is finished, you will have four new files in your history.  \n\n\n\n\na \nContigs\n file\n\n\na \nContigs stats\n file\n\n\nthe velvet \nlog\n file\n\n\nan assembly \nLast Graph\n file\n\n\n\n\n\n\n\n\nClick on the View Data button \n on each of the files.\n\n\n\n\n\n\nThe \nContigs\n file will show each contig with the \nk-mer length\n and \nk-mer coverage\n listed as part of the header (however, these are just called \nlength\n and \ncoverage\n).\n\n\n\n\nK-mer length\n: For the value of k chosen in the assembly, a measure of how many k-mers overlap (by 1 bp each overlap) to give this length.\n\n\nK-mer coverage\n: For the value of k chosen in the assembly, a measure of how many k-mers overlap each base position (in the assembly).\n\n\n\n\n\n\n\n\n\n\n\n\nThe \nContigs stats\n file will show a list of these k-mer lengths and k-mer coverages.\n\n\n\n\n\n\n\n\nWe will summarise the information in the \nlog\n file.\n\n\nGo to \nNGS Common Toolsets \n FASTA manipulation \n Fasta statistics\n\n\nFor the required input file, choose the velvet \nContigs\n file.\n\n\nClick \nExecute\n.\n\n\nA new file will appear called \nFasta summary stats\n\n\nClick the eye icon to look at this file.\n\n\n\n\n\n\n\n\nLook at:\n\n\nnum_seq\n: the number of contigs in the FASTA file.\n\n\nnum_bp\n: the number of assembled bases. Roughly proportional to genome size.\n\n\nlen_max\n: the biggest contig.  \n\n\nlen_N50\n: N50 is a contig size. If contigs were ordered from small to large, half of all the nucleotides will be in contigs this size or larger.\n\n\n\n\n\n\n\n\nNow copy the relevant data back into the k-mer spreadsheet on your line.\n\n\nAlong with the demonstrator, have a look at the effect of the k-mer size on the output metrics of the assembly. Note that there are local maxima and minima in the charts.\n\n\n\n\n\nAssembly with Velvet Optimiser\n\n\nNow that we have seen the effect of k-mer size on the assembly, we will run the Velvet Optimiser to automatically choose the best k-mer size for us. It will use the \nn50\n to determine the best k-mer value to use. It then performs the further graph cleaning steps and automatically chooses other parameters for velvet. We should get a much better assembly result than we did with our attempts with Velvet alone.\n\n\n\n\nGo to \nTools \n NGS Analysis \n NGS: Assembly \n Velvet Optimiser\n\n\n\n\nSet the following parameters (leave other settings as they are):\n\n\n\n\nStart k-mer size\n: 45\n\n\nEnd k-mer size\n: 73\n\n\nInput file type\n: Fastq\n\n\nSingle or paired end reads\n: Paired\n\n\n Select first set of reads\n: \nmutant_R1.fastq\n  \n\n\n\n\n Select second set of reads\n: \nmutant_R2.fastq\n\n\n\n\n\n\nClick \nExecute\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nUse the Fasta Statistics tool you used earlier to summarise the Velvet Optimiser \nContigs\n output. Examine the resulting table. What are the main differences?", 
            "title": "Genome assembly with Velvet"
        }, 
        {
            "location": "/modules/velvet/#assembly-using-velvet", 
            "text": "Keywords: de novo assembly, Velvet, Galaxy, Microbial Genomics Virtual Lab", 
            "title": "Assembly using Velvet"
        }, 
        {
            "location": "/modules/velvet/#background", 
            "text": "Velvet is one of a number of  de novo  assemblers that use short read sets as input (e.g. Illumina Reads), and the assembly method is based on de Bruijn graphs. For information about Velvet see this  link .   In this activity, we will perform a  de novo  assembly of a short read set using the Velvet assembler.", 
            "title": "Background"
        }, 
        {
            "location": "/modules/velvet/#learning-objectives", 
            "text": "At the end of this tutorial you should be able to:   assemble the reads using Velvet, and  examine the output assembly.", 
            "title": "Learning objectives"
        }, 
        {
            "location": "/modules/velvet/#import-and-view-data", 
            "text": "If you have completed the previous tutorial on  Quality Control , you should already have the required files in your current Galaxy history. If not, see how to get them  here .", 
            "title": "Import and view data"
        }, 
        {
            "location": "/modules/velvet/#the-data", 
            "text": "The read set for today is from an imaginary  Staphylococcus aureus  bacterium with a miniature genome. The whole genome shotgun method used to sequence our mutant strain read set was produced on an Illumina DNA sequencing instrument.   The files we need for assembly are the  mutant_R1.fastq  and  mutant_R2.fastq .   (We don t need the reference genome sequences for this tutorial).    The reads are paired-end.    Each read is 150 bases long.     The number of bases sequenced is equivalent to 19x the genome sequence of the wildtype strain. (Read coverage 19x - rather low!).      Click on the View Data button (the  ) next to one of the FASTQ sequence files.", 
            "title": "The data"
        }, 
        {
            "location": "/modules/velvet/#assemble-reads-with-velvet", 
            "text": "We will perform a  de novo  assembly of the mutant FASTQ reads into long contiguous sequences (in FASTA format.)  Velvet requires the user to input a value of  k  for the assembly process. K-mers are fragments of sequence reads. Small k-mers will give greater connectivity, but large k-mers will give better specificity.     Go to  Tools   NGS Analysis   NGS: Assembly   velvet   Set the following parameters (leave other settings as they are):   K-mer : Enter the value for  k  that you have been assigned in the spreadsheet.     Input file type : Fastq  Single or paired end reads : Paired   Select first set of reads :  mutant_R1.fastq      Select second set of reads :  mutant_R2.fastq     Your tool interface should look like this (you will most likely have a different value for k):      Click  Execute", 
            "title": "Assemble reads with Velvet"
        }, 
        {
            "location": "/modules/velvet/#examine-the-output", 
            "text": "Galaxy is now running velvet on the reads for you.  Press the refresh button in the history pane to see if it has finished.   When it is finished, you will have four new files in your history.     a  Contigs  file  a  Contigs stats  file  the velvet  log  file  an assembly  Last Graph  file     Click on the View Data button   on each of the files.    The  Contigs  file will show each contig with the  k-mer length  and  k-mer coverage  listed as part of the header (however, these are just called  length  and  coverage ).   K-mer length : For the value of k chosen in the assembly, a measure of how many k-mers overlap (by 1 bp each overlap) to give this length.  K-mer coverage : For the value of k chosen in the assembly, a measure of how many k-mers overlap each base position (in the assembly).       The  Contigs stats  file will show a list of these k-mer lengths and k-mer coverages.     We will summarise the information in the  log  file.  Go to  NGS Common Toolsets   FASTA manipulation   Fasta statistics  For the required input file, choose the velvet  Contigs  file.  Click  Execute .  A new file will appear called  Fasta summary stats  Click the eye icon to look at this file.     Look at:  num_seq : the number of contigs in the FASTA file.  num_bp : the number of assembled bases. Roughly proportional to genome size.  len_max : the biggest contig.    len_N50 : N50 is a contig size. If contigs were ordered from small to large, half of all the nucleotides will be in contigs this size or larger.     Now copy the relevant data back into the k-mer spreadsheet on your line.  Along with the demonstrator, have a look at the effect of the k-mer size on the output metrics of the assembly. Note that there are local maxima and minima in the charts.", 
            "title": "Examine the output"
        }, 
        {
            "location": "/modules/velvet/#assembly-with-velvet-optimiser", 
            "text": "Now that we have seen the effect of k-mer size on the assembly, we will run the Velvet Optimiser to automatically choose the best k-mer size for us. It will use the  n50  to determine the best k-mer value to use. It then performs the further graph cleaning steps and automatically chooses other parameters for velvet. We should get a much better assembly result than we did with our attempts with Velvet alone.   Go to  Tools   NGS Analysis   NGS: Assembly   Velvet Optimiser   Set the following parameters (leave other settings as they are):   Start k-mer size : 45  End k-mer size : 73  Input file type : Fastq  Single or paired end reads : Paired   Select first set of reads :  mutant_R1.fastq       Select second set of reads :  mutant_R2.fastq    Click  Execute        Use the Fasta Statistics tool you used earlier to summarise the Velvet Optimiser  Contigs  output. Examine the resulting table. What are the main differences?", 
            "title": "Assembly with Velvet Optimiser"
        }, 
        {
            "location": "/modules/spades/", 
            "text": "Assembly using Spades\n\n\nKeywords: de novo assembly, Spades, Galaxy, Microbial Genomics Virtual Lab\n\n\nBackground\n\n\nSpades is one of a number of \nde novo\n assemblers that use short read sets as input (e.g. Illumina Reads), and the assembly method is based on de Bruijn graphs. For information about Spades see this \nlink\n.\n\n\nLearning objectives\n\n\nAt the end of this tutorial you should be able to:\n\n\n\n\nassemble the reads using Spades, and\n\n\nexamine the output assembly.\n\n\n\n\nImport and view data\n\n\n\n\n\nGalaxy\n\n\nIf you are using Galaxy-Mel or Galaxy-Qld, import the files:\n\n\n\n\nIn your browser, go to \nGalaxy-Mel\n or \nGalaxy-Qld\n \n\n\nIn the top Galaxy panel, go to \nUser\n and log in (or register, and then log in)\n\n\nIn the top Galaxy panel, go to \nShared Data\n and click on the drop down arrow\n\n\nClick on \nHistories\n\n\nClick on \nGenomics-workshop\n and then (over in the top right) \nImport history\n\n\nThe files will now be listed in the right hand panel (your current history).\n\n\n\n\n(Alternatively, see \nhere\n for information about how to start with Galaxy, and \nhere\n for the link to import the Galaxy history for this tutorial, if you don\nt already have them in your history.)\n\n\nThe data\n\n\nThe read set for today is from an imaginary \nStaphylococcus aureus\n bacterium with a miniature genome.\n\n\n\n\n\n\nThe whole genome shotgun method used to sequence our mutant strain read set was produced on an Illumina DNA sequencing instrument.\n\n\n\n\n\n\nThe files we need for assembly are the \nmutant_R1.fastq\n and \nmutant_R2.fastq\n.\n\n\n\n\n\n\n(We don\nt need the reference genome sequences for this tutorial).\n\n\n\n\n\n\nThe reads are paired-end.\n\n\n\n\n\n\nEach read is 150 bases long. \n\n\n\n\n\n\nThe number of bases sequenced is equivalent to 19x the genome sequence of the wildtype strain. (Read coverage 19x - rather low!).\n\n\n\n\n\n\n\n\n\n\n\nClick on the View Data button (the \n) next to one of the FASTQ sequence files.\n\n\n\n\n\n\n\nAssemble reads with Spades\n\n\n\n\n\n\nWe will perform a \nde novo\n assembly of the mutant FASTQ reads into long contiguous sequences (in FASTA format.)\n\n\n\n\n\n\nGo to \nTools \n NGS Analysis \n NGS: Assembly \n spades\n\n\n\n\n\n\nSet the following parameters (leave other settings as they are):\n\n\n\n\nRun only Assembly\n: \nYes\n [the \nYes\n button should be darker grey]\n\n\nKmers to use separated by commas:\n \n33,55,91\n  [note: no spaces]  \n\n\nCoverage cutoff:\n \nauto\n  \n\n\nFiles \n Forward reads:\n \nmutant_R1.fastq\n  \n\n\nFiles \n Reverse reads:\n \nmutant_R2.fastq\n  \n\n\n\n\n\n\n\n\nYour tool interface should look like this:\n\n\n\n\n\n\n\n\n\n\nClick \nExecute\n\n\n\n\nExamine the output\n\n\n\n\nGalaxy is now running Spades on the reads for you.\n\n\n\n\nWhen it is finished, you will have five (or more) new files in your history, including:\n\n\n\n\ntwo FASTA files of the resulting contigs and scaffolds\n\n\ntwo files for statistics about these\n\n\nthe Spades logfile\n\n\n\n\n\n\n\n\n\n\n\n\nClick on the View Data button \n on each of the files.\n\n\nNote that the short reads have been assembled into much longer contigs.\n\n\n(However, in this case, the contigs have not been assembled into larger scaffolds.)\n\n\nThe stats files will give you the length of each of the contigs, and the file should look something like this:", 
            "title": "Genome assembly with Spades"
        }, 
        {
            "location": "/modules/spades/#assembly-using-spades", 
            "text": "Keywords: de novo assembly, Spades, Galaxy, Microbial Genomics Virtual Lab", 
            "title": "Assembly using Spades"
        }, 
        {
            "location": "/modules/spades/#background", 
            "text": "Spades is one of a number of  de novo  assemblers that use short read sets as input (e.g. Illumina Reads), and the assembly method is based on de Bruijn graphs. For information about Spades see this  link .", 
            "title": "Background"
        }, 
        {
            "location": "/modules/spades/#learning-objectives", 
            "text": "At the end of this tutorial you should be able to:   assemble the reads using Spades, and  examine the output assembly.", 
            "title": "Learning objectives"
        }, 
        {
            "location": "/modules/spades/#import-and-view-data", 
            "text": "", 
            "title": "Import and view data"
        }, 
        {
            "location": "/modules/spades/#galaxy", 
            "text": "If you are using Galaxy-Mel or Galaxy-Qld, import the files:   In your browser, go to  Galaxy-Mel  or  Galaxy-Qld    In the top Galaxy panel, go to  User  and log in (or register, and then log in)  In the top Galaxy panel, go to  Shared Data  and click on the drop down arrow  Click on  Histories  Click on  Genomics-workshop  and then (over in the top right)  Import history  The files will now be listed in the right hand panel (your current history).   (Alternatively, see  here  for information about how to start with Galaxy, and  here  for the link to import the Galaxy history for this tutorial, if you don t already have them in your history.)", 
            "title": "Galaxy"
        }, 
        {
            "location": "/modules/spades/#the-data", 
            "text": "The read set for today is from an imaginary  Staphylococcus aureus  bacterium with a miniature genome.    The whole genome shotgun method used to sequence our mutant strain read set was produced on an Illumina DNA sequencing instrument.    The files we need for assembly are the  mutant_R1.fastq  and  mutant_R2.fastq .    (We don t need the reference genome sequences for this tutorial).    The reads are paired-end.    Each read is 150 bases long.     The number of bases sequenced is equivalent to 19x the genome sequence of the wildtype strain. (Read coverage 19x - rather low!).      Click on the View Data button (the  ) next to one of the FASTQ sequence files.", 
            "title": "The data"
        }, 
        {
            "location": "/modules/spades/#assemble-reads-with-spades", 
            "text": "We will perform a  de novo  assembly of the mutant FASTQ reads into long contiguous sequences (in FASTA format.)    Go to  Tools   NGS Analysis   NGS: Assembly   spades    Set the following parameters (leave other settings as they are):   Run only Assembly :  Yes  [the  Yes  button should be darker grey]  Kmers to use separated by commas:   33,55,91   [note: no spaces]    Coverage cutoff:   auto     Files   Forward reads:   mutant_R1.fastq     Files   Reverse reads:   mutant_R2.fastq        Your tool interface should look like this:      Click  Execute", 
            "title": "Assemble reads with Spades"
        }, 
        {
            "location": "/modules/spades/#examine-the-output", 
            "text": "Galaxy is now running Spades on the reads for you.   When it is finished, you will have five (or more) new files in your history, including:   two FASTA files of the resulting contigs and scaffolds  two files for statistics about these  the Spades logfile       Click on the View Data button   on each of the files.  Note that the short reads have been assembled into much longer contigs.  (However, in this case, the contigs have not been assembled into larger scaffolds.)  The stats files will give you the length of each of the contigs, and the file should look something like this:", 
            "title": "Examine the output"
        }, 
        {
            "location": "/modules/prokka/", 
            "text": "Genome annotation using Prokka\n\n\nKeywords: annotation, Prokka, JBrowse, Galaxy, Microbial Genomics Virtual Lab\n\n\nBackground\n\n\nIn this section we will use a software tool called Prokka to annotate the draft genome sequence produced in the previous \ntutorial\n. Prokka is a \u201cwrapper\u201d; it collects together several pieces of software (from various authors), and so avoids \u201cre-inventing the wheel\u201d.\n\n\nProkka finds and annotates features (both protein coding regions and RNA genes, i.e. tRNA, rRNA) present on on a sequence. Note, Prokka uses a two-step process for the annotation of protein coding regions: first, protein coding regions on the genome are identified using \nProdigal\n; second, the \nfunction\n of the encoded protein is predicted by similarity to proteins in one of many protein or protein domain databases. Prokka is a software tool that can be used to annotate bacterial, archaeal and viral genomes quickly, generating standard output files in GenBank, EMBL and gff formats. More information about Prokka can be found \nhere\n.\n\n\nLearning objectives\n\n\nAt the end of this tutorial you should be able to:\n\n\n\n\nload a genome assembly into Prokka\n\n\nannotate the assembly using Prokka\n\n\nexamine the annotated genome using JBrowse\n\n\n\n\nInput data\n\n\nProkka requires assembled contigs.\n\n\n\n\n\n\nIf you are continuing on from the previous workshop (\nAssembly with Spades\n), this file will be in your current history named something like \nSPAdes contigs(fasta)\n. \n\n\n\n\n\n\nOr, if you have uploaded the history of workshop files, there is also a copy in your history called \nSPAdes_contigs.fasta\n. Either copy is fine to use. \n\n\n\n\n\n\nAlternatively, get the file called \nassembled contigs\n from the \nTraining dataset page.\n\n\n\n\n\n\n\n\n\nRun Prokka\n\n\n\n\nIn Galaxy, go to \nTools \n NGS Analysis \n NGS: Annotation \n Prokka\n  \n\n\nSet the following parameters (leave everything else unchanged):\n\n\nContigs to annotate\n: \nSPAdes contigs (fasta)\n  \n\n\nLocus tag prefix (\nlocustag)\n: P\n\n\nForce GenBank/ENA/DDJB compliance (\ncompliant)\n: \nNo\n\n\nSequencing Centre ID (\ncentre)\n: V\n\n\nGenus Name\n: \nStaphylococcus\n  \n\n\nSpecies Name\n: \naureus\n  \n\n\nUse genus-specific BLAST database\n \nNo\n  \n\n\n\n\n\n\n\n\nYour tool interface should look like this:\n\n\n\n\n\n\nClick \nExecute\n  \n\n\n\n\nExamine the output\n\n\n\n\n\nOnce Prokka has finished, examine each of its output files.\n\n\n\n\nThe \nGFF\n and \nGBK\n files contain all of the information about the features annotated (in different formats.)\n\n\nThe \n.txt\n file contains a summary of the number of features annotated.\n\n\nThe \n.faa\n file contains the protein sequences of the genes annotated.\n\n\nThe \n.ffn\n file contains the nucleotide sequences of the genes annotated.\n\n\n\n\nView annotated features in JBrowse\n\n\nNow that we have annotated the draft genome sequence, we would like to view the sequence in the JBrowse genome viewer.\n\n\n\n\n\n\nGo to the Galaxy tool panel, and use the top search box to search for \nJBrowse\n. \n\n\n\n\n\n\nUnder \nReference genome to display\n choose \nUse a genome from history\n.\n\n\n\n\n\n\nUnder \nSelect the reference genome\n choose \nProkka on data XX:fna\n. This .fna sequence is the fasta nucleotide sequence, and will be the reference against which annotations are displayed.\n\n\n\n\n\n\nFor \nProduce a Standalone Instance\n select \nYes\n.\n\n\n\n\n\n\nFor \nGenetic Code\n choose \n11: The Bacterial, Archaeal and Plant Plastid Code\n.\n\n\n\n\n\n\nUnder \nJBrowse-in-Galaxy Action\n choose \nNew JBrowse Instance\n.\n\n\n\n\n\n\nClick \nInsert Track Group\n\n\n\n\n\n\nUnder \nTrack Category\n type in \ngene annotations\n.\n\n\n\n\n\n\nClick \nInsert Annotation Track\n\n\n\n\n\n\nFor \nTrack Type\n choose \nGFF/GFF3/BED/GBK Features\n\n\n\n\n\n\nFor \nGFF/GFF3/BED Track Data\n select \nProkka on data XX:gff\n  [Note: not wildtype.gff]\n\n\n\n\n\n\nUnder \nJBrowse Track Type[Advanced]\n select \nCanvas Features\n.\n\n\n\n\n\n\nClick on \nJBrowse Styling Options \n\n\n\n\n\n\nUnder \nJBrowse style.label\n add in \nproduct\n.\n\n\n\n\n\n\nUnder \nTrack Visibility\n choose \nOn for new users\n.\n\n\n\n\n\n\nYour tool interface should look like this:\n\n\n\n\n\n\n\n\n\n\n\nClick \nExecute\n\n\n\n\n\n\nA new file will be created, called \nJBrowse on data XX and data XX - Complete\n. Click on the eye icon next to the file name. The JBrowse window will appear in the centre Galaxy panel.\n\n\n\n\n\n\nUnder \nAvailable Tracks\n on the left, tick the box for \nProkka on data XX:gff\n.\n\n\n\n\n\n\nSelect contig 1 in the drop down box. You can only see one contig displayed at a time.\n\n\n\n\n\n\n\n\n\n\n\n\nUse the plus and minus buttons to zoom in and out, and the arrows to move left or right (or click and drag within the window to move left or right).\n\n\n\n\n\n\nZoom in to see the reference sequence at the top. JBrowse displays the sequence and a 6-frame amino acid translation.\n\n\n\n\n\n\nZoomed in view:\n\n\n\n\n\n\nRight click on a gene/feature annotation (the bars on the annotation track), then select \nView Details\n to see more information.\n\n\ngene name\n\n\nproduct name\n\n\nyou can download the FASTA sequence by clicking on the disk icon.", 
            "title": "Genome annotation"
        }, 
        {
            "location": "/modules/prokka/#genome-annotation-using-prokka", 
            "text": "Keywords: annotation, Prokka, JBrowse, Galaxy, Microbial Genomics Virtual Lab", 
            "title": "Genome annotation using Prokka"
        }, 
        {
            "location": "/modules/prokka/#background", 
            "text": "In this section we will use a software tool called Prokka to annotate the draft genome sequence produced in the previous  tutorial . Prokka is a \u201cwrapper\u201d; it collects together several pieces of software (from various authors), and so avoids \u201cre-inventing the wheel\u201d.  Prokka finds and annotates features (both protein coding regions and RNA genes, i.e. tRNA, rRNA) present on on a sequence. Note, Prokka uses a two-step process for the annotation of protein coding regions: first, protein coding regions on the genome are identified using  Prodigal ; second, the  function  of the encoded protein is predicted by similarity to proteins in one of many protein or protein domain databases. Prokka is a software tool that can be used to annotate bacterial, archaeal and viral genomes quickly, generating standard output files in GenBank, EMBL and gff formats. More information about Prokka can be found  here .", 
            "title": "Background"
        }, 
        {
            "location": "/modules/prokka/#learning-objectives", 
            "text": "At the end of this tutorial you should be able to:   load a genome assembly into Prokka  annotate the assembly using Prokka  examine the annotated genome using JBrowse", 
            "title": "Learning objectives"
        }, 
        {
            "location": "/modules/prokka/#input-data", 
            "text": "Prokka requires assembled contigs.    If you are continuing on from the previous workshop ( Assembly with Spades ), this file will be in your current history named something like  SPAdes contigs(fasta) .     Or, if you have uploaded the history of workshop files, there is also a copy in your history called  SPAdes_contigs.fasta . Either copy is fine to use.     Alternatively, get the file called  assembled contigs  from the  Training dataset page.", 
            "title": "Input data"
        }, 
        {
            "location": "/modules/prokka/#run-prokka", 
            "text": "In Galaxy, go to  Tools   NGS Analysis   NGS: Annotation   Prokka     Set the following parameters (leave everything else unchanged):  Contigs to annotate :  SPAdes contigs (fasta)     Locus tag prefix ( locustag) : P  Force GenBank/ENA/DDJB compliance ( compliant) :  No  Sequencing Centre ID ( centre) : V  Genus Name :  Staphylococcus     Species Name :  aureus     Use genus-specific BLAST database   No        Your tool interface should look like this:    Click  Execute", 
            "title": "Run Prokka"
        }, 
        {
            "location": "/modules/prokka/#examine-the-output", 
            "text": "Once Prokka has finished, examine each of its output files.   The  GFF  and  GBK  files contain all of the information about the features annotated (in different formats.)  The  .txt  file contains a summary of the number of features annotated.  The  .faa  file contains the protein sequences of the genes annotated.  The  .ffn  file contains the nucleotide sequences of the genes annotated.", 
            "title": "Examine the output"
        }, 
        {
            "location": "/modules/prokka/#view-annotated-features-in-jbrowse", 
            "text": "Now that we have annotated the draft genome sequence, we would like to view the sequence in the JBrowse genome viewer.    Go to the Galaxy tool panel, and use the top search box to search for  JBrowse .     Under  Reference genome to display  choose  Use a genome from history .    Under  Select the reference genome  choose  Prokka on data XX:fna . This .fna sequence is the fasta nucleotide sequence, and will be the reference against which annotations are displayed.    For  Produce a Standalone Instance  select  Yes .    For  Genetic Code  choose  11: The Bacterial, Archaeal and Plant Plastid Code .    Under  JBrowse-in-Galaxy Action  choose  New JBrowse Instance .    Click  Insert Track Group    Under  Track Category  type in  gene annotations .    Click  Insert Annotation Track    For  Track Type  choose  GFF/GFF3/BED/GBK Features    For  GFF/GFF3/BED Track Data  select  Prokka on data XX:gff   [Note: not wildtype.gff]    Under  JBrowse Track Type[Advanced]  select  Canvas Features .    Click on  JBrowse Styling Options     Under  JBrowse style.label  add in  product .    Under  Track Visibility  choose  On for new users .    Your tool interface should look like this:      Click  Execute    A new file will be created, called  JBrowse on data XX and data XX - Complete . Click on the eye icon next to the file name. The JBrowse window will appear in the centre Galaxy panel.    Under  Available Tracks  on the left, tick the box for  Prokka on data XX:gff .    Select contig 1 in the drop down box. You can only see one contig displayed at a time.       Use the plus and minus buttons to zoom in and out, and the arrows to move left or right (or click and drag within the window to move left or right).    Zoom in to see the reference sequence at the top. JBrowse displays the sequence and a 6-frame amino acid translation.    Zoomed in view:    Right click on a gene/feature annotation (the bars on the annotation track), then select  View Details  to see more information.  gene name  product name  you can download the FASTA sequence by clicking on the disk icon.", 
            "title": "View annotated features in JBrowse"
        }, 
        {
            "location": "/modules/snippy/", 
            "text": "Variant calling with Snippy\n\n\nKeywords: variant calling, SNP, Snippy, JBrowse, Galaxy, Microbial Genomics Virtual Lab\n\n\nBackground\n\n\nVariant calling is the process of identifying differences between two genome samples.\nUsually differences are limited to single nucleotide polymorphisms (SNPs) and small insertions and deletions (indels). Larger structural variation such as inversions, duplications and large deletions are not typically covered by \nvariant calling\n.\n\n\nIn this tutorial, we will use the tool \nSnippy\n (link to Snippy is \nhere\n). Snippy uses a tool to align the reads to a reference genome, and another tool to decide (\ncall\n) if the discrepancies are real variants.\n\n\nLearning Objectives\n\n\n\n\nFind variants between a reference genome and a set of reads\n\n\nVisualise the SNP in context of the reads aligned to the genome\n\n\nDetermine the effect of those variants on genomic features\n\n\nUnderstand if the SNP is potentially affecting the phenotype\n\n\n\n\nPrepare reference\n\n\n\n\n\n\n\n\nFor variant calling, we need a reference genome that is of the same strain as the input sequence reads.\n\n\nFor this tutorial, our reference is the \nwildtype.gbk\n file and our reads are \nmutant_R1.fastq\n and \nmutant_R2.fastq\n. \n\n\nIf these files are not presently in your Galaxy history, import them from the \nTraining dataset page.\n\n\nCall variants with Snippy\n\n\n\n\nGo to the Galaxy tools panel, and use the search box at the top to search for \nsnippy\n. \n\n\nFor \nReference type\n select \nGenbank\n.\n\n\nThen for \nReference Genbank\n choose the \nwildtype.gbk\n file.\n\n\nFor \nSingle or Paired-end reads\n choose \nPaired\n.\n\n\nThen choose the first set of reads, \nmutant_R1.fastq\n and second set of reads, \nmutant_R2.fastq\n.\n\n\nFor \nCleanup the non-snp output files\n select \nNo\n.\n\n\n\n\nYour tool interface should look like this:\n\n\n\n\n\n\nClick \nExecute\n.\n\n\n\n\nExamine Snippy output\n\n\n\n\n\nFrom Snippy, there are 10 output files in various formats.\n\n\n\n\nGo to the file called \nsnippy on data XX, data XX and data XX table\n and click on the eye icon.\n\n\nWe can see a list of variants. Look in column 3 to see which types the variants are, such as a SNP or a deletion.\n\n\nLook at the third variant called. This is a T\nA mutation, causing a stop codon. Look at column 14: the product of this gene is a methicillin resistance protein. Methicillin is an antibiotic. What might be the result of such a mutation? \n\n\n\n\nView Snippy output in JBrowse\n\n\n\n\n\n\nGo to the Galaxy tools panel, and use the search box at the top to search for \nJBrowse\n. \n\n\n\n\n\n\nUnder \nReference genome to display\n choose \nUse a genome from history\n.\n\n\n\n\n\n\nUnder \nSelect the reference genome\n choose \nwildtype.fna\n. This sequence will be the reference against which annotations are displayed.\n\n\n\n\n\n\nFor \nProduce a Standalone Instance\n select \nYes\n.\n\n\n\n\n\n\nFor \nGenetic Code\n choose \n11: The Bacterial, Archaeal and Plant Plastid Code\n.\n\n\n\n\n\n\nUnder \nJBrowse-in-Galaxy Action\n choose \nNew JBrowse Instance\n.\n\n\n\n\n\n\nWe will now set up three different tracks - these are datasets displayed underneath the reference sequence (which is displayed as nucleotides in FASTA format). We will choose to display the sequence reads (the .bam file), the variants found by snippy (the .gff file) and the annotated reference genome (the wildtype.gff)\n\n\n\n\n\n\nTrack 1 - sequence reads\n\n\n\n\nClick \nInsert Track Group\n\n\nFor \nTrack Cateogry\n name it \nsequence reads\n\n\nClick \nInsert Annotation Track\n\n\nFor \nTrack Type\n choose \nBAM Pileups\n\n\nFor \nBAM Track Data\n select \nthe snippy bam file\n\n\nFor \nAutogenerate SNP Track\n select \nYes\n\n\nUnder \nTrack Visibility\n choose \nOn for new users\n.\n\n\n\n\nTrack 2 - variants\n\n\n\n\nClick \nInsert Track Group\n again\n\n\nFor \nTrack Category\n name it \nvariants\n\n\nClick \nInsert Annotation Track\n\n\nFor \nTrack Type\n choose \nGFF/GFF3/BED/GBK Features\n\n\nFor \nTrack Data\n select \nthe snippy snps gff file\n\n\nUnder \nTrack Visibility\n choose \nOn for new users\n.\n\n\n\n\nTrack 3 - annotated reference\n\n\n\n\nClick \nInsert Track Group\n again\n\n\nFor \n Track Category\n name it \nannotated reference\n\n\nClick \nInsert Annotation Track\n\n\nFor \nTrack Type\n choose \nGFF/GFF3/BED/GBK Features\n\n\nFor \nTrack Data\n select \nwildtype.gff\n\n\nUnder \nJBrowse Track Type[Advanced]\n select \nCanvas Features\n.\n\n\nClick on \nJBrowse Styling Options \n\n\nUnder \nJBrowse style.label\n add in the word \nproduct\n.\n\n\nUnder \nJBrowse style.description\n add in the word \nproduct\n.\n\n\n\n\nUnder \nTrack Visibility\n choose \nOn for new users\n.\n\n\n\n\n\n\nClick \nExecute\n\n\n\n\n\n\nA new file will be created, called \nJBrowse on data XX and data XX - Complete\n. Click on the eye icon next to the file name. The JBrowse window will appear in the centre Galaxy panel.\n\n\n\n\n\n\nOn the left, tick boxes to display the tracks\n\n\n\n\n\n\nUse the minus button to zoom out to see:\n\n\n\n\nsequence reads and their coverage (the grey graph)\n\n\n\n\n\n\n\n\nUse the plus button to zoom in to see:\n\n\n\n\nprobable real variants (a whole column of snps)\n\n\nprobable errors (single one here and there)\n\n\n\n\n\n\n\n\n\n\n\n\nIn the coordinates box, type in \n47299\n and then \nGo\n to see the position of the SNP discussed above.\n\n\nthe correct codon at this position is TGT, coding for the amino acid Cysteine, in the middle row of the amino acid translations.\n\n\nthe mutation of T \n A turns this triplet into TGA, a stop codon.", 
            "title": "Variant finding"
        }, 
        {
            "location": "/modules/snippy/#variant-calling-with-snippy", 
            "text": "Keywords: variant calling, SNP, Snippy, JBrowse, Galaxy, Microbial Genomics Virtual Lab", 
            "title": "Variant calling with Snippy"
        }, 
        {
            "location": "/modules/snippy/#background", 
            "text": "Variant calling is the process of identifying differences between two genome samples.\nUsually differences are limited to single nucleotide polymorphisms (SNPs) and small insertions and deletions (indels). Larger structural variation such as inversions, duplications and large deletions are not typically covered by  variant calling .  In this tutorial, we will use the tool  Snippy  (link to Snippy is  here ). Snippy uses a tool to align the reads to a reference genome, and another tool to decide ( call ) if the discrepancies are real variants.", 
            "title": "Background"
        }, 
        {
            "location": "/modules/snippy/#learning-objectives", 
            "text": "Find variants between a reference genome and a set of reads  Visualise the SNP in context of the reads aligned to the genome  Determine the effect of those variants on genomic features  Understand if the SNP is potentially affecting the phenotype", 
            "title": "Learning Objectives"
        }, 
        {
            "location": "/modules/snippy/#prepare-reference", 
            "text": "For variant calling, we need a reference genome that is of the same strain as the input sequence reads.  For this tutorial, our reference is the  wildtype.gbk  file and our reads are  mutant_R1.fastq  and  mutant_R2.fastq .   If these files are not presently in your Galaxy history, import them from the  Training dataset page.", 
            "title": "Prepare reference"
        }, 
        {
            "location": "/modules/snippy/#call-variants-with-snippy", 
            "text": "Go to the Galaxy tools panel, and use the search box at the top to search for  snippy .   For  Reference type  select  Genbank .  Then for  Reference Genbank  choose the  wildtype.gbk  file.  For  Single or Paired-end reads  choose  Paired .  Then choose the first set of reads,  mutant_R1.fastq  and second set of reads,  mutant_R2.fastq .  For  Cleanup the non-snp output files  select  No .   Your tool interface should look like this:    Click  Execute .", 
            "title": "Call variants with Snippy"
        }, 
        {
            "location": "/modules/snippy/#examine-snippy-output", 
            "text": "From Snippy, there are 10 output files in various formats.   Go to the file called  snippy on data XX, data XX and data XX table  and click on the eye icon.  We can see a list of variants. Look in column 3 to see which types the variants are, such as a SNP or a deletion.  Look at the third variant called. This is a T A mutation, causing a stop codon. Look at column 14: the product of this gene is a methicillin resistance protein. Methicillin is an antibiotic. What might be the result of such a mutation?", 
            "title": "Examine Snippy output"
        }, 
        {
            "location": "/modules/snippy/#view-snippy-output-in-jbrowse", 
            "text": "Go to the Galaxy tools panel, and use the search box at the top to search for  JBrowse .     Under  Reference genome to display  choose  Use a genome from history .    Under  Select the reference genome  choose  wildtype.fna . This sequence will be the reference against which annotations are displayed.    For  Produce a Standalone Instance  select  Yes .    For  Genetic Code  choose  11: The Bacterial, Archaeal and Plant Plastid Code .    Under  JBrowse-in-Galaxy Action  choose  New JBrowse Instance .    We will now set up three different tracks - these are datasets displayed underneath the reference sequence (which is displayed as nucleotides in FASTA format). We will choose to display the sequence reads (the .bam file), the variants found by snippy (the .gff file) and the annotated reference genome (the wildtype.gff)    Track 1 - sequence reads   Click  Insert Track Group  For  Track Cateogry  name it  sequence reads  Click  Insert Annotation Track  For  Track Type  choose  BAM Pileups  For  BAM Track Data  select  the snippy bam file  For  Autogenerate SNP Track  select  Yes  Under  Track Visibility  choose  On for new users .   Track 2 - variants   Click  Insert Track Group  again  For  Track Category  name it  variants  Click  Insert Annotation Track  For  Track Type  choose  GFF/GFF3/BED/GBK Features  For  Track Data  select  the snippy snps gff file  Under  Track Visibility  choose  On for new users .   Track 3 - annotated reference   Click  Insert Track Group  again  For   Track Category  name it  annotated reference  Click  Insert Annotation Track  For  Track Type  choose  GFF/GFF3/BED/GBK Features  For  Track Data  select  wildtype.gff  Under  JBrowse Track Type[Advanced]  select  Canvas Features .  Click on  JBrowse Styling Options   Under  JBrowse style.label  add in the word  product .  Under  JBrowse style.description  add in the word  product .   Under  Track Visibility  choose  On for new users .    Click  Execute    A new file will be created, called  JBrowse on data XX and data XX - Complete . Click on the eye icon next to the file name. The JBrowse window will appear in the centre Galaxy panel.    On the left, tick boxes to display the tracks    Use the minus button to zoom out to see:   sequence reads and their coverage (the grey graph)     Use the plus button to zoom in to see:   probable real variants (a whole column of snps)  probable errors (single one here and there)       In the coordinates box, type in  47299  and then  Go  to see the position of the SNP discussed above.  the correct codon at this position is TGT, coding for the amino acid Cysteine, in the middle row of the amino acid translations.  the mutation of T   A turns this triplet into TGA, a stop codon.", 
            "title": "View Snippy output in JBrowse"
        }, 
        {
            "location": "/modules/access_data/", 
            "text": "Public data \n assembly, annotation, MLST\n\n\nOverview\n\n\n\n\nDownload a readset from a public database\n\n\nCheck the quality of the data and filter\n\n\nAssemble the reads into a draft genome\n\n\nFind antibiotic resistance genes\n\n\nAnnotate the genome\n\n\nFind the sequence type (the MLST)\n\n\n\n\nBackground\n\n\nSequencing reads (readsets) for more than 100,000 isolates are available on public molecular sequence databases (GenBank/ENA/DDJB):\n\n\n\n\nMost of these have been produced using the Illumina sequencing platform.\n\n\nMost of these have no corresponding draft assembly.\n\n\n\n\nNot all readsets are of high quality:\n\n\n\n\nThere may be insufficient reads (usually ~x20 is the minimum read coverage needed).\n\n\nThe reads could be from a mixed colony.\n\n\nThe classification could be incorrect (both genus and species).\n\n\n\n\nIt is VERY important to check that what you find in the readset makes sense!\n\n\nImport data\n\n\n\n\nGo to your Galaxy instance.\n\n\n\n\nSet up a new History for this Activity.\n\n\n\n\nIn the History panel, click on the cog icon, select \nCreate New\n.\n\n\nA new empty history should appear; click on \nUnnamed history\n and re-name it (e.g. ENA Activity).\n\n\n\n\n\n\n\n\n\n\nChoose an accession number.\n\n\n\n\nIf you are working on this tutorial in a workshop: assign yourself a readset from the table of isolates provided. Put your name in Column B. The accession number for the readset that relates to each isolate is located in Column A. ERR019289 will be used in this demonstration. \n\n\nAlternatively, use accession number ERR019289. This is \nVibrio cholerae\n.\n\n\n\n\n\n\n\n\nIn Galaxy, go to the Tools panel on the left, select \nGet Data \n EBI SRA\n.\n\n\n\n\nThis causes the ENA website to open.\n\n\nEnter the accession number in the ENA search bar.\n\n\n\n\n\n\n\n\n\n(The search may find reads under Experiment and Run. If so, click on the Accession number under \nRun\n.)\n\n\n\n\n\n\nFind the column called \nFastq files (galaxy)\n. Click on \nFile 1\n.\n\n\n\n\n\n\n\n\nThis file will download to your Galaxy history, and will return you to the Galaxy page.\n\n\n\n\n\n\nRepeat the above steps for \nGet Data \n EBI SRA\n and download \nFile 2\n.\n\n\n\n\n\n\nThe files should now be in your Galaxy history.\n\n\n\n\nClick on the pencil icon next to File 1.\n\n\nRe-name it \nERR019289_1.fastq.gz\n. \nSave\n\n\nChange the datatype to \nfastqsanger\n (note: not fastqCsanger). \n Save\n\n\n\n\n\n\nRepeat for File 2 (name it \nERR019289_2.fastq.gz\n).\n\n\n\n\nEvaluate quality\n\n\nWe will run FastQC on the pair of fastq files.\n\n\n\n\nIn the Galaxy tools panel, go to \nNGS Analysis: NGS QC and manipulation: FastQC\n.\n\n\nChoose the \nMultiple datasets\n icon and then select both \nfastq\n files.\n\n\nYour Galaxy window should look like this:\n\n\n\n\n\n\n\n\nClick \nExecute\n  \n\n\nThe output (4 files) will appear at the top of your Galaxy history.\n\n\nClick on the eye icon next to \nFastQC on data 1: Web page\n\n\nScroll through the results. Take note of the maximum read length (\ne.g.\n 54 bp).\n\n\n\n\nTrim\n\n\nIn this step we will remove adapters and trim low-quality sequence from the reads.\n\n\n\n\nIn the Galaxy tools panel, go to \nNGS Analysis: NGS QC and manipulation: Trimmomatic\n\n\nLeave settings as they are except for:\n\n\nInput FASTQ file R1\n - check this is File 1\n\n\nInput FASTQ file R2\n - check this is File 2\n\n\n\n\n\n\nUnder \nPerform initial ILLUMINACLIP step\n choose \nYes\n\n\nUnder \nAdapter sequences to use\n choose \nNextera(paired-ended)\n\n\nThis trims particular adapters from the sequences.\n\n\n\n\n\n\nUnder \nTrimmomatic Operation\n leave the settings as they are.\n\n\nWe will use the average quality across a 4-base sliding window to identify and delete bad sequence (and the flanking bases to the start or end of the sequences - whichever is nearest to the patch of poor quality sequence)\n\n\n\n\n\n\n\n\nYour tool interface should look like this:\n\n\n\n\n\n\nClick \nExecute\n  \n\n\n\n\nThere are four output files.\n\n\n\n\nBecause trimmomatic might have trimmed some reads to zero, there are now some reads reads with no pair. These are in the \nunpaired\n output files. These can be deleted (with the cross button).\n\n\nRe-name the other two output files, e.g. as \nERRxxxxx_T1.fastq.gz\n \n \nERRxxxxx_T2.fastq.gz\n. These properly paired fastq files will be the input for the Spades assembly.  \n\n\n\n\nAssemble\n\n\nWe will assemble the trimmed reads.\n\n\nIn the left hand tools panel, go to \nNGS Analysis: NGS Assembly: spades\n.\n\n\nLeave the parameters as their defaults except:\n\n\n\n\nCareful correction?\n \nNo\n\n\nKmers to use, separated by commas:\n \n21,33,51\n\n\nchosen kmers must be \nshorter\n than the maximum read length (see the FastQC output: sequence length)\n\n\n\n\n\n\nCoverage Cutoff:\n \nOff\n\n\nusing a coverage cutoff might cause a problem if there are high-copy-number plasmids\n\n\n\n\n\n\nForward reads:\n ERR019289_T1.fastq.gz\n\n\nReverse reads:\n ERR019289_T2.fastq.gz\n\n\n\n\nYour tool interface should look like this:\n\n\n\n\n\n\nClick \nExecute\n  \n\n\n\n\nThere are five output files.\n\n\n\n\nSPAdes contigs (fasta)\n \n \nSPAdes scaffolds (fasta)\n: The draft genome assembly. (These should be identical with the conditions used here.)\n\n\nSPAdes contig stats\n \n \nSPAdes scaffold stats\n: A list of all the contigs and sizes in each of these files.\n\n\nSPAdes log\n: A summary of the assembly run.\n\n\n\n\nRename \nSPAdes contigs (fasta)\n to something like \nERR019289.fasta\n.\n\n\nCheck the size of your draft genome sequence\n\n\n\n\nIf you only have a few contigs, you can estimate the size from the \nSPAdes contig stats\n file by adding together the contig sizes.\n\n\nAlternatively, go to \nNGS Common Toolsets: Fasta Statistics\n and input the \nSPAdes contigs (fasta)\n file. Click \nExecute\n. The output will show the draft genome size next to  \nnum_bp\n.\n\n\n\n\nCompare your assembly size to others of the same species\n\n\n\n\nGo to the \nNCBI website: Genome\n\n\nNext to \n Genome \n, enter the name of your species; \ne.g. Vibrio cholerae\n.\n\n\nClick on \nGenome ASsembly and Annotation report\n\n\nView the table. Click on the \nSize\n column to sort by size. (Check for additional pages at the bottom right.)\n\n\nIs your assembly size similar?\n\n\n\n\nFind antibiotic resistance genes\n\n\nNow that we have our draft genome sequence, we can search for particular genes.\n\n\n\n\nWe will use the tool called \nABRicate\n to find antibiotic resistance genes in the genome.\n\n\nABRicate uses a \ndatabase\n of these genes called \nResFinder\n.\n\n\n\n\nIn the tools panel, go to \nNGS Analysis: NGS Annotation: ABRicate\n.\n\n\n\n\nFor \nSelect fasta file\n choose \nSPAdes contigs (fasta)\n or whatever you renamed it (e.g. ERR019289.fasta).\n\n\nClick \nExecute\n.\n\n\n\n\nThere is one output file. Click on the eye icon to view.\n\n\n\n\nThis shows a table with one line for each antibiotic resistance gene found, in which contig, at which position, and the % coverage.\n\n\n\n\n\n\nFind the sequence type (MLST)\n\n\nBacterial samples (isolates) are often assigned a \nsequence type\n. This is a number that defines the particular combination of alleles in that isolate, \ne.g.\n ST248.\n\n\n\n\nBecause several genes (loci) are used, this is termed Multi-Locus Sequence Typing (MLST).\n\n\nThere are different MLST schemes for different groups of bacteria.\n\n\n\n\nIn the tools panel, go to \nNGS Analysis: NGS Annotation: MLST\n\n\n\n\nUnder \ninput_file\n choose choose \nSPAdes contigs (fasta)\n or whatever you renamed it (e.g. ERR019289.fasta).\n\n\nNote: a specific MLST scheme can be specified if you wish, but by default all schemes are searched\n\n\nClick \nExecute\n.\n\n\n\n\nThere is one output file. Click on the eye icon to view.\n\n\n\n\nThere is a one line output.\n\n\n\n\n\n\nSome symbols are used to describe missing or inexact matches to alleles:\n\n\n\n\nn: Exact intact allele\n\n\n~n : Novel allele similar to n\n\n\nn,m : Multiple alleles\n\n\n- : Allele missing\n\n\n\n\nAnnotate\n\n\nWe have found a list of resistance genes in the draft sequence, but we can also annotate the whole genome to find all the genes present.\n\n\nIn the tools panel, go to \nTools \n NGS Analysis \n NGS: Annotation \n Prokka\n  \n\n\nSet the following parameters (leave everything else unchanged):\n\n\n\n\nContigs to annotate\n: \nSPAdes contigs (fasta)\n (or equivalent)\n\n\nLocus tag prefix (\nlocustag)\n: P\n\n\nForce GenBank/ENA/DDJB compliance (\ncompliant)\n: \nNo\n\n\nSequencing Centre ID (\ncentre)\n: V\n\n\nClick \nExecute\n  \n\n\n\n\nThere are several output files:\n\n\n\n\n\n\ngff\n: the master annotation in GFF format, containing both sequences and annotations\n\n\n\n\n\n\ngbk\n: a standard GenBank file derived from the master .gff. If the input to prokka was a multi-FASTA, then this will be a multi-GenBank, with one record for each sequence\n\n\n\n\n\n\nfna\n: nucleotide FASTA file of the input contig sequences\n\n\n\n\n\n\nfaa\n: protein FASTA file of the translated CDS sequences\n\n\n\n\n\n\nffn\n: nucleotide FASTA file of all the annotated sequences, not just CDS\n\n\n\n\n\n\nsqn\n: an ASN1 format \nSequin\n file for submission to GenBank. It needs to be edited to set the correct taxonomy, authors, related publication, etc.\n\n\n\n\n\n\nfsa\n: nucleotide FASTA file of the input contig sequences, used by \ntbl2asn\n to create the .sqn file. It is mostly the same as the .fna file, but with extra Sequin tags in the sequence description lines\n\n\n\n\n\n\ntbl\n: Feature Table file, used by \ntbl2asn\n to create the .sqn file\n\n\n\n\n\n\nerr\n: unacceptable annotations - the NCBI discrepancy report\n\n\n\n\n\n\nlog\n: contains all the output that Prokka produced during its run\n\n\n\n\n\n\ntxt\n: statistics relating to the annotated features found\n\n\n\n\n\n\nTabulate\n\n\nIf you are working on this tutorial as part of a class workshop:\n\n\n\n\nGo to the table of isolates and add information about genome size, GC content, and number of contigs.\n\n\n\n\nNext\n\n\n\n\nView the annotated genome in Artemis or JBrowse.", 
            "title": "Public data &rarr; assembly, annotation"
        }, 
        {
            "location": "/modules/access_data/#public-data-assembly-annotation-mlst", 
            "text": "", 
            "title": "Public data &rarr; assembly, annotation, MLST"
        }, 
        {
            "location": "/modules/access_data/#overview", 
            "text": "Download a readset from a public database  Check the quality of the data and filter  Assemble the reads into a draft genome  Find antibiotic resistance genes  Annotate the genome  Find the sequence type (the MLST)", 
            "title": "Overview"
        }, 
        {
            "location": "/modules/access_data/#background", 
            "text": "Sequencing reads (readsets) for more than 100,000 isolates are available on public molecular sequence databases (GenBank/ENA/DDJB):   Most of these have been produced using the Illumina sequencing platform.  Most of these have no corresponding draft assembly.   Not all readsets are of high quality:   There may be insufficient reads (usually ~x20 is the minimum read coverage needed).  The reads could be from a mixed colony.  The classification could be incorrect (both genus and species).   It is VERY important to check that what you find in the readset makes sense!", 
            "title": "Background"
        }, 
        {
            "location": "/modules/access_data/#import-data", 
            "text": "Go to your Galaxy instance.   Set up a new History for this Activity.   In the History panel, click on the cog icon, select  Create New .  A new empty history should appear; click on  Unnamed history  and re-name it (e.g. ENA Activity).      Choose an accession number.   If you are working on this tutorial in a workshop: assign yourself a readset from the table of isolates provided. Put your name in Column B. The accession number for the readset that relates to each isolate is located in Column A. ERR019289 will be used in this demonstration.   Alternatively, use accession number ERR019289. This is  Vibrio cholerae .     In Galaxy, go to the Tools panel on the left, select  Get Data   EBI SRA .   This causes the ENA website to open.  Enter the accession number in the ENA search bar.     (The search may find reads under Experiment and Run. If so, click on the Accession number under  Run .)    Find the column called  Fastq files (galaxy) . Click on  File 1 .     This file will download to your Galaxy history, and will return you to the Galaxy page.    Repeat the above steps for  Get Data   EBI SRA  and download  File 2 .    The files should now be in your Galaxy history.   Click on the pencil icon next to File 1.  Re-name it  ERR019289_1.fastq.gz .  Save  Change the datatype to  fastqsanger  (note: not fastqCsanger).   Save    Repeat for File 2 (name it  ERR019289_2.fastq.gz ).", 
            "title": "Import data"
        }, 
        {
            "location": "/modules/access_data/#evaluate-quality", 
            "text": "We will run FastQC on the pair of fastq files.   In the Galaxy tools panel, go to  NGS Analysis: NGS QC and manipulation: FastQC .  Choose the  Multiple datasets  icon and then select both  fastq  files.  Your Galaxy window should look like this:     Click  Execute     The output (4 files) will appear at the top of your Galaxy history.  Click on the eye icon next to  FastQC on data 1: Web page  Scroll through the results. Take note of the maximum read length ( e.g.  54 bp).", 
            "title": "Evaluate quality"
        }, 
        {
            "location": "/modules/access_data/#trim", 
            "text": "In this step we will remove adapters and trim low-quality sequence from the reads.   In the Galaxy tools panel, go to  NGS Analysis: NGS QC and manipulation: Trimmomatic  Leave settings as they are except for:  Input FASTQ file R1  - check this is File 1  Input FASTQ file R2  - check this is File 2    Under  Perform initial ILLUMINACLIP step  choose  Yes  Under  Adapter sequences to use  choose  Nextera(paired-ended)  This trims particular adapters from the sequences.    Under  Trimmomatic Operation  leave the settings as they are.  We will use the average quality across a 4-base sliding window to identify and delete bad sequence (and the flanking bases to the start or end of the sequences - whichever is nearest to the patch of poor quality sequence)     Your tool interface should look like this:    Click  Execute      There are four output files.   Because trimmomatic might have trimmed some reads to zero, there are now some reads reads with no pair. These are in the  unpaired  output files. These can be deleted (with the cross button).  Re-name the other two output files, e.g. as  ERRxxxxx_T1.fastq.gz     ERRxxxxx_T2.fastq.gz . These properly paired fastq files will be the input for the Spades assembly.", 
            "title": "Trim"
        }, 
        {
            "location": "/modules/access_data/#assemble", 
            "text": "We will assemble the trimmed reads.  In the left hand tools panel, go to  NGS Analysis: NGS Assembly: spades .  Leave the parameters as their defaults except:   Careful correction?   No  Kmers to use, separated by commas:   21,33,51  chosen kmers must be  shorter  than the maximum read length (see the FastQC output: sequence length)    Coverage Cutoff:   Off  using a coverage cutoff might cause a problem if there are high-copy-number plasmids    Forward reads:  ERR019289_T1.fastq.gz  Reverse reads:  ERR019289_T2.fastq.gz   Your tool interface should look like this:    Click  Execute      There are five output files.   SPAdes contigs (fasta)     SPAdes scaffolds (fasta) : The draft genome assembly. (These should be identical with the conditions used here.)  SPAdes contig stats     SPAdes scaffold stats : A list of all the contigs and sizes in each of these files.  SPAdes log : A summary of the assembly run.   Rename  SPAdes contigs (fasta)  to something like  ERR019289.fasta .  Check the size of your draft genome sequence   If you only have a few contigs, you can estimate the size from the  SPAdes contig stats  file by adding together the contig sizes.  Alternatively, go to  NGS Common Toolsets: Fasta Statistics  and input the  SPAdes contigs (fasta)  file. Click  Execute . The output will show the draft genome size next to   num_bp .   Compare your assembly size to others of the same species   Go to the  NCBI website: Genome  Next to   Genome  , enter the name of your species;  e.g. Vibrio cholerae .  Click on  Genome ASsembly and Annotation report  View the table. Click on the  Size  column to sort by size. (Check for additional pages at the bottom right.)  Is your assembly size similar?", 
            "title": "Assemble"
        }, 
        {
            "location": "/modules/access_data/#find-antibiotic-resistance-genes", 
            "text": "Now that we have our draft genome sequence, we can search for particular genes.   We will use the tool called  ABRicate  to find antibiotic resistance genes in the genome.  ABRicate uses a  database  of these genes called  ResFinder .   In the tools panel, go to  NGS Analysis: NGS Annotation: ABRicate .   For  Select fasta file  choose  SPAdes contigs (fasta)  or whatever you renamed it (e.g. ERR019289.fasta).  Click  Execute .   There is one output file. Click on the eye icon to view.   This shows a table with one line for each antibiotic resistance gene found, in which contig, at which position, and the % coverage.", 
            "title": "Find antibiotic resistance genes"
        }, 
        {
            "location": "/modules/access_data/#find-the-sequence-type-mlst", 
            "text": "Bacterial samples (isolates) are often assigned a  sequence type . This is a number that defines the particular combination of alleles in that isolate,  e.g.  ST248.   Because several genes (loci) are used, this is termed Multi-Locus Sequence Typing (MLST).  There are different MLST schemes for different groups of bacteria.   In the tools panel, go to  NGS Analysis: NGS Annotation: MLST   Under  input_file  choose choose  SPAdes contigs (fasta)  or whatever you renamed it (e.g. ERR019289.fasta).  Note: a specific MLST scheme can be specified if you wish, but by default all schemes are searched  Click  Execute .   There is one output file. Click on the eye icon to view.   There is a one line output.    Some symbols are used to describe missing or inexact matches to alleles:   n: Exact intact allele  ~n : Novel allele similar to n  n,m : Multiple alleles  - : Allele missing", 
            "title": "Find the sequence type (MLST)"
        }, 
        {
            "location": "/modules/access_data/#annotate", 
            "text": "We have found a list of resistance genes in the draft sequence, but we can also annotate the whole genome to find all the genes present.  In the tools panel, go to  Tools   NGS Analysis   NGS: Annotation   Prokka     Set the following parameters (leave everything else unchanged):   Contigs to annotate :  SPAdes contigs (fasta)  (or equivalent)  Locus tag prefix ( locustag) : P  Force GenBank/ENA/DDJB compliance ( compliant) :  No  Sequencing Centre ID ( centre) : V  Click  Execute      There are several output files:    gff : the master annotation in GFF format, containing both sequences and annotations    gbk : a standard GenBank file derived from the master .gff. If the input to prokka was a multi-FASTA, then this will be a multi-GenBank, with one record for each sequence    fna : nucleotide FASTA file of the input contig sequences    faa : protein FASTA file of the translated CDS sequences    ffn : nucleotide FASTA file of all the annotated sequences, not just CDS    sqn : an ASN1 format  Sequin  file for submission to GenBank. It needs to be edited to set the correct taxonomy, authors, related publication, etc.    fsa : nucleotide FASTA file of the input contig sequences, used by  tbl2asn  to create the .sqn file. It is mostly the same as the .fna file, but with extra Sequin tags in the sequence description lines    tbl : Feature Table file, used by  tbl2asn  to create the .sqn file    err : unacceptable annotations - the NCBI discrepancy report    log : contains all the output that Prokka produced during its run    txt : statistics relating to the annotated features found    Tabulate  If you are working on this tutorial as part of a class workshop:   Go to the table of isolates and add information about genome size, GC content, and number of contigs.", 
            "title": "Annotate"
        }, 
        {
            "location": "/modules/access_data/#next", 
            "text": "View the annotated genome in Artemis or JBrowse.", 
            "title": "Next"
        }, 
        {
            "location": "/modules/abricate/", 
            "text": "Finding antibiotic-resistant genes\n\n\nOverview\n\n\n\n\nImport an assembled bacterial genome\n\n\nFind antibiotic-resistance (AMR) genes\n\n\n\n\nImport data\n\n\n\n\nGo to your Galaxy instance.\n\n\n\n\nSet up a new History for this Activity.\n\n\n\n\nIn the History panel, click on the cog icon, select \nCreate New\n.\n\n\nA new empty history should appear; click on \nUnnamed history\n and re-name it (e.g. AMR genes).\n\n\n\n\n\n\n\n\n\n\nImport an assembled genome (or use one from your history).\n\n\n\n\nCopy this URL for a previously-assembled genome:  \nhttps://swift.rc.nectar.org.au:8888/v1/AUTH_377/public/Microbial_tutorials/SPAdes_contigs.fasta\n\n\nFrom the Galaxy tool panel, click on \nGet Data \n Upload File\n  \n\n\nClick the \nPaste/Fetch data\n button  \n\n\nPaste the URL into the box.\n\n\nClick the \nStart\n button.  \n\n\nOnce the progress bar reaches 100%, click the \nClose\n button  \n\n\nThe file will now upload to your current history.\n\n\nRe-name it with the pencil icon to \ncontigs.fasta\n.\n\n\n\n\n\n\n\n\nFind antibiotic-resistance genes\n\n\n\n\nWe will use the tool called \nABRicate\n to find antibiotic resistance genes in the (draft) genome.\n\n\nABRicate uses a \ndatabase\n of these genes called \nResFinder\n.\n\n\n\n\nIn the tools panel, go to \nNGS Analysis: NGS Annotation: ABRicate\n.\n\n\n\n\nFor \nSelect fasta file\n choose \ncontigs.fasta\n (or the name of your own assembly file.)\n\n\nClick \nExecute\n.\n\n\n\n\nThere is one output file. Click on the eye icon to view. It should look like this, although likely with a different number of rows.\n\n\n\n\nThis shows a table with one line for each antibiotic resistance gene found, in which contig, at which position, and the % coverage.\n\n\n\n\n\n\nNext\n\n\nIn the output from Abricate, column 5 has the list of the antibiotic-resistant gene names. Some of these may be complete, exact matches, and some may have a gap/mutation in their sequence which can affect whether that protein is actually expressed.\n\n\nTo find out more about what type of AMR genes these are, you can search \nGenbank\n with the gene name (e.g. aadD).", 
            "title": "Finding antibiotic-resistant genes"
        }, 
        {
            "location": "/modules/abricate/#finding-antibiotic-resistant-genes", 
            "text": "", 
            "title": "Finding antibiotic-resistant genes"
        }, 
        {
            "location": "/modules/abricate/#overview", 
            "text": "Import an assembled bacterial genome  Find antibiotic-resistance (AMR) genes", 
            "title": "Overview"
        }, 
        {
            "location": "/modules/abricate/#import-data", 
            "text": "Go to your Galaxy instance.   Set up a new History for this Activity.   In the History panel, click on the cog icon, select  Create New .  A new empty history should appear; click on  Unnamed history  and re-name it (e.g. AMR genes).      Import an assembled genome (or use one from your history).   Copy this URL for a previously-assembled genome:   https://swift.rc.nectar.org.au:8888/v1/AUTH_377/public/Microbial_tutorials/SPAdes_contigs.fasta  From the Galaxy tool panel, click on  Get Data   Upload File     Click the  Paste/Fetch data  button    Paste the URL into the box.  Click the  Start  button.    Once the progress bar reaches 100%, click the  Close  button    The file will now upload to your current history.  Re-name it with the pencil icon to  contigs.fasta .", 
            "title": "Import data"
        }, 
        {
            "location": "/modules/abricate/#find-antibiotic-resistance-genes", 
            "text": "We will use the tool called  ABRicate  to find antibiotic resistance genes in the (draft) genome.  ABRicate uses a  database  of these genes called  ResFinder .   In the tools panel, go to  NGS Analysis: NGS Annotation: ABRicate .   For  Select fasta file  choose  contigs.fasta  (or the name of your own assembly file.)  Click  Execute .   There is one output file. Click on the eye icon to view. It should look like this, although likely with a different number of rows.   This shows a table with one line for each antibiotic resistance gene found, in which contig, at which position, and the % coverage.", 
            "title": "Find antibiotic-resistance genes"
        }, 
        {
            "location": "/modules/abricate/#next", 
            "text": "In the output from Abricate, column 5 has the list of the antibiotic-resistant gene names. Some of these may be complete, exact matches, and some may have a gap/mutation in their sequence which can affect whether that protein is actually expressed.  To find out more about what type of AMR genes these are, you can search  Genbank  with the gene name (e.g. aadD).", 
            "title": "Next"
        }, 
        {
            "location": "/modules/viral_genomes/", 
            "text": "Viral Genome Sequencing\n\n\nThis tutorial is about determining the genome sequence of a virus, using comparisons to a reference sequence.\n\n\nBackground\n\n\nMurray Valley encephalitis virus is classified as part of the Flavivirus genus of viruses, all of which are positive strand RNA viruses. The type species for this genus is yellow fever virus, and the genus includes dengue virus, west nile virus and zika virus.\n\n\nViruses from this genus have a single-segment genome of about 11 kb. Within this, there is a 10 kb open reading frame that encodes a polyprotein. Following translation, this protein is modified to yield the various, mature structural and non-structural viral proteins as illustrated in Fig. 1.\n\n\n\n\nFig. 1 - An overview of a typical flavivirus genome and the viral proteins that are part of the viral polyprotein (from \nViralzone\n).\n\n\nThere are 14 complete Murray Valley encephalitis virus genome sequences available at NCBI Viral Genomes.\n\n\n\n\nGo to NCBI \nViral Genomes\n.\n\n\nSelect \nBrowse viral genomes by family\n and click on the family \nFlaviviridae\n: \nComplete Genomes\n\n\nNote: you may have to widen your screen to see all the columns of viral family names.\n\n\n\n\n\n\n\n\nLook at the row for Murray Valley encephelitis virus. In the Neigbours column, we can see there are 14.\n\n\n\n\n\n\n\nIn this tutorial we will use the prototype strain 1-151 as the reference genome sequence.\n\n\n\n\nThis strain was isolated in the early 1950s - see \nAF161266\n.\n\n\n\n\n\n\n\nThe isolate we are looking at has been sequenced using the Illumina platform.\n\n\n\n\nThe genomic cDNA was prepared using random hexamers to prime the reverse transcription of the viral genomic RNA.\n\n\nAfter second strand synthesis, the cDNA was used to prepare an Illumina sequencing library and run on an Illumina MiSeq instrument.\n\n\n\n\nIn this activity we will use a read mapping approach to determine the sequence of a new Murray Valley encephalitis virus isolate.\n\n\nImport data\n\n\nSection overview:\n\n\n\n\nLog in to your Galaxy server\n\n\nImport files required for the activity\n\n\nView imported files\n\n\n\n\nGo to the Galaxy Page\n\n\n\n\nWeb address: \nhttp://phln.genome.edu.au/galaxy\n\n\nRemind me how to logon\n\n\n\n\nImport files to Galaxy\n\n\n\n\nClick on the \nAnalyze Data\n menu at the top of the page.\n\n\nClick on the \nHistory\n menu button (the \n on the top right of the history pane)\n\n\nClick \nImport from File\n (at the bottom of the list)\n\n\nA new page will appear with a text box for the URL of the history to import.\n\n\nCopy the following URL into the text box:\n\n\n\n\nhttp://phln.genome.edu.au/public/dieter/Galaxy-History-MVEVmapping.tar.gz\n\n\n\n\n\n\nClick \nSubmit\n\n\n\n\nGalaxy will download the data files from the internet and will be available as an additional history (takes about one minute).\n\n\n\n\nTo make the newly imported history appear as the current history:\n\n\n\n\nClick on the View all Histories button (the \n on the top right of the history pane.)\n\n\nIf the history has finished downloading it will appear with the title:\n\n\n\u201cimported from archive: MVEVmapping\u201c\n\n\nClick on the \nSwitch to\n button above this history and then the \nDone\n button.\n\n\n\n\nYou should now have 4 files in the history pane as follows:\n\n\n\n\nReference sequence files \n :\n\n\n\n\nMVEV.gbk\n - genbank format\n\n\nMVEV.fna\n - fasta format\n\n\n\n\nIllumina sequence reads (R1 and R2) from the new isolate:\n\n\n\n\nMVE_R1.fq\n - forward reads\n\n\nMVE_R2.fq\n - reverse reads\n\n\n\n\nSnippy\n\n\nSection overview:\n\n\n\n\nFind variants in the isolate using the tool Snippy.\n\n\n\n\nSnippy is a fast variant caller for haploid genomes. The software is available on GitHub at \nhttps://github.com/tseemann/snippy\n. For this activity, we are using Snippy as installed on Galaxy.\n\n\nPreliminary Activity\n\n\n\n\n\n\nRun FastQC: How many reads in in each of the fastq files \nMVE_R1.fq\n and \nMVE_R2.fq\n?\n\n\n\n\n\n\nMVEV.fna\n and \nMVEV.gbk\n each contain the genome sequence of Murray Valley encephalitis virus strain 1-151 - how many bases in the genome? (Hint: use Fasta Statistics)\n\n\n\n\n\n\nRunning Snippy\n\n\nSnippy maps reads from the new Murray Valley encephalitis virus isolate (the \nMVE_R1.fq\n and \nMVE_R2.fq\n reads) onto the genome sequence of Murray Valley encephalitis virus strain 1-151 (\nMVEV.fna\n). \n\n\n\n\nFind Snippy in the tool menu (in  NGS: Variant Analysis)\n\n\nSelect appropriate files (see screenshot below) and Execute (use default settings).\n\n\n\n\n\n\nOutput\n\n\nFiles cataloging SNP differences:\n\n\n\n\n9: \nsnippy on data 4, data 3, and data 2 snps vcf file\n\n\n10: \nsnippy on data 4, data 3, and data 2 snps gff file\n\n\n11: \nsnippy on data 4, data 3, and data 2 snps table\n\n\n12: \nsnippy on data 4, data 3, and data 2 snps summary\n\n\n\n\nA log of the progress of the run:\n\n\n\n\n13: \nsnippy on data 4, data 3, and data 2 log file\n\n\n\n\nRegions where reads aligned (NNNN \n, indicate regions where there was low or no read data):\n\n\n\n\n14: \nsnippy on data 4, data 3, and data 2 aligned fasta\n\n\n\n\nA consensus genome sequence for the new isolate:\n\n\n\n\n15: \nsnippy on data 4, data 3, and data 2 consensus fasta\n\n\n\n\nSummary of the read depth:\n\n\n\n\n16: \nsnippy on data 4, data 3, and data 2 mapping depth\n\n\n\n\nA compressed version of the above files (and more that can be downloaded):\n\n\n\n\n17: \nsnippy on data 4, data 3, and data 2 out dir\n\n\n\n\nDownload these files to your local computer (click on the file name and then the disk icon in the lower left hand corner):\n\n\n\n\n17: \nsnippy on data 4, data 3, and data 2 out dir\n (and unzip)\n\n\n2: \nMVEV.gbk\n\n\n1: \nMVEV.fna\n\n\n\n\nAlso download these bam files from these URLs (open each URL in a new tab and the file should download automatically):\n\n\n\n\nhttp://phln.genome.edu.au/public/dieter/snps.bam\n\n\nhttp://phln.genome.edu.au/public/dieter/snps.bam.bai\n\n\nhttp://phln.genome.edu.au/public/dieter/snps.depth.gz\n\n\nhttp://phln.genome.edu.au/public/dieter/snps.depth.gz.tbi\n\n\n\n\nNote: if you have previously downloaded these files, the new downloads may be renamed. Remove any spaces in the names.\n\n\n\n\n\nArtemis\n\n\nSection overview:\n\n\n\n\nView the reads from the new isolate mapped against the reference sequence, using the tool Artemis.\n\n\n\n\nArtemis is a tool to view genome sequences and mapped reads, including variants (SNPs).\n\n\nIf Artemis is not installed, go to \nhttp://www.sanger.ac.uk/science/tools/artemis\n.\n\n\nView the reference sequence\n\n\n\n\nOpen Artemis.\n\n\nGo to \nFile: Open\n and select \nMVEV.gbk\n. The file will probably have a \nGalaxy\n prefix, e.g. \nGalaxy2-[MVEV.gbk].genbank\n.\n\n\n\n\nThe Artemis window:\n\n\n\n\npanes 1 and 2 are the same, but can be scaled differently\n\n\neach pane has the double-stranded sequence in the centre, with amino acid translations above and below\n\n\nthere is a third lower pane with feature information\n\n\ncoding sequences are highlighted in blue\n\n\nother features are highlighted in green\n\n\nclicking on one of these will select it in all panels\n\n\nblack vertical lines are stop codons (when zoomed out)\n\n\nmove left and right with horizontal scroll bar\n\n\nzoom in and out with right-hand scroll bar\n\n\n\n\n\n\nAdd a plot\n\n\n\n\nGo to \nGraph: Add User Plot\n, select \nsnps.depth.gz\n\n\nA graph should display at the top of the screen \n\n\n\n\n\n\n\n\n\nProducing a draft genome sequence\n\n\nSection overview:\n\n\n\n\nProduce draft genome sequence for the new viral isolate.\n\n\n\n\nExamine the mapped reads\n\n\n\n\n\nWhat is the minimum read depth used by Snippy to call a SNP?\n\n\n\n\nHint: Go back to Snippy on Galaxy - look at the information below the \u2018Execute\u2019 button\n\n\n\n\nWould Snippy call a SNP at positions 1 \u2192 5 ?\n\n\nWhat is the maximum read depth?\n\n\nWhat do we know about the sequence of the new isolate in the regions where there is low read coverage?\n\n\n\n\n\n\n\nUnzip \n17: snippy on data 4, data 3, and data 2 out dir\n\n\n\n\nThis makes an \nout\n folder containing some files including the consensus file.\n\n\n\n\n\n\nIn Artemis, open \nsnps.consensus.fa\n\n\n\n\n\n\nThis is a file that is based on the reference sequence and includes any confirmed SNPs called by Snippy.\n\n\nIf we were going to use this sequence to produce the draft sequence of the new isolate, what bases would you have at positions 1\u2192 5?\n\n\nGetting an Overview of the Difference between strain 1-151 and our new isolate\n\n\nSimplest overview: view the bam file with Artemis\n\n\nOpen \nMVEV.gbk\n in Artemis and load the \nsnps.bam\n via the File menu to \u201cRead BAM / VCF\u201d\n\n\nOnce loaded, differences between reads and the reference sequence can be highlighted by right/command click in the bam view window. Select \u2018Show \n SNP marks\u2019.\n\n\n\n\nGetting more detail: looking at the table of SNPs\n\n\nLocated in the out folder there is a html file that contains a table with information about each of the SNPs called by Snippy.\n\n\nIncluded in the table is a column that provides a prediction about the impact each SNP will have on annotated protein coding regions. The genbank file provides the annotation information used by Snippy to make the predictions.\n\n\nA total of 790 SNP differences were call by Snippy\n\n\nOpen snps.html in your web browser\n\n\n\n\n\nSummary: 663/790 SNPs do not result a difference in the encoded polyprotein\n\n\nIs this pattern of variable genome sequence and more conserved protein sequence normal in viruses? What might be the cause?", 
            "title": "Viral genome sequencing"
        }, 
        {
            "location": "/modules/viral_genomes/#viral-genome-sequencing", 
            "text": "This tutorial is about determining the genome sequence of a virus, using comparisons to a reference sequence.", 
            "title": "Viral Genome Sequencing"
        }, 
        {
            "location": "/modules/viral_genomes/#background", 
            "text": "Murray Valley encephalitis virus is classified as part of the Flavivirus genus of viruses, all of which are positive strand RNA viruses. The type species for this genus is yellow fever virus, and the genus includes dengue virus, west nile virus and zika virus.  Viruses from this genus have a single-segment genome of about 11 kb. Within this, there is a 10 kb open reading frame that encodes a polyprotein. Following translation, this protein is modified to yield the various, mature structural and non-structural viral proteins as illustrated in Fig. 1.   Fig. 1 - An overview of a typical flavivirus genome and the viral proteins that are part of the viral polyprotein (from  Viralzone ).  There are 14 complete Murray Valley encephalitis virus genome sequences available at NCBI Viral Genomes.   Go to NCBI  Viral Genomes .  Select  Browse viral genomes by family  and click on the family  Flaviviridae :  Complete Genomes  Note: you may have to widen your screen to see all the columns of viral family names.     Look at the row for Murray Valley encephelitis virus. In the Neigbours column, we can see there are 14.    In this tutorial we will use the prototype strain 1-151 as the reference genome sequence.   This strain was isolated in the early 1950s - see  AF161266 .    The isolate we are looking at has been sequenced using the Illumina platform.   The genomic cDNA was prepared using random hexamers to prime the reverse transcription of the viral genomic RNA.  After second strand synthesis, the cDNA was used to prepare an Illumina sequencing library and run on an Illumina MiSeq instrument.   In this activity we will use a read mapping approach to determine the sequence of a new Murray Valley encephalitis virus isolate.", 
            "title": "Background"
        }, 
        {
            "location": "/modules/viral_genomes/#import-data", 
            "text": "", 
            "title": "Import data"
        }, 
        {
            "location": "/modules/viral_genomes/#section-overview", 
            "text": "Log in to your Galaxy server  Import files required for the activity  View imported files", 
            "title": "Section overview:"
        }, 
        {
            "location": "/modules/viral_genomes/#go-to-the-galaxy-page", 
            "text": "Web address:  http://phln.genome.edu.au/galaxy  Remind me how to logon", 
            "title": "Go to the Galaxy Page"
        }, 
        {
            "location": "/modules/viral_genomes/#import-files-to-galaxy", 
            "text": "Click on the  Analyze Data  menu at the top of the page.  Click on the  History  menu button (the   on the top right of the history pane)  Click  Import from File  (at the bottom of the list)  A new page will appear with a text box for the URL of the history to import.  Copy the following URL into the text box:   http://phln.genome.edu.au/public/dieter/Galaxy-History-MVEVmapping.tar.gz    Click  Submit   Galaxy will download the data files from the internet and will be available as an additional history (takes about one minute).", 
            "title": "Import files to Galaxy"
        }, 
        {
            "location": "/modules/viral_genomes/#to-make-the-newly-imported-history-appear-as-the-current-history", 
            "text": "Click on the View all Histories button (the   on the top right of the history pane.)  If the history has finished downloading it will appear with the title:  \u201cimported from archive: MVEVmapping\u201c  Click on the  Switch to  button above this history and then the  Done  button.   You should now have 4 files in the history pane as follows:   Reference sequence files   :   MVEV.gbk  - genbank format  MVEV.fna  - fasta format   Illumina sequence reads (R1 and R2) from the new isolate:   MVE_R1.fq  - forward reads  MVE_R2.fq  - reverse reads", 
            "title": "To make the newly imported history appear as the current history:"
        }, 
        {
            "location": "/modules/viral_genomes/#snippy", 
            "text": "", 
            "title": "Snippy"
        }, 
        {
            "location": "/modules/viral_genomes/#section-overview_1", 
            "text": "Find variants in the isolate using the tool Snippy.   Snippy is a fast variant caller for haploid genomes. The software is available on GitHub at  https://github.com/tseemann/snippy . For this activity, we are using Snippy as installed on Galaxy.", 
            "title": "Section overview:"
        }, 
        {
            "location": "/modules/viral_genomes/#preliminary-activity", 
            "text": "Run FastQC: How many reads in in each of the fastq files  MVE_R1.fq  and  MVE_R2.fq ?    MVEV.fna  and  MVEV.gbk  each contain the genome sequence of Murray Valley encephalitis virus strain 1-151 - how many bases in the genome? (Hint: use Fasta Statistics)", 
            "title": "Preliminary Activity"
        }, 
        {
            "location": "/modules/viral_genomes/#running-snippy", 
            "text": "Snippy maps reads from the new Murray Valley encephalitis virus isolate (the  MVE_R1.fq  and  MVE_R2.fq  reads) onto the genome sequence of Murray Valley encephalitis virus strain 1-151 ( MVEV.fna ).    Find Snippy in the tool menu (in  NGS: Variant Analysis)  Select appropriate files (see screenshot below) and Execute (use default settings).", 
            "title": "Running Snippy"
        }, 
        {
            "location": "/modules/viral_genomes/#output", 
            "text": "Files cataloging SNP differences:   9:  snippy on data 4, data 3, and data 2 snps vcf file  10:  snippy on data 4, data 3, and data 2 snps gff file  11:  snippy on data 4, data 3, and data 2 snps table  12:  snippy on data 4, data 3, and data 2 snps summary   A log of the progress of the run:   13:  snippy on data 4, data 3, and data 2 log file   Regions where reads aligned (NNNN  , indicate regions where there was low or no read data):   14:  snippy on data 4, data 3, and data 2 aligned fasta   A consensus genome sequence for the new isolate:   15:  snippy on data 4, data 3, and data 2 consensus fasta   Summary of the read depth:   16:  snippy on data 4, data 3, and data 2 mapping depth   A compressed version of the above files (and more that can be downloaded):   17:  snippy on data 4, data 3, and data 2 out dir   Download these files to your local computer (click on the file name and then the disk icon in the lower left hand corner):   17:  snippy on data 4, data 3, and data 2 out dir  (and unzip)  2:  MVEV.gbk  1:  MVEV.fna   Also download these bam files from these URLs (open each URL in a new tab and the file should download automatically):   http://phln.genome.edu.au/public/dieter/snps.bam  http://phln.genome.edu.au/public/dieter/snps.bam.bai  http://phln.genome.edu.au/public/dieter/snps.depth.gz  http://phln.genome.edu.au/public/dieter/snps.depth.gz.tbi   Note: if you have previously downloaded these files, the new downloads may be renamed. Remove any spaces in the names.", 
            "title": "Output"
        }, 
        {
            "location": "/modules/viral_genomes/#artemis", 
            "text": "", 
            "title": "Artemis"
        }, 
        {
            "location": "/modules/viral_genomes/#section-overview_2", 
            "text": "View the reads from the new isolate mapped against the reference sequence, using the tool Artemis.   Artemis is a tool to view genome sequences and mapped reads, including variants (SNPs).  If Artemis is not installed, go to  http://www.sanger.ac.uk/science/tools/artemis .", 
            "title": "Section overview:"
        }, 
        {
            "location": "/modules/viral_genomes/#view-the-reference-sequence", 
            "text": "Open Artemis.  Go to  File: Open  and select  MVEV.gbk . The file will probably have a  Galaxy  prefix, e.g.  Galaxy2-[MVEV.gbk].genbank .", 
            "title": "View the reference sequence"
        }, 
        {
            "location": "/modules/viral_genomes/#the-artemis-window", 
            "text": "panes 1 and 2 are the same, but can be scaled differently  each pane has the double-stranded sequence in the centre, with amino acid translations above and below  there is a third lower pane with feature information  coding sequences are highlighted in blue  other features are highlighted in green  clicking on one of these will select it in all panels  black vertical lines are stop codons (when zoomed out)  move left and right with horizontal scroll bar  zoom in and out with right-hand scroll bar", 
            "title": "The Artemis window:"
        }, 
        {
            "location": "/modules/viral_genomes/#add-a-plot", 
            "text": "Go to  Graph: Add User Plot , select  snps.depth.gz  A graph should display at the top of the screen", 
            "title": "Add a plot"
        }, 
        {
            "location": "/modules/viral_genomes/#producing-a-draft-genome-sequence", 
            "text": "", 
            "title": "Producing a draft genome sequence"
        }, 
        {
            "location": "/modules/viral_genomes/#section-overview_3", 
            "text": "Produce draft genome sequence for the new viral isolate.", 
            "title": "Section overview:"
        }, 
        {
            "location": "/modules/viral_genomes/#examine-the-mapped-reads", 
            "text": "What is the minimum read depth used by Snippy to call a SNP?   Hint: Go back to Snippy on Galaxy - look at the information below the \u2018Execute\u2019 button   Would Snippy call a SNP at positions 1 \u2192 5 ?  What is the maximum read depth?  What do we know about the sequence of the new isolate in the regions where there is low read coverage?    Unzip  17: snippy on data 4, data 3, and data 2 out dir   This makes an  out  folder containing some files including the consensus file.    In Artemis, open  snps.consensus.fa    This is a file that is based on the reference sequence and includes any confirmed SNPs called by Snippy.  If we were going to use this sequence to produce the draft sequence of the new isolate, what bases would you have at positions 1\u2192 5?", 
            "title": "Examine the mapped reads"
        }, 
        {
            "location": "/modules/viral_genomes/#getting-an-overview-of-the-difference-between-strain-1-151-and-our-new-isolate", 
            "text": "Simplest overview: view the bam file with Artemis  Open  MVEV.gbk  in Artemis and load the  snps.bam  via the File menu to \u201cRead BAM / VCF\u201d  Once loaded, differences between reads and the reference sequence can be highlighted by right/command click in the bam view window. Select \u2018Show   SNP marks\u2019.", 
            "title": "Getting an Overview of the Difference between strain 1-151 and our new isolate"
        }, 
        {
            "location": "/modules/viral_genomes/#getting-more-detail-looking-at-the-table-of-snps", 
            "text": "Located in the out folder there is a html file that contains a table with information about each of the SNPs called by Snippy.  Included in the table is a column that provides a prediction about the impact each SNP will have on annotated protein coding regions. The genbank file provides the annotation information used by Snippy to make the predictions.  A total of 790 SNP differences were call by Snippy  Open snps.html in your web browser   Summary: 663/790 SNPs do not result a difference in the encoded polyprotein  Is this pattern of variable genome sequence and more conserved protein sequence normal in viruses? What might be the cause?", 
            "title": "Getting more detail: looking at the table of SNPs"
        }, 
        {
            "location": "/modules/workflows/", 
            "text": "Galaxy workflows\n\n\nThis tutorial assumes you have used Galaxy before.\n\n\nAlthough we can use tools in Galaxy to analyse data and create a history, there is also a way to create a workflow of files, tools, settings and outputs. You can then input different datasets and run the workflow.\n\n\nThis tutorial covers building a workflow to analyse a bacterial genome, from input Fastq sequencing reads to assembly, annotation, and visualization.\n\n\nStart\n\n\nGo to your Galaxy instance and Register/Login.\n\n\nImport a history of data files:\n\n\n\n\nClick on the \nHistory\n cog \n\n\nSelect \nImport from File\n\n\nIn the box called \nArchived History URL\n, paste in this link address to the Galaxy history of input files:\n\n\n\n\nhttps://swift.rc.nectar.org.au:8888/v1/AUTH_377/public/Microbial_tutorials/Galaxy_history_input_files.tar.gz\n\n\n\n\nClick \nSubmit\n\n\nWait a few seconds.\n\n\nClick on the \nView all histories\n button \n\n\nSee if the Galaxy history has been imported: it will be called \nimported from archive: Data\n\n\nAbove that pane, click on the \nSwitch to\n button.\n\n\nThen click \nDone\n (in the top left corner).\n\n\n\n\nYou should now have a list of five files in your current history.\n\n\n\n\n\n\nRe-name this history \nWorkflows\n.\n\n\n\n\n\n\nBuild a workflow\n\n\nWe will first write a workflow for genome assembly.\n\n\n\n\nIn the top menu bar in Galaxy, click on \nWorkflow\n.\n\n\n\n\n\n\n\n\nClick on \nCreate new workflow\n\n\n\n\n\n\n\n\n\n\nUnder \nWorkflow Name:\n put in \nReads to Annotation\n.\n\n\n\n\n\n\nClick \nCreate\n\n\n\n\n\n\nThis will bring up the \nWorkflow Canvas\n, a grid where you can arrange the workflow.\n\n\n\n\n\n\nAdd inputs\n\n\n\n\n\n\nIn the Tools panel, click \nInputs: Input datset\n twice (at the very top of the list).\n\n\n\n\n\n\nA box will appear: drag it to the left and there will be another box underneath it. Drag this also to the left. Your workflow canvas should look like this:\n\n\n\n\n\n\n\n\n\n\nClick on the first box. Look in the right hand panel (now called \nDetails\n) and change the name of the Input dataset to \nR1.fastq\n. Press Enter for the change to be saved.\n\n\n\n\n\n\n\n\nRepeat for the second input dataset box, naming that one \nR2.fastq\n.\n\n\n\n\nAdd the tool \nspades\n\n\n\n\nIn the tools panel, click on \nNGS Analysis: NGS Assembly: spades\n.\nThis puts the spades box onto the workflow canvas.\n\n\n\n\n\n\n\n\n\n\nClick on the spades box and look in the Details pane on the right. This shows all the options in spades. Choose:\n\n\n\n\n\n\nRun only Assembly\n: \nYes\n [the \nYes\n button should be darker grey]\n\n\n\n\nKmers to use separated by commas:\n \n33,55,91\n  [note: no spaces]  \n\n\nCoverage cutoff:\n \nauto\n  \n\n\n\n\nJoin inputs to the tool\n\n\nNow tell spades which input files to use.\n\n\n\n\n\n\nLook at the input dataset box called \nR1.fastq\n and find the small arrow: \n\n\n\n\n\n\nClick on this and drag the arrow over to the spades box input arrow \n next to \nLibraries 1 \n Files 1 \n Forward reads\n.\n\n\n\n\n\n\n\n\n\n\nRepeat for the dataset box \nR2.fastq\n, joining to the spades box next to \nLibraries 1 \n Files 1 \n Reverse reads\n.\n\n\n\n\nSave it and run\n\n\n\n\nClick on the cog at the top right of the workflow canvas and \nSave\n.\n\n\n\n\n\n\n\n\n\n\nClick the cog again and choose \nRun\n.\n\n\n\n\n\n\nThis brings up a window where you specify the input datasets to use in the workflow.\n\n\n\n\nUnder \nStep1: Input dataset\n choose \nmutant_R1.fastq\n.\n\n\nUnder \nStep2: Input dataset\n choose \nmutant_R2.fastq\n.\n\n\n\n\n\n\n\n\nClick \nRun workflow\n.\n\n\n\n\n\n\nThis will run the workflow (spades) and save the output to the top of your current history in the right hand panel.\n\n\n\n\nView some of the output files with the eye icon to check that the workflow (in this case, just spades) ran correctly.\n\n\n\n\nAdd to the worfklow\n\n\nWe will add another tool to the workflow.\n\n\n\n\n\n\nGo to the top Galaxy panel and click \nWorkflow\n.\n\n\n\n\n\n\nYour workflow \nReads to Annotation\n should be in the list. Click on the drop-down arrow next to this workflow and choose \nEdit\n.\n\n\n\n\n\n\nThis will bring up the Workflow Canvas where we can add more inputs and tools.\n\n\n\n\n\n\nIn the Tools panel, click on \nNGS Annotation: Prokka\n. This will add a Prokka box to the workflow canvas.\n\n\n\n\n\n\nWe need to tell Prokka which genome assembly) to annotate. Join the spades output called \nout_contigs(fasta)\n to the Prokka input called \nContigs to annotate\n.\n\n\n\n\n\n\n\n\n\n\n\n\nClick on the Prokka box and change some of the settings in the right hand Details panel:\n\n\n\n\nSet the following parameters (leave everything else unchanged):\n\n\nLocus tag prefix (\nlocustag)\n: P\n\n\nForce GenBank/ENA/DDJB compliance (\ncompliant)\n: \nNo\n\n\nSequencing Centre ID (\ncentre)\n: V\n\n\nUse genus-specific BLAST database\n \nNo\n  \n\n\n\n\n\n\n\n\nClick on the cog to the top right of the workflow canvas to save.\n\n\n\n\n\n\nClick on the cog again to run.\n\n\n\n\nAgain, choose the input files: \nmutant_R1.fastq\n and \nmutant_R2.fastq\n, and then click \nRun workflow\n.\n\n\n\n\n\n\n\n\nThe output from the workflow (files from spades and prokka) will appear at the top of the History panel.\n\n\n\n\n\n\nClick on the eye icon for some files to verify the workflow ran correctly.      \n\n\n\n\n\n\nAdd more to the workflow\n\n\nWe will add a visualization tool to view the genome annotation.\n\n\n\n\n\n\nGo to the top Galaxy panel and click \nWorkflow\n.\n\n\n\n\n\n\nYour workflow \nReads to Annotation\n should be in the list. Click on the drop-down arrow next to this workflow and choose \nEdit\n.\n\n\n\n\n\n\nThis will bring up the Workflow Canvas where we can add more inputs and tools.\n\n\n\n\n\n\nIn the Tools panel, click on \nStatistics and Visualisation: Graph/Display Data: JBrowse\n. This will add a JBrowse box to the workflow canvas.\n\n\n\n\n\n\nClick on the JBrowse box. In the Details pane:\n\n\n\n\n\n\nUnder \nJBrowse-in-Galaxy Action\n choose \nNew JBrowse Instance\n.\n\n\n\n\n\n\nUnder \nReference genome to display\n choose \nUse a genome from history\n.\n\n\n\n\n\n\nFor \nProduce a Standalone Instance\n select \nYes\n.\n\n\n\n\n\n\nFor \nGenetic Code\n choose \n11: The Bacterial, Archaeal and Plant Plastid Code\n.\n\n\n\n\n\n\nClick \nInsert Track Group\n\n\n\n\n\n\nUnder \nTrack Category\n type in \ngene annotations\n.\n\n\n\n\n\n\nClick \nInsert Annotation Track\n\n\n\n\n\n\nFor \nTrack Type\n choose \nGFF/GFF3/BED/GBK Features\n\n\n\n\n\n\nUnder \nJBrowse Track Type[Advanced]\n select \nCanvas Features\n.\n\n\n\n\n\n\nClick on \nJBrowse Styling Options \n\n\n\n\n\n\nUnder \nJBrowse style.label\n correct the word \nprodcut\n to \nproduct\n.\n\n\n\n\n\n\nUnder \nTrack Visibility\n choose \nOn for new users\n.\n\n\n\n\n\n\n\n\n\n\nNow we need to tell JBrowse the input files to use.\n\n\n\n\n\n\nJoin the Prokka output \nout_fna (fasta)\n to the JBrowse input \nFasta sequences\n\n\n\n\n\n\nJoin the Prokka output \nout_gff (gff)\n to the JBrowse input \nTrack Group 1\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nClick on the cog to save; again to run; choose input files; \nRun workflow\n; examine output files in current history.\n\n\n\n\n\n\nThe workflow will now assemble and annotate the genome, and create a JBrowse view of the annotations.\n\n\n\n\n\n\nJBrowse will produce one output file.\n\n\n\n\nClick on the eye icon to view.\n\n\nIn the centre drop down box, choose contig 6.\n\n\nUnder \nAvailable Tracks\n on the left, tick the boxes.\n\n\nZoom in and out with the plus and minus icons.\n\n\nThe blue blocks are the genome annotations.\n\n\n\n\n\n\n\n\n\n\n\n\n\nSummary\n\n\n\n\n\n\nOur workflow is now:\n\n\n\n\nFastq\n sequence reads to Spades for assembly\n\n\nSpades \ncontigs fasta file\n to Prokka for annotation\n\n\nProkka \nfasta file\n and \n.gff file\n to JBrowse for visualisation.\n\n\n\n\n\n\n\n\nWe can re-run this workflow with different input Fastq files.\n\n\n\n\n\n\nOther workflow options\n\n\nSaving outputs\n\n\nTo save only some output files:\n\n\n\n\nGo to the workflow canvas.\n\n\nFind the star next to the outputs.\n\n\nClick on the star for any outputs you want to save.\n\n\n\n\n\n\nTo save these starred files from the workflow output as a new history:\n\n\n\n\nBefore you click \nRun workflow\n, tick the box above to \nSend results to a new history\n.\n\n\n\n\nImport a workflow\n\n\nTo import an existing Galaxy Workflow:\n\n\n\n\nGo to the Workflow tab in the top panel.\n\n\nAt the top right, click on \nUpload or import workflow\n.\n\n\n\n\nExtract a workflow\n\n\nYou can extract a workflow from an existing Galaxy history.\n\n\n\n\nGo to your Galaxy history\n\n\nClick on the History cog icon and choose \nExtract Workflow\n.\n\n\nGive it a name and click \nCreate Workflow\n.\n\n\nTo edit, go to the Workflow tab, select the workflow, and choose \nEdit\n from the drop down menu. You can then edit the steps on the Workflow Canvas.\n\n\n\n\nA note on workflow tabs\n\n\nWe have been using the top Workflow tab. There is another tab at the bottom of the tool panel called Workflows. Click on \nWorkflows: All Workflows\n. This gives a similar view with a list of workflows, and you can also click on the top right tab \nswitch to workflow management view\n.\n\n\nTo return to the main Galaxy window click on the Analyze Data tab in the top panel.\n\n\nLinks\n\n\nIntroduction to workflows:\n\nhttps://wiki.galaxyproject.org/Learn/AdvancedWorkflow\n\n\nAnother tutorial on workflows:\n\nhttp://vlsci.github.io/lscc_docs/tutorials/galaxy-workflows/galaxy-workflows/\n\n\nGalaxy published workflows:\n\nhttps://usegalaxy.org/workflow/list_published", 
            "title": "Galaxy workflows"
        }, 
        {
            "location": "/modules/workflows/#galaxy-workflows", 
            "text": "This tutorial assumes you have used Galaxy before.  Although we can use tools in Galaxy to analyse data and create a history, there is also a way to create a workflow of files, tools, settings and outputs. You can then input different datasets and run the workflow.  This tutorial covers building a workflow to analyse a bacterial genome, from input Fastq sequencing reads to assembly, annotation, and visualization.", 
            "title": "Galaxy workflows"
        }, 
        {
            "location": "/modules/workflows/#start", 
            "text": "Go to your Galaxy instance and Register/Login.  Import a history of data files:   Click on the  History  cog   Select  Import from File  In the box called  Archived History URL , paste in this link address to the Galaxy history of input files:   https://swift.rc.nectar.org.au:8888/v1/AUTH_377/public/Microbial_tutorials/Galaxy_history_input_files.tar.gz   Click  Submit  Wait a few seconds.  Click on the  View all histories  button   See if the Galaxy history has been imported: it will be called  imported from archive: Data  Above that pane, click on the  Switch to  button.  Then click  Done  (in the top left corner).   You should now have a list of five files in your current history.    Re-name this history  Workflows .", 
            "title": "Start"
        }, 
        {
            "location": "/modules/workflows/#build-a-workflow", 
            "text": "We will first write a workflow for genome assembly.   In the top menu bar in Galaxy, click on  Workflow .     Click on  Create new workflow      Under  Workflow Name:  put in  Reads to Annotation .    Click  Create    This will bring up the  Workflow Canvas , a grid where you can arrange the workflow.", 
            "title": "Build a workflow"
        }, 
        {
            "location": "/modules/workflows/#add-inputs", 
            "text": "In the Tools panel, click  Inputs: Input datset  twice (at the very top of the list).    A box will appear: drag it to the left and there will be another box underneath it. Drag this also to the left. Your workflow canvas should look like this:      Click on the first box. Look in the right hand panel (now called  Details ) and change the name of the Input dataset to  R1.fastq . Press Enter for the change to be saved.     Repeat for the second input dataset box, naming that one  R2.fastq .", 
            "title": "Add inputs"
        }, 
        {
            "location": "/modules/workflows/#add-the-tool-spades", 
            "text": "In the tools panel, click on  NGS Analysis: NGS Assembly: spades .\nThis puts the spades box onto the workflow canvas.      Click on the spades box and look in the Details pane on the right. This shows all the options in spades. Choose:    Run only Assembly :  Yes  [the  Yes  button should be darker grey]   Kmers to use separated by commas:   33,55,91   [note: no spaces]    Coverage cutoff:   auto", 
            "title": "Add the tool \"spades\""
        }, 
        {
            "location": "/modules/workflows/#join-inputs-to-the-tool", 
            "text": "Now tell spades which input files to use.    Look at the input dataset box called  R1.fastq  and find the small arrow:     Click on this and drag the arrow over to the spades box input arrow   next to  Libraries 1   Files 1   Forward reads .      Repeat for the dataset box  R2.fastq , joining to the spades box next to  Libraries 1   Files 1   Reverse reads .", 
            "title": "Join inputs to the tool"
        }, 
        {
            "location": "/modules/workflows/#save-it-and-run", 
            "text": "Click on the cog at the top right of the workflow canvas and  Save .      Click the cog again and choose  Run .    This brings up a window where you specify the input datasets to use in the workflow.   Under  Step1: Input dataset  choose  mutant_R1.fastq .  Under  Step2: Input dataset  choose  mutant_R2.fastq .     Click  Run workflow .    This will run the workflow (spades) and save the output to the top of your current history in the right hand panel.   View some of the output files with the eye icon to check that the workflow (in this case, just spades) ran correctly.", 
            "title": "Save it and run"
        }, 
        {
            "location": "/modules/workflows/#add-to-the-worfklow", 
            "text": "We will add another tool to the workflow.    Go to the top Galaxy panel and click  Workflow .    Your workflow  Reads to Annotation  should be in the list. Click on the drop-down arrow next to this workflow and choose  Edit .    This will bring up the Workflow Canvas where we can add more inputs and tools.    In the Tools panel, click on  NGS Annotation: Prokka . This will add a Prokka box to the workflow canvas.    We need to tell Prokka which genome assembly) to annotate. Join the spades output called  out_contigs(fasta)  to the Prokka input called  Contigs to annotate .       Click on the Prokka box and change some of the settings in the right hand Details panel:   Set the following parameters (leave everything else unchanged):  Locus tag prefix ( locustag) : P  Force GenBank/ENA/DDJB compliance ( compliant) :  No  Sequencing Centre ID ( centre) : V  Use genus-specific BLAST database   No        Click on the cog to the top right of the workflow canvas to save.    Click on the cog again to run.   Again, choose the input files:  mutant_R1.fastq  and  mutant_R2.fastq , and then click  Run workflow .     The output from the workflow (files from spades and prokka) will appear at the top of the History panel.    Click on the eye icon for some files to verify the workflow ran correctly.", 
            "title": "Add to the worfklow"
        }, 
        {
            "location": "/modules/workflows/#add-more-to-the-workflow", 
            "text": "We will add a visualization tool to view the genome annotation.    Go to the top Galaxy panel and click  Workflow .    Your workflow  Reads to Annotation  should be in the list. Click on the drop-down arrow next to this workflow and choose  Edit .    This will bring up the Workflow Canvas where we can add more inputs and tools.    In the Tools panel, click on  Statistics and Visualisation: Graph/Display Data: JBrowse . This will add a JBrowse box to the workflow canvas.    Click on the JBrowse box. In the Details pane:    Under  JBrowse-in-Galaxy Action  choose  New JBrowse Instance .    Under  Reference genome to display  choose  Use a genome from history .    For  Produce a Standalone Instance  select  Yes .    For  Genetic Code  choose  11: The Bacterial, Archaeal and Plant Plastid Code .    Click  Insert Track Group    Under  Track Category  type in  gene annotations .    Click  Insert Annotation Track    For  Track Type  choose  GFF/GFF3/BED/GBK Features    Under  JBrowse Track Type[Advanced]  select  Canvas Features .    Click on  JBrowse Styling Options     Under  JBrowse style.label  correct the word  prodcut  to  product .    Under  Track Visibility  choose  On for new users .      Now we need to tell JBrowse the input files to use.    Join the Prokka output  out_fna (fasta)  to the JBrowse input  Fasta sequences    Join the Prokka output  out_gff (gff)  to the JBrowse input  Track Group 1         Click on the cog to save; again to run; choose input files;  Run workflow ; examine output files in current history.    The workflow will now assemble and annotate the genome, and create a JBrowse view of the annotations.    JBrowse will produce one output file.   Click on the eye icon to view.  In the centre drop down box, choose contig 6.  Under  Available Tracks  on the left, tick the boxes.  Zoom in and out with the plus and minus icons.  The blue blocks are the genome annotations.", 
            "title": "Add more to the workflow"
        }, 
        {
            "location": "/modules/workflows/#summary", 
            "text": "Our workflow is now:   Fastq  sequence reads to Spades for assembly  Spades  contigs fasta file  to Prokka for annotation  Prokka  fasta file  and  .gff file  to JBrowse for visualisation.     We can re-run this workflow with different input Fastq files.", 
            "title": "Summary"
        }, 
        {
            "location": "/modules/workflows/#other-workflow-options", 
            "text": "", 
            "title": "Other workflow options"
        }, 
        {
            "location": "/modules/workflows/#saving-outputs", 
            "text": "To save only some output files:   Go to the workflow canvas.  Find the star next to the outputs.  Click on the star for any outputs you want to save.    To save these starred files from the workflow output as a new history:   Before you click  Run workflow , tick the box above to  Send results to a new history .", 
            "title": "Saving outputs"
        }, 
        {
            "location": "/modules/workflows/#import-a-workflow", 
            "text": "To import an existing Galaxy Workflow:   Go to the Workflow tab in the top panel.  At the top right, click on  Upload or import workflow .", 
            "title": "Import a workflow"
        }, 
        {
            "location": "/modules/workflows/#extract-a-workflow", 
            "text": "You can extract a workflow from an existing Galaxy history.   Go to your Galaxy history  Click on the History cog icon and choose  Extract Workflow .  Give it a name and click  Create Workflow .  To edit, go to the Workflow tab, select the workflow, and choose  Edit  from the drop down menu. You can then edit the steps on the Workflow Canvas.", 
            "title": "Extract a workflow"
        }, 
        {
            "location": "/modules/workflows/#a-note-on-workflow-tabs", 
            "text": "We have been using the top Workflow tab. There is another tab at the bottom of the tool panel called Workflows. Click on  Workflows: All Workflows . This gives a similar view with a list of workflows, and you can also click on the top right tab  switch to workflow management view .  To return to the main Galaxy window click on the Analyze Data tab in the top panel.", 
            "title": "A note on workflow tabs"
        }, 
        {
            "location": "/modules/workflows/#links", 
            "text": "Introduction to workflows: https://wiki.galaxyproject.org/Learn/AdvancedWorkflow  Another tutorial on workflows: http://vlsci.github.io/lscc_docs/tutorials/galaxy-workflows/galaxy-workflows/  Galaxy published workflows: https://usegalaxy.org/workflow/list_published", 
            "title": "Links"
        }, 
        {
            "location": "/modules/frogs/", 
            "text": "Metagenomics\n\n\nMetagenomics aims to compare microbial communities from different environments by using information from the metagenome. Typically, 16S rRNA is used when classifying taxa, and whole-genome sequencing when aiming to identify gene functions and pathways.\n\n\n\n\n\nThis tutorial covers the tool called FROGS (in Galaxy): \nFind Rapidly OTU with Galaxy Solution\n.\n\n\n\n\n\n\nGet data\n\n\n\n\n\n\nThe data: paired-end Illumina reads from two environmental samples. \n\n\n\n\n\n\nIn Galaxy, in the history panel, click on the cog item, and select \nimport from file\n.\n\n\n\n\nIn the \nArchived History URL:\n box paste:\n\n\n\n\nhttps://swift.rc.nectar.org.au:8888/v1/AUTH_377/public/Microbial_tutorials/Galaxy-History-16S_metagenomics_dataset.tar.gz\n\n\n\n\n\n\nYou should now have four files in your Galaxy history.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nIn the Galaxy tools panel, in the top search bar, type FROGS.\n\n\nThis will bring up the various tools available.\n\n\nWe will be using 6 of these tools.\n\n\n\n\n\n\n\n\n\n\n1. Pre-process\n\n\nThis is the first step in the Frogs analysis. It takes in the forward and reverse sequencing reads (R1 and R2) from multiple samples (e.g. microbiome A and microbiome B) and performs the following steps:\n\n\n\n\nIf the data is not in contigs, read1 and read2 will be overlapped (allowing some mismatch in overlapping region).\n\n\nContigs that are too big or too small will be filtered out. \n\n\nIf using the Illumina standard protocol: will look for those primers, filter out contigs without primers, and cut the primer sequences.\n\n\nSequences that are too small or of poor quality will be filtered out.\n\n\nSequences will be de-replicated: duplicates will be removed but the number of duplicates will be recorded.\n\n\n\n\nRun\n\n\nGo to \nFROGS Pre-process\n and select the following:\n\n\n\n\nSequencer\n: Illumina\n\n\nInput type\n: Files by samples\n\n\nReads alread contiged?\n: No\n\n\nSamples\n:\n\n\nName\n: microbiomeA \nnote: no spaces\n\n\nReads1\n: \nmicrobiomeA_R1.fq\n\n\nReads2\n: \nmicrobiomeA_R2.fq\n\n\nInsert Samples\n- click plus sign\n\n\nName\n: microbiomeB\n\n\nReads1\n: \nmicrobiomeB_R1.fq\n\n\nReads2\n: \nmicrobiomeB_R2.fq\n\n\n\n\n\n\nReads 1 size\n: 250\n\n\nReads 2 size\n: 250\n\n\nExpected amplicon size\n: 420\n\n\nMinimum amplicon size\n: 380\n\n\nMaximum amplicon size\n: 460\n\n\nSequencing protocol\n: Illumina standard\n\n\n5\n primer\n: GGCGVACGGGTGAGTAA\n\n\n3\n primer\n: GTGCCAGCNGCNGCGG \nnote: needs to be in 5\n to 3\n orientation\n\n\nExecute\n\n\n\n\n\n\nOutput\n\n\nThere are three output files. Click on the eye icon for each to see their contents.\n\n\nReport:\n\n\n\n\nThe \nreport.html\n shows how samples were filtered. For example, in the bar chart called \nFiltering summary\n, the number of reads kept at each filtering stage is displayed. We would expect some decrease in some of these categories, but if many reads have been filtered at a particular stage it could indicate poor quality data.\n\n\n\n\n\n\n\n\nBelow this chart, a table shows the statistics for each sample. Check the boxes next to \nmicrobiomeA\n and \nmicrobiomeB\n and then click \nDisplay amplicon lengths\n - shows amplicon distribution before filtering. Click \nDisplay preprocessed amplicon lengths\n - shows the distribution has been narrowed after filtering. Check if both samples are similar.\n\n\n\n\nCounts:\n\n\n\n\nThe \ncounts.tsv\n file is a list of sequences and their counts in the two samples.\n\n\n\n\nFasta file:\n\n\n\n\nThe \ndereplicated.fasta\n contains the sequences, without any duplicates.\n\n\n\n\n2. Clustering swarm\n\n\nIn this step, sequences are clustered into groups using Swarm (more information about \nSwarm\n). This takes the pre-processed \nfasta\n and \ncounts\n files and does the following:\n\n\n\n\nSorts reads by abundance.\n\n\nClusters the reads into pre-clusters using Swarm and distance parameter of 1.\n\n\nSorts these pre-clusters by abundance.\n\n\nCluster the pre-clusters using Swarm and a user-specified distance.\n\n\n\n\nGo to \nFROGS Clustering swarm\n and select the following:\n\n\n\n\nSequences files\n: \ndereplicated.fasta\n\n\nCounts file\n: \ncount.tsv\n\n\nAggregation distance\n: 3\n\n\nPerform deionising clustering step?\n: Yes\n\n\nExecute\n\n\n\n\nNote: Galaxy may say that the job submission has failed. Click Close, then click refresh in the top of the history panel. The job should be running.\n\n\n\n\nOutput\n\n\nThere are three output files.\n\n\n\n\nThe \nabundance.biom\n shows the abundance of each cluster.\n\n\nThe \nseed_sequences.fasta\n contains the the cluster (OTU) representative sequences. \n\n\nThe \nswarms.composition.tsv\n shows what is in each cluster.\n\n\n\n\n3. Remove chimera\n\n\nClosely-related sequences may form chimeras (mixed sequences) during PCR (libray prep). This step removes these sequences by the following method:\n\n\n\n\nSplits input data into samples\n\n\nUses vsearch to find chimeras in each sample\n\n\nRemoves chimeras\n\n\n\n\nGo to \nFROGS Remove chimera\n and select the following:\n\n\n\n\nSequences file\n: \nseed_sequences.fasta\n\n\nAbundance type\n: \nBIOM file\n\n\nAbundance file\n: \nabundance.biom\n\n\nExecute\n\n\n\n\nNote: Galaxy may say that the job submission has failed. Click Close, then click refresh in the top of the history panel. The job should be running.\n\n\n\n\nOutput\n\n\nThere are three output files.\n\n\n\n\nThe \nnon_chimera.fasta\n is a filtered file containing no chimeras.\n\n\nThe \nnon_chimera_abundance.biom\n is a filtered abundance file containing no chimeras.\n\n\nThe summary \nreport.html\n. In this case, although almost 70% of the clusters were removed, more than 70% of the actual reads were kept.\n\n\n\n\n\n\n4. Filters\n\n\nThe OTUs (Operational Taxonomic Units) have now been clustered. In this step, we will filter out some of the OTUs that are either not in both samples, and/or contain at least 0.005% of all the sequences.\n\n\nGo to \nFROGS Filters\n and select the following:\n\n\n\n\nSequences file\n: \nnon_chimera.fasta\n\n\nAbundance file\n:  \nnon_chimera_abundance.biom\n\n\n*** THE FILTERS ON OTUS IN SAMPLES, OTUS SIZE and SEQUENCE PERCENTAGE\n: Apply filters\n\n\nMinimum number of samples\n: 2\n\n\nMinimum proportion/number of sequences to keep OTU\n: 0.00005\n\n\nN biggest OTU\n: leave blank\n\n\n*** THE FILTERS ON RDP\n: No filters\n\n\n*** THE FILTERS ON BLAST\n: No filters\n\n\n*** THE FILTERS ON CONTAMINATIONS\n: No filters\n\n\nExecute\n\n\n\n\n]\n\n\nNote: Galaxy may say that the job submission has failed. Click Close, then click refresh in the top of the history panel. The job should be running.\n\n\nOutput\n\n\nThere are four output files.\n\n\n\n\nsequences.fasta\n: the retained sequences.\n\n\nabudance.biom\n: the abundance file.\n\n\nexcluded.tsv\n: discarded OTUs\n\n\nreport.html\n: this shows the proportion of OTUs and the proportion of sequences kept. In this example, although most OTUs have been filtered out, most sequences have been retained.\n\n\n\n\n\n\n\n\n5. Affiliation OTU\n\n\nAn OTU is a cluster of sequences. This step adds the taxonomy to the abundance file. It uses the SILVA database for rRNA.\n\n\n\n\n\nGo to \nFROGS Affiliation OTU\n and select:\n\n\n\n\nUsing reference database\n: silva123\n\n\nAlso perform RDP assignation\n: No\n\n\nOTU seed sequence\n: \nsequences.fasta\n from step 4\n\n\nAbundance file\n: \nabundance.biom\n from step 4\n\n\nExecute\n\n\n\n\n\n\nNote: Galaxy may say that the job submission has failed. Click Close, then click refresh in the top of the history panel. The job should be running.\n\n\n\n\n\nOutput\n\n\nThere are two output files.\n\n\n\n\n\n\naffiliation.biom\n: the abundance file with affiliation. Note: this \n.biom\n file is not human-readable. If you wish, you can convert it with the FROGS \nbiom to tsv\n tool.\n\n\n\n\n\n\nreport.html\n: the report shows the proportion of OTUs and sequences affiliated to sequences in the database. Here we can see that almost all OTUs and sequences have been taxonomically assigned, but almost 10% of OTUs could be assigned to multiple species. \n\n\n\n\n\n\n\n\n6. Affiliations stat\n\n\nThis step computes some statistics from the analysis and generates a report of the OTUs/taxonomy found.\n\n\nGo to \nFROGS Affiliations stat\n and select:\n\n\n\n\nAbundance file\n: \naffiliation.biom\n from step 5\n\n\nRarefaction ranks\n: Class Order Family Genus Species\n\n\nAffiliation processed\n: FROGS blast\n\n\nExecute\n\n\n\n\n\n\nOutput\n\n\nThere is one output file. Click on the eye icon next to \nsummary.html\n:\n\n\n\n\nclick on \nDisplay global distribution\n: this shows the taxonomy of the sample. Start at the centre; major groups each have a segment by colour; as you go outwards, taxonomic identification becomes more specific. \n Click on a segment to display a table of statisics below. Click on the cross in the top right corner to exit.\n\n\n\n\n\n\n\n\n\n\n\nNext, we will look at the rarefaction curve, which is a measure of samples vs diversity. \n Click on the boxes next to each of the samples (both, or one at a time) in the table (microbiomeA and microbiomeB). Click \nDisplay rarefaction\n.\n\n\n\n\n\n\nLinks\n\n\n\n\nFROGS slides by Yvan Le Bras \nhttps://f1000research.com/slides/5-1832\n\n\nThe SILVA database: \nhttps://www.arb-silva.de/\n\n\nOther metagenomics software:\n\n\nQIIME: \nhttp://qiime.org/\n    \n\n\nUPARSE: \nhttp://www.drive5.com/uparse/\n\n\nMOTHUR: \nhttps://www.mothur.org/\n\n\nMG-RAST: \nhttp://metagenomics.anl.gov/", 
            "title": "Metagenomics with FROGS"
        }, 
        {
            "location": "/modules/frogs/#metagenomics", 
            "text": "Metagenomics aims to compare microbial communities from different environments by using information from the metagenome. Typically, 16S rRNA is used when classifying taxa, and whole-genome sequencing when aiming to identify gene functions and pathways.   This tutorial covers the tool called FROGS (in Galaxy):  Find Rapidly OTU with Galaxy Solution .", 
            "title": "Metagenomics"
        }, 
        {
            "location": "/modules/frogs/#get-data", 
            "text": "The data: paired-end Illumina reads from two environmental samples.     In Galaxy, in the history panel, click on the cog item, and select  import from file .   In the  Archived History URL:  box paste:   https://swift.rc.nectar.org.au:8888/v1/AUTH_377/public/Microbial_tutorials/Galaxy-History-16S_metagenomics_dataset.tar.gz    You should now have four files in your Galaxy history.         In the Galaxy tools panel, in the top search bar, type FROGS.  This will bring up the various tools available.  We will be using 6 of these tools.", 
            "title": "Get data"
        }, 
        {
            "location": "/modules/frogs/#1-pre-process", 
            "text": "This is the first step in the Frogs analysis. It takes in the forward and reverse sequencing reads (R1 and R2) from multiple samples (e.g. microbiome A and microbiome B) and performs the following steps:   If the data is not in contigs, read1 and read2 will be overlapped (allowing some mismatch in overlapping region).  Contigs that are too big or too small will be filtered out.   If using the Illumina standard protocol: will look for those primers, filter out contigs without primers, and cut the primer sequences.  Sequences that are too small or of poor quality will be filtered out.  Sequences will be de-replicated: duplicates will be removed but the number of duplicates will be recorded.", 
            "title": "1. Pre-process"
        }, 
        {
            "location": "/modules/frogs/#run", 
            "text": "Go to  FROGS Pre-process  and select the following:   Sequencer : Illumina  Input type : Files by samples  Reads alread contiged? : No  Samples :  Name : microbiomeA  note: no spaces  Reads1 :  microbiomeA_R1.fq  Reads2 :  microbiomeA_R2.fq  Insert Samples - click plus sign  Name : microbiomeB  Reads1 :  microbiomeB_R1.fq  Reads2 :  microbiomeB_R2.fq    Reads 1 size : 250  Reads 2 size : 250  Expected amplicon size : 420  Minimum amplicon size : 380  Maximum amplicon size : 460  Sequencing protocol : Illumina standard  5  primer : GGCGVACGGGTGAGTAA  3  primer : GTGCCAGCNGCNGCGG  note: needs to be in 5  to 3  orientation  Execute", 
            "title": "Run"
        }, 
        {
            "location": "/modules/frogs/#output", 
            "text": "There are three output files. Click on the eye icon for each to see their contents.  Report:   The  report.html  shows how samples were filtered. For example, in the bar chart called  Filtering summary , the number of reads kept at each filtering stage is displayed. We would expect some decrease in some of these categories, but if many reads have been filtered at a particular stage it could indicate poor quality data.     Below this chart, a table shows the statistics for each sample. Check the boxes next to  microbiomeA  and  microbiomeB  and then click  Display amplicon lengths  - shows amplicon distribution before filtering. Click  Display preprocessed amplicon lengths  - shows the distribution has been narrowed after filtering. Check if both samples are similar.   Counts:   The  counts.tsv  file is a list of sequences and their counts in the two samples.   Fasta file:   The  dereplicated.fasta  contains the sequences, without any duplicates.", 
            "title": "Output"
        }, 
        {
            "location": "/modules/frogs/#2-clustering-swarm", 
            "text": "In this step, sequences are clustered into groups using Swarm (more information about  Swarm ). This takes the pre-processed  fasta  and  counts  files and does the following:   Sorts reads by abundance.  Clusters the reads into pre-clusters using Swarm and distance parameter of 1.  Sorts these pre-clusters by abundance.  Cluster the pre-clusters using Swarm and a user-specified distance.   Go to  FROGS Clustering swarm  and select the following:   Sequences files :  dereplicated.fasta  Counts file :  count.tsv  Aggregation distance : 3  Perform deionising clustering step? : Yes  Execute   Note: Galaxy may say that the job submission has failed. Click Close, then click refresh in the top of the history panel. The job should be running.", 
            "title": "2. Clustering swarm"
        }, 
        {
            "location": "/modules/frogs/#output_1", 
            "text": "There are three output files.   The  abundance.biom  shows the abundance of each cluster.  The  seed_sequences.fasta  contains the the cluster (OTU) representative sequences.   The  swarms.composition.tsv  shows what is in each cluster.", 
            "title": "Output"
        }, 
        {
            "location": "/modules/frogs/#3-remove-chimera", 
            "text": "Closely-related sequences may form chimeras (mixed sequences) during PCR (libray prep). This step removes these sequences by the following method:   Splits input data into samples  Uses vsearch to find chimeras in each sample  Removes chimeras   Go to  FROGS Remove chimera  and select the following:   Sequences file :  seed_sequences.fasta  Abundance type :  BIOM file  Abundance file :  abundance.biom  Execute   Note: Galaxy may say that the job submission has failed. Click Close, then click refresh in the top of the history panel. The job should be running.", 
            "title": "3. Remove chimera"
        }, 
        {
            "location": "/modules/frogs/#output_2", 
            "text": "There are three output files.   The  non_chimera.fasta  is a filtered file containing no chimeras.  The  non_chimera_abundance.biom  is a filtered abundance file containing no chimeras.  The summary  report.html . In this case, although almost 70% of the clusters were removed, more than 70% of the actual reads were kept.", 
            "title": "Output"
        }, 
        {
            "location": "/modules/frogs/#4-filters", 
            "text": "The OTUs (Operational Taxonomic Units) have now been clustered. In this step, we will filter out some of the OTUs that are either not in both samples, and/or contain at least 0.005% of all the sequences.  Go to  FROGS Filters  and select the following:   Sequences file :  non_chimera.fasta  Abundance file :   non_chimera_abundance.biom  *** THE FILTERS ON OTUS IN SAMPLES, OTUS SIZE and SEQUENCE PERCENTAGE : Apply filters  Minimum number of samples : 2  Minimum proportion/number of sequences to keep OTU : 0.00005  N biggest OTU : leave blank  *** THE FILTERS ON RDP : No filters  *** THE FILTERS ON BLAST : No filters  *** THE FILTERS ON CONTAMINATIONS : No filters  Execute   ]  Note: Galaxy may say that the job submission has failed. Click Close, then click refresh in the top of the history panel. The job should be running.", 
            "title": "4. Filters"
        }, 
        {
            "location": "/modules/frogs/#output_3", 
            "text": "There are four output files.   sequences.fasta : the retained sequences.  abudance.biom : the abundance file.  excluded.tsv : discarded OTUs  report.html : this shows the proportion of OTUs and the proportion of sequences kept. In this example, although most OTUs have been filtered out, most sequences have been retained.", 
            "title": "Output"
        }, 
        {
            "location": "/modules/frogs/#5-affiliation-otu", 
            "text": "An OTU is a cluster of sequences. This step adds the taxonomy to the abundance file. It uses the SILVA database for rRNA.   Go to  FROGS Affiliation OTU  and select:   Using reference database : silva123  Also perform RDP assignation : No  OTU seed sequence :  sequences.fasta  from step 4  Abundance file :  abundance.biom  from step 4  Execute    Note: Galaxy may say that the job submission has failed. Click Close, then click refresh in the top of the history panel. The job should be running.", 
            "title": "5. Affiliation OTU"
        }, 
        {
            "location": "/modules/frogs/#output_4", 
            "text": "There are two output files.    affiliation.biom : the abundance file with affiliation. Note: this  .biom  file is not human-readable. If you wish, you can convert it with the FROGS  biom to tsv  tool.    report.html : the report shows the proportion of OTUs and sequences affiliated to sequences in the database. Here we can see that almost all OTUs and sequences have been taxonomically assigned, but almost 10% of OTUs could be assigned to multiple species.", 
            "title": "Output"
        }, 
        {
            "location": "/modules/frogs/#6-affiliations-stat", 
            "text": "This step computes some statistics from the analysis and generates a report of the OTUs/taxonomy found.  Go to  FROGS Affiliations stat  and select:   Abundance file :  affiliation.biom  from step 5  Rarefaction ranks : Class Order Family Genus Species  Affiliation processed : FROGS blast  Execute", 
            "title": "6. Affiliations stat"
        }, 
        {
            "location": "/modules/frogs/#output_5", 
            "text": "There is one output file. Click on the eye icon next to  summary.html :   click on  Display global distribution : this shows the taxonomy of the sample. Start at the centre; major groups each have a segment by colour; as you go outwards, taxonomic identification becomes more specific.   Click on a segment to display a table of statisics below. Click on the cross in the top right corner to exit.      Next, we will look at the rarefaction curve, which is a measure of samples vs diversity.   Click on the boxes next to each of the samples (both, or one at a time) in the table (microbiomeA and microbiomeB). Click  Display rarefaction .", 
            "title": "Output"
        }, 
        {
            "location": "/modules/frogs/#links", 
            "text": "FROGS slides by Yvan Le Bras  https://f1000research.com/slides/5-1832  The SILVA database:  https://www.arb-silva.de/  Other metagenomics software:  QIIME:  http://qiime.org/       UPARSE:  http://www.drive5.com/uparse/  MOTHUR:  https://www.mothur.org/  MG-RAST:  http://metagenomics.anl.gov/", 
            "title": "Links"
        }, 
        {
            "location": "/modules/kraken/", 
            "text": "Sample identification with Kraken\n\n\nTo identify a sample from sequencing reads, we can use the tool \nKraken\n. This tool can also be used to identify members in a mixed set of reads, for metagenomics.\n\n\n\n\n\n\ne.g. reads from one sample \n Kraken \n 95% \nStaphylococcus aureus\n.\n\n\n\n\n\n\ne.g. mixed reads \n Kraken \n 50% \nStaphylococcus aureus\n, 40%  \nCampylobacter concisus\n, 10% unclassified.\n\n\n\n\n\n\n\n\n\nIn this tutorial we will use Kraken to confirm the identify of reads from a bacterial isolate.\n\n\nGet data\n\n\nIn Galaxy, go to \nShared Data\n in the top panel, and click on the history named \nKraken data\n. In the top right, click \nSwitch to this history\n.\n\n\nYour current history should now contain four files. If you are using the tutorial independently of a workshop, at this stage you can upload your FASTQ files into the current history.\n\n\n\n\n\n\n\nRun Kraken\n\n\nWe have a sample that should be \nStaphylococcus aureus\n. The paired-end FASTQ read files are:\n\n\n\n\nstaph_R1.fq\n and \nstaph_R2.fq\n.\n\n\n\n\n(We will look at the other set of files later on in the tutorial).\n\n\n\n\n\n\nGo to \nTools \n NGS Analysis \n Metagenomic analyses \n Kraken, assign taxonomic labels to sequencing reads\n\n\n\n\n\n\nSet the following parameters:\n\n\n\n\nSingle or paired reads\n: \nPaired\n\n\nForward strand:\n \nstaph_R1.fq\n\n\nReverse strand:\n \nstaph_R2.fq\n\n\nleave other settings as they are\n\n\n\n\n\n\n\n\nYour tool interface should look like this:\n\n\n\n\n\n\n\n\n\n\nClick \nExecute\n\n\n\n\n\n\n\nExamine the output\n\n\nThe output is a file called \nKraken on data x and x: Classification\n. This will be at the top of your history pane.\n\n\nClick \nRefresh\n if the file hasn\nt yet turned green.\n\n\n\n\nWhen the file is green, click on the eye icon to view.\n\n\n\n\nWe will turn this output into something easier to read in the next step.\n\n\nColumn 2 is the sequence ID.\n\n\nColumn 3 is the taxon ID (from NCBI).\n\n\nColumn 5 is a summary of all the taxon IDs that each k-mer in the sequence matched to (taxon ID:number of k-mers).  \n\n\n\n\n\n\n\n\n\nKraken report\n\n\nGo to \nTools \n NGS Analysis \n Metagenomic analyses \n Kraken-report\n\n\n\n\n\n\nSet the following parameters:\n\n\n\n\nKraken output\n: \nKraken on data x and x: Classification\n\n\nSelect a Kraken database\n: \nkrakendb\n\n\nClick \nExecute\n\n\n\n\n\n\n\n\nThe output file is called \nKraken-report on data x\n.\n\n\n\n\nClick on the eye icon to view.\n\n\nColumn 1: percentage of reads in the clade/taxon in Column 6\n\n\nColumn 2: number of reads in the clade.\n\n\nColumn 3: number of reads in the clade but not further classified.\n\n\nColumn 4: code indicating the rank of the classification: (U)nclassified, (D)omain, (K)ingdom, (P)hylum, (C)lass, (O)rder, (F)amily, (G)enus, (S)pecies).\n\n\nColumn 5: NCBI taxonomy ID.\n\n\n\n\n\n\nApproximately 95% of reads were classified as \nStaphylococcus aureus\n, confirming the correct identity of our bacterial sample.\n\n\n\n\nOf these reads, roughly half were uniquely present in \nS. aureus\n subsp. \naureus\n, and most of those were uniquely present in strain HO 5096 0412.\n\n\nThe sample strain is therefore most related to the HO 5096 0412 strain.\n\n\n\n\nThe remaining reads within the \nS. aureus\n clade were classified into various taxa.\n\n\n\n\nScroll down column 3 to see the number of reads assigned directly to the taxon in column 6.\n\n\nThese are all very low and can be disregarded.\n\n\n\n\n\n\n\nNext\n\n\nRe-run Kraken with another sample. This sample should be \nEnterococcus faecalis\n.\n\n\n\n\nUse the files \nent_R1.fq\n and \nent_R2.fq\n.\n\n\nRun \nKraken\n with these files. These are paired-end reads.\n\n\nWith the \nClassification\n file from Kraken, run \nKraken-report\n.\n\n\nCick on the eye icon to view the \nKraken-report\n file.\n\n\n\n\n\n\n\n\n\n\n63% are classified to the genus \nEnterococcus\n, and most of these to \nE. faecalis\n.\n\n\n\n\n\n\nHowever, if we scroll down the table of results, we see that 31% are classified to the genus \nMycobacterium\n, mostly \nM. abscessus\n. These are not in the same phylum as \nEnterococcus\n.\n\n\n\n\n\n\n\n\n\n\nThis sample is probably contaminated.\n\n\n\n\nLinks\n\n\nKraken paper\n\n\nKraken software", 
            "title": "Sample identification with Kraken"
        }, 
        {
            "location": "/modules/kraken/#sample-identification-with-kraken", 
            "text": "To identify a sample from sequencing reads, we can use the tool  Kraken . This tool can also be used to identify members in a mixed set of reads, for metagenomics.    e.g. reads from one sample   Kraken   95%  Staphylococcus aureus .    e.g. mixed reads   Kraken   50%  Staphylococcus aureus , 40%   Campylobacter concisus , 10% unclassified.     In this tutorial we will use Kraken to confirm the identify of reads from a bacterial isolate.", 
            "title": "Sample identification with Kraken"
        }, 
        {
            "location": "/modules/kraken/#get-data", 
            "text": "In Galaxy, go to  Shared Data  in the top panel, and click on the history named  Kraken data . In the top right, click  Switch to this history .  Your current history should now contain four files. If you are using the tutorial independently of a workshop, at this stage you can upload your FASTQ files into the current history.", 
            "title": "Get data"
        }, 
        {
            "location": "/modules/kraken/#run-kraken", 
            "text": "We have a sample that should be  Staphylococcus aureus . The paired-end FASTQ read files are:   staph_R1.fq  and  staph_R2.fq .   (We will look at the other set of files later on in the tutorial).    Go to  Tools   NGS Analysis   Metagenomic analyses   Kraken, assign taxonomic labels to sequencing reads    Set the following parameters:   Single or paired reads :  Paired  Forward strand:   staph_R1.fq  Reverse strand:   staph_R2.fq  leave other settings as they are     Your tool interface should look like this:      Click  Execute", 
            "title": "Run Kraken"
        }, 
        {
            "location": "/modules/kraken/#examine-the-output", 
            "text": "The output is a file called  Kraken on data x and x: Classification . This will be at the top of your history pane.  Click  Refresh  if the file hasn t yet turned green.   When the file is green, click on the eye icon to view.   We will turn this output into something easier to read in the next step.  Column 2 is the sequence ID.  Column 3 is the taxon ID (from NCBI).  Column 5 is a summary of all the taxon IDs that each k-mer in the sequence matched to (taxon ID:number of k-mers).", 
            "title": "Examine the output"
        }, 
        {
            "location": "/modules/kraken/#kraken-report", 
            "text": "Go to  Tools   NGS Analysis   Metagenomic analyses   Kraken-report    Set the following parameters:   Kraken output :  Kraken on data x and x: Classification  Select a Kraken database :  krakendb  Click  Execute     The output file is called  Kraken-report on data x .   Click on the eye icon to view.  Column 1: percentage of reads in the clade/taxon in Column 6  Column 2: number of reads in the clade.  Column 3: number of reads in the clade but not further classified.  Column 4: code indicating the rank of the classification: (U)nclassified, (D)omain, (K)ingdom, (P)hylum, (C)lass, (O)rder, (F)amily, (G)enus, (S)pecies).  Column 5: NCBI taxonomy ID.    Approximately 95% of reads were classified as  Staphylococcus aureus , confirming the correct identity of our bacterial sample.   Of these reads, roughly half were uniquely present in  S. aureus  subsp.  aureus , and most of those were uniquely present in strain HO 5096 0412.  The sample strain is therefore most related to the HO 5096 0412 strain.   The remaining reads within the  S. aureus  clade were classified into various taxa.   Scroll down column 3 to see the number of reads assigned directly to the taxon in column 6.  These are all very low and can be disregarded.", 
            "title": "Kraken report"
        }, 
        {
            "location": "/modules/kraken/#next", 
            "text": "Re-run Kraken with another sample. This sample should be  Enterococcus faecalis .   Use the files  ent_R1.fq  and  ent_R2.fq .  Run  Kraken  with these files. These are paired-end reads.  With the  Classification  file from Kraken, run  Kraken-report .  Cick on the eye icon to view the  Kraken-report  file.      63% are classified to the genus  Enterococcus , and most of these to  E. faecalis .    However, if we scroll down the table of results, we see that 31% are classified to the genus  Mycobacterium , mostly  M. abscessus . These are not in the same phylum as  Enterococcus .      This sample is probably contaminated.", 
            "title": "Next"
        }, 
        {
            "location": "/modules/kraken/#links", 
            "text": "Kraken paper  Kraken software", 
            "title": "Links"
        }, 
        {
            "location": "/modules/pacbio/", 
            "text": "Assembly with PacBio data and SMRT Portal\n\n\nKeywords: de novo assembly, PacBio, PacificBiosciences, HGAP, SMRT Portal, Microbial Genomics Virtual Laboratory\n\n\nThis tutorial will show you how to assemble a bacterial genome \nde novo\n, using the PacBio SMRT Portal on the mGVL. We will use an analysis pipeline called HGAP, the Hierarchical Genome Assembly Process.\n\n\n\n\n\n\n\n\nStart\n\n\n\n\nOpen your mGVL dashboard.\n\n\nYou should see SMRT Portal as one of the instance services on your GVL dashboard.\n\n\nOpen up the SMRT portal web link (to the right) and register/log on.\n\n\n\n\nInput\n\n\n\n\n\nWe will use a dataset from a \nStreptococcus pyogenes\n bacteria.\n\n\nIf this has already been loaded onto SMRT portal (e.g. for use during a workshop), proceed to the next step (\nAssembly\n).\n\n\nOtherwise:\n\n\n\n\nLoad the PacBio data (your own, or the training dataset) onto your GVL.\n\n\nIn the SMRT Portal, go to \nDesign Job\n, the top left tab.\n\n\nGo to \nImport and Manage\n.\n\n\n\nClick \nImport SMRT cells\n.\n\n\n\n\n\nWork out where you put the data on your GVL, and make sure the file path is showing.\n\n\n\n\nIf not, click \nAdd\n and enter the file path to the data.\n\n\nA SMRT cell is the collection of data from a particular cell in the machine. It includes .bax.h5 files.\n\n\n\n\n\n\n\n\nClick on the file path and then \nScan\n to check for new data.\n\n\n\n\n\n\nAssembly\n\n\nHGAP process overview\n\n\nWe will use the Hierarchical Genome Assembly Process (HGAP). This flowchart shows the steps in the process:\n\n\n\n\nSet up job\n\n\n\n\nIn the SMRT Portal, go to the top left tab, \nDesign Job\n.\n\n\nGo to \nCreate New\n.\n\n\nAn \nAnalysis\n window should appear. Tick all the boxes, then \nNext\n.\n\n\nUnder \nJob Name\n enter a name.\n\n\nTo the right, under \nGroups\n choose \nall\n.\n\n\nUnder \nProtocols\n choose \nRS_HGAP_Assembly.3\n.\n\n\nThere is an ellipsis underneath \nProtocols\n - click on the ellipsis.\n\n\n\n\n\n\nThis brings up the settings. Click on \nAssembly\n.\n\n\n\n\n\n\nFor \nCompute Minimum Seed Read Length\n: ensure box is ticked\n\n\n\n\n\n\n\nFor \nNumber of Seed Read Chunks\n: enter \n12\n\n\n\n\nChange the \nGenome Size\n to an approximately correct size for the species. For \nS. pyogenes\n, enter 1800000.\n\n\nFor \nTarget Coverage\n: enter \n10\n\n\nFor \nOverlapper Error Rate\n: enter \n0.04\n\n\nLeave all other settings as they are.\n\n\nClick \nApply\n\n\n\n\nYour protocol window should look like this:\n\n\n\n\n\n\n\n\nClick \nOk\n.  \n\n\n\n\n\n\nIn the \nSMRT Cells Available\n window, select the file to be used. Click on the arrow to transfer these files to the SMRT Cells in Job window.\n\n\n\n\nYou can drag the column widths of the \nUrl\n column so that you can see the URLs of the file paths better.\n\n\n\n\n\n\n\n\nClick \nSave\n (bottom right hand side).\n\n\nNext to \nSave\n, click \nStart\n.\n\n\nThe \nMonitor Jobs\n window should open.\n\n\nAs each step proceeds, new items will appear under the \nReports\n and \nData\n tabs on the left.\n\n\n\n\n\n\n\n\n\n\nInputs and Outputs\n\n\nThe connections between the names of assembly stages and outputs is not always clear. This flowchart shows how each stage of the HGAP process corresponds to protocol window names and outputs:\n\n\n\n\n\n\nResults\n\n\nIf the job is still running, click on the centre tab \nMonitor Jobs\n. Otherwise, click on the top right tab, \nView Data\n.\n\n\n\n\nDouble click on the job name to open its reports.\n\n\nClick on different \nReports\n in the left hand panel.\n\n\n\n\nThings to look at:\n\n\nGeneral: Filtering (polymerase reads)\n\n\n\n\nnumber of reads post-filter\n\n\nread length (=average)\n\n\n\n\n\n\nGeneral: Subread Filtering (subreads)\n\n\n\n\nnumber of reads post-filter\n\n\nread length (average)\n\n\n\n\n\n\nAssembly: Pre-Assembly (pre-assembled reads)\n\n\n\n\nlength cutoff (the computed minimum seed read length)\n\n\nread length (average)\n\n\n\n\n\n\nAssembly: Corrections\n\n\nConsensus calling results:\n\n\n\n\nConsensus concordance should be \n 99%.\n\n\n\n\nGraph: corrections across reference:\n\n\n\n\nWith the first run of polishing, we expect a lot of corrections but they should be randomly distributed.\n\n\n\n\n\n\nNote: only unitigs 0 and 1 shown.\n\n\nAssembly: Top Corrections\n\n\nThis is a list of all the corrections made.\n\n\n\n\nNote: only first 15 shown.\n\n\n\n\n\nResequencing: Coverage\n\n\nCoverage across reference:\n\n\n\n\ndiscard contigs \n20X coverage\n\n\nothers should have fairly consistent coverage.\n\n\nspikes could be collapsed repeats.\n\n\nvalleys could be mis-assembly - e.g. draft assembly was incorrect and so remapped reads didn\nt support this part of the assembly.\n\n\n\n\n\n\nNote: only unitigs 0 and 1 shown.\n\n\nGraph: Depth of Coverage:\n\n\nThe is the \nnumber\n of reference regions vs. coverage. \n\n\n\n\nAssembly: Polished Assembly\n\n\n\n\nNumber of contigs\n\n\nMax contig length\n\n\nGraph: confidence vs depth. Multi-copy plasmids may have higher coverage.\n\n\n\n\n\n\n\n\n\nOutput\n\n\nThe polished assembly as a FASTA file.\n\n\n\n\n\n\ndownload to local computer; or\n\n\nopen file in (GVL) Galaxy; or\n\n\nopen file in GVL command line and perform further analysis.\n\n\n\n\n\n\n\nNext\n\n\nFurther options:\n\n\n\n\n\n\nCircularise the contigs; e.g. with Circlator.\n\n\n\n\n\n\nPolish the assembly using Illumina data; e.g. with Pilon.\n\n\n\n\n\n\nAnnotate the polished assembly; e.g. with Prokka.\n\n\n\n\n\n\nLinks to more information\n\n\nPacBio \nE. coli\n data set\n\n\nHGAP overview\n\n\nA full ist of reports and terminology\n\n\nVideo overview of HGAP on SMRT portal\n\n\nMore about the SMRT bell template", 
            "title": "PacBio assembly with SMRT portal"
        }, 
        {
            "location": "/modules/pacbio/#assembly-with-pacbio-data-and-smrt-portal", 
            "text": "Keywords: de novo assembly, PacBio, PacificBiosciences, HGAP, SMRT Portal, Microbial Genomics Virtual Laboratory  This tutorial will show you how to assemble a bacterial genome  de novo , using the PacBio SMRT Portal on the mGVL. We will use an analysis pipeline called HGAP, the Hierarchical Genome Assembly Process.", 
            "title": "Assembly with PacBio data and SMRT Portal"
        }, 
        {
            "location": "/modules/pacbio/#start", 
            "text": "Open your mGVL dashboard.  You should see SMRT Portal as one of the instance services on your GVL dashboard.  Open up the SMRT portal web link (to the right) and register/log on.", 
            "title": "Start"
        }, 
        {
            "location": "/modules/pacbio/#input", 
            "text": "We will use a dataset from a  Streptococcus pyogenes  bacteria.  If this has already been loaded onto SMRT portal (e.g. for use during a workshop), proceed to the next step ( Assembly ).  Otherwise:   Load the PacBio data (your own, or the training dataset) onto your GVL.  In the SMRT Portal, go to  Design Job , the top left tab.  Go to  Import and Manage .  Click  Import SMRT cells .   Work out where you put the data on your GVL, and make sure the file path is showing.   If not, click  Add  and enter the file path to the data.  A SMRT cell is the collection of data from a particular cell in the machine. It includes .bax.h5 files.     Click on the file path and then  Scan  to check for new data.", 
            "title": "Input"
        }, 
        {
            "location": "/modules/pacbio/#assembly", 
            "text": "", 
            "title": "Assembly"
        }, 
        {
            "location": "/modules/pacbio/#hgap-process-overview", 
            "text": "We will use the Hierarchical Genome Assembly Process (HGAP). This flowchart shows the steps in the process:", 
            "title": "HGAP process overview"
        }, 
        {
            "location": "/modules/pacbio/#set-up-job", 
            "text": "In the SMRT Portal, go to the top left tab,  Design Job .  Go to  Create New .  An  Analysis  window should appear. Tick all the boxes, then  Next .  Under  Job Name  enter a name.  To the right, under  Groups  choose  all .  Under  Protocols  choose  RS_HGAP_Assembly.3 .  There is an ellipsis underneath  Protocols  - click on the ellipsis.    This brings up the settings. Click on  Assembly .    For  Compute Minimum Seed Read Length : ensure box is ticked    For  Number of Seed Read Chunks : enter  12   Change the  Genome Size  to an approximately correct size for the species. For  S. pyogenes , enter 1800000.  For  Target Coverage : enter  10  For  Overlapper Error Rate : enter  0.04  Leave all other settings as they are.  Click  Apply   Your protocol window should look like this:     Click  Ok .      In the  SMRT Cells Available  window, select the file to be used. Click on the arrow to transfer these files to the SMRT Cells in Job window.   You can drag the column widths of the  Url  column so that you can see the URLs of the file paths better.     Click  Save  (bottom right hand side).  Next to  Save , click  Start .  The  Monitor Jobs  window should open.  As each step proceeds, new items will appear under the  Reports  and  Data  tabs on the left.", 
            "title": "Set up job"
        }, 
        {
            "location": "/modules/pacbio/#inputs-and-outputs", 
            "text": "The connections between the names of assembly stages and outputs is not always clear. This flowchart shows how each stage of the HGAP process corresponds to protocol window names and outputs:", 
            "title": "Inputs and Outputs"
        }, 
        {
            "location": "/modules/pacbio/#results", 
            "text": "If the job is still running, click on the centre tab  Monitor Jobs . Otherwise, click on the top right tab,  View Data .   Double click on the job name to open its reports.  Click on different  Reports  in the left hand panel.   Things to look at:  General: Filtering (polymerase reads)   number of reads post-filter  read length (=average)    General: Subread Filtering (subreads)   number of reads post-filter  read length (average)    Assembly: Pre-Assembly (pre-assembled reads)   length cutoff (the computed minimum seed read length)  read length (average)    Assembly: Corrections  Consensus calling results:   Consensus concordance should be   99%.   Graph: corrections across reference:   With the first run of polishing, we expect a lot of corrections but they should be randomly distributed.    Note: only unitigs 0 and 1 shown.  Assembly: Top Corrections  This is a list of all the corrections made.   Note: only first 15 shown.   Resequencing: Coverage  Coverage across reference:   discard contigs  20X coverage  others should have fairly consistent coverage.  spikes could be collapsed repeats.  valleys could be mis-assembly - e.g. draft assembly was incorrect and so remapped reads didn t support this part of the assembly.    Note: only unitigs 0 and 1 shown.  Graph: Depth of Coverage:  The is the  number  of reference regions vs. coverage.    Assembly: Polished Assembly   Number of contigs  Max contig length  Graph: confidence vs depth. Multi-copy plasmids may have higher coverage.", 
            "title": "Results"
        }, 
        {
            "location": "/modules/pacbio/#output", 
            "text": "The polished assembly as a FASTA file.    download to local computer; or  open file in (GVL) Galaxy; or  open file in GVL command line and perform further analysis.", 
            "title": "Output"
        }, 
        {
            "location": "/modules/pacbio/#next", 
            "text": "Further options:    Circularise the contigs; e.g. with Circlator.    Polish the assembly using Illumina data; e.g. with Pilon.    Annotate the polished assembly; e.g. with Prokka.", 
            "title": "Next"
        }, 
        {
            "location": "/modules/pacbio/#links-to-more-information", 
            "text": "PacBio  E. coli  data set  HGAP overview  A full ist of reports and terminology  Video overview of HGAP on SMRT portal  More about the SMRT bell template", 
            "title": "Links to more information"
        }, 
        {
            "location": "/modules/cmdline_assembly/", 
            "text": "Pacbio reads: assembly with command line tools\n\n\nKeywords: de novo assembly, PacBio, PacificBiosciences, Illumina, command line, Canu, Circlator, BWA, Spades, Pilon, Microbial Genomics Virtual Laboratory\n\n\nThis tutorial demonstrates how to use long Pacbio sequence reads to assemble a bacterial genome, including correcting the assembly with short Illumina reads.\n\n\nNote: this tutorial uses canu v1.5. \n\n\nResources\n\n\nTools (and versions) used in this tutorial include:\n\n\n\n\ncanu 1.5 \n\n\ninfoseq and sizeseq (part of EMBOSS) 6.6.0.0\n\n\ncirclator 1.5.1 [recently updated]\n\n\nbwa 0.7.15\n\n\nsamtools 1.3.1\n\n\nspades 3.10.1\n\n\nmakeblastdb and blastn (part of blast) 2.4.0+\n\n\npilon 1.20\n\n\n\n\n\n\n\nLearning objectives\n\n\nAt the end of this tutorial, be able to:\n\n\n\n\nAssemble and circularise a bacterial genome from PacBio sequence data.\n\n\nRecover small plasmids missed by long read sequencing, using Illumina data\n\n\nExplore the effect of polishing assembled sequences with a different data set.\n\n\n\n\nOverview\n\n\nSimplified version of workflow:\n\n\n\n\nGet data\n\n\nThe files we need are:\n\n\n\n\npacbio.fastq.gz\n : the PacBio reads\n\n\nillumina_R1.fastq.gz\n: the Illumina forward reads\n\n\nillumina_R2.fastq.gz\n: the Illumina reverse reads\n\n\n\n\nIf you already have the files, skip forward to next section, \nAssemble\n.\n\n\nOtherwise, this section has information about how to find and move the files:\n\n\nPacBio files\n\n\n\n\nOpen the command line. \n\n\nNavigate to or create the directory in which you want to work.\n\n\nIf the files are already on your server, you can symlink by using\n\n\n\n\nln -s real_file_path [e.g. data/sample_name/pacbio1.fastq.gz] chosen_symlink_name [e.g. pacbio1.fastq.gz]\n\n\n\n\n\n\n\n\n\nAlternatively, obtain the input files from elsewhere, e.g. from the BPA portal. (You will need a password.)\n\n\n\n\n\n\nPacbio files are often stored in the format:\n\n\n\n\nSample_name/Cell_name/Analysis_Results/long_file_name_1.fastq.gz\n\n\n\n\n\n\n\n\nWe will use the \nlongfilename.subreads.fastq.gz\n files.\n\n\n\n\n\n\nThe reads are usually split into three separate files because they are so large.\n\n\n\n\n\n\nRight click on the first \nsubreads.fastq.gz\n file and \ncopy link address\n.\n\n\n\n\n\n\nIn the command line, type:\n\n\n\n\n\n\nwget --user username --password password [paste link URL for file]\n\n\n\n\n\n\n\nRepeat for the other two \nsubreads.fastq.gz\n files.\n\n\nJoin the files:\n\n\n\n\ncat pacbio*.fastq.gz \n pacbio.fastq.gz\n\n\n\n\n\n\n\nIf the files are not gzipped, type:\n\n\n\n\ncat pacbio*.fastq | gzip \n pacbio.fastq.gz\n\n\n\n\n\nIllumina files\n\n\n\n\nWe will also use 2 x Illumina (Miseq) fastq.gz files.\n\n\nThese are the \nR1.fastq.gz\n and \nR2.fastq.gz\n files.\n\n\nSymlink or \nwget\n these files as described above for PacBio files.\n\n\nShorten the name of each of these files:\n\n\n\n\nmv longfilename_R1.fastq.gz illumina_R1.fastq.gz\nmv longfilename_R2.fastq.gz illumina_R2.fastq.gz\n\n\n\n\n\n\n\n\nSample information\n\n\nThe sample used in this tutorial is a gram-positive bacteria called \nStaphylococcus aureus\n (sample number 25747). This particular sample is from a strain that is resistant to the antibiotic methicillin (a type of penicillin). It is also called MRSA: methicillin-resistant \nStaphylococcus aureus\n. It was isolated from (human) blood and caused bacteraemia, an infection of the bloodstream.\n\n\nAssemble\n\n\n\n\nWe will use the assembly software called \nCanu\n.\n\n\nRun Canu with these commands:\n\n\n\n\ncanu -p canu -d canu_outdir genomeSize=2.8m -pacbio-raw pacbio.fastq.gz\n\n\n\n\n\n\n\nthe first \ncanu\n tells the program to run\n\n\n-p canu\n names prefix for output files (\ncanu\n)\n\n\n-d canu_outdir\n names output directory (\ncanu_outdir\n)\n\n\n\n\ngenomeSize\n only has to be approximate.\n\n\n\n\ne.g. \nStaphylococcus aureus\n, 2.8m\n\n\ne.g. \nStreptococcus pyogenes\n, 1.8m\n\n\n\n\n\n\n\n\nCanu will correct, trim and assemble the reads.\n\n\n\n\nVarious output will be displayed on the screen.\n\n\n\n\nCheck the output\n\n\nMove into \ncanu_outdir\n and \nls\n to see the output files.\n\n\n\n\nThe \ncanu.contigs.fasta\n are the assembled sequences.\n\n\nThe \ncanu.unassembled.fasta\n are the reads that could not be assembled.\n\n\nThe \ncanu.correctedReads.fasta.gz\n are the corrected Pacbio reads that were used in the assembly.\n\n\nThe \ncanu.file.gfa\n is the graph of the assembly.\n\n\nDisplay summary information about the contigs: (\ninfoseq\n is a tool from \nEMBOSS\n)\n\n\n\n\ninfoseq canu.contigs.fasta\n\n\n\n\n\n\n\nThis will show the contigs found by Canu. e.g.,\n\n\n\n\n    - tig00000001   2851805\n\n\n\n\n\nThis looks like a chromosome of approximately 2.8 million bases.\n\n\nThis matches what we would expect for this sample. For other data, Canu may not be able to join all the reads into one contig, so there may be several contigs in the output. Also, the sample may contain some plasmids and these may be found full or partially by Canu as additional contigs.  \n\n\nChange Canu parameters if required\n\n\nIf the assembly is poor with many contigs, re-run Canu with extra sensitivity parameters; e.g.\n\n\ncanu -p prefix -d outdir corMhapSensitivity=high corMinCoverage=0 genomeSize=2.8m -pacbio-raw pacbio.fastq.gz\n\n\n\n\n\nQuestions\n\n\n\n\nQuestion\n\n\nHow do long- and short-read assembly methods differ?\n\n\nAnswer\nshort reads: De Bruijn graphs; long reads: a move back towards simpler overlap-layout-consensus methods.\n\n\n\n\nQuestion\n\n\nWhere can we find out the what the approximate genome size should be for the species being assembled?\n\n\nAnswer\nNCBI Genomes - enter species name - click on Genome Assembly and Annotation report - sort table by clicking on the column header Size (Mb) - look at range of sizes in this column.\n\n\n\n\nQuestion\n\n\nIn the assembly output, what are the unassembled reads? Why are they there?\n\n\nAnswer\n\n\n\n\nQuestion\n\n\nWhat are the corrected reads? How did canu correct the reads?\n\n\nAnswer\n\n\n\n\nQuestion\n\n\nWhere could you view the output .gfa and what would it show?\n\n\nAnswer\n\n\nTrim and circularise\n\n\nRun Circlator\n\n\nCirclator identifies and trims overhangs (on chromosomes and plasmids) and orients the start position at an appropriate gene (e.g. dnaA). It takes in the assembled contigs from Canu, as well as the corrected reads prepared by Canu.\n\n\nOverhangs are shown in blue:\n\n\n\n\nAdapted from Figure 1. Hunt et al. Genome Biology 2015\n\n\nMove back into your main analysis folder.\n\n\nRun Circlator:\n\n\ncirclator all --threads 8 --verbose canu_outdir/canu.contigs.fasta canu_outdir/canu.correctedReads.fasta.gz circlator_outdir\n\n\n\n\n\n\n\n--threads\n is the number of cores: change this to an appropriate number\n\n\n--verbose\n prints progress information to the screen\n\n\ncanu_outdir/canu.contigs.fasta\n is the file path to the input Canu assembly\n\n\ncanu_outdir/canu.correctedReads.fasta.gz\n is the file path to the corrected Pacbio reads - note, fastA not fastQ\n\n\ncirclator_outdir\n is the name of the output directory.\n\n\n\n\nSome output will print to screen. When finished, it should say \nCircularized x of x contig(s)\n.\n\n\nCheck the output\n\n\nMove into the \ncirclator_outdir\n directory and \nls\n to list files.\n\n\nWere the contigs circularised?\n :\n\n\nless 04.merge.circularise.log\n\n\n\n\n\n\n\nYes, the contig was circularised (last column).\n\n\nType \nq\n to exit.\n\n\n\n\nWhere were the contigs oriented (which gene)?\n :\n\n\nless 06.fixstart.log\n\n\n\n\n\n\n\nLook in the \ngene_name\n column.\n\n\nThe contig has been oriented at tr|A0A090N2A8|A0A090N2A8_STAAU, which is another name for dnaA. \n This is typically used as the start of bacterial chromosome sequences.\n\n\n\n\nWhat are the trimmed contig sizes?\n :\n\n\ninfoseq 06.fixstart.fasta\n\n\n\n\n\n\n\ntig00000001 2823331 (28564 bases trimmed)\n\n\n\n\nThis trimmed part is the overlap.\n\n\nRe-name the contigs file\n:\n\n\n\n\nThe trimmed contigs are in the file called \n06.fixstart.fasta\n.\n\n\nRe-name it \ncontig1.fasta\n:\n\n\n\n\nmv 06.fixstart.fasta contig1.fasta\n\n\n\n\n\nOpen this file in a text editor (e.g. nano: \nnano contig1.fasta\n) and change the header to \nchromosome\n.\n\n\nMove the file back into the main folder (\nmv contig1.fasta ../\n).\n\n\nOptions\n\n\nIf all the contigs have not circularised with Circlator, an option is to change the \n--b2r_length_cutoff\n setting to approximately 2X the average read depth.\n\n\nQuestions\n\n\n\n\nQuestion\n\n\nWere all the contigs circularised? Why/why not?\n\n\nAnswer\n\n\n\n\nQuestion\n\n\nCirclator can set the start of the sequence at a particular gene. Which gene does it use? Is this appropriate for all contigs?\n\n\nAnswer\nUses dnaA for the chromosomal contig. For other contigs, uses a centrally-located gene. However, ideally, plasmids would be oriented on a gene such as repA. It is possible to provide a file to Circlator to do this.\n\n\nFind smaller plasmids\n\n\nPacbio reads are long, and may have been longer than small plasmids. We will look for any small plasmids using the Illumina reads.\n\n\nThis section involves several steps:\n\n\n\n\nUse the Canu+Circlator output of a trimmed assembly contig.\n\n\nMap all the Illumina reads against this Pacbio-assembled contig.\n\n\nExtract any reads that \ndidn\nt\n map and assemble them together: this could be a plasmid, or part of a plasmid.\n\n\nLook for overhang: if found, trim.\n\n\n\n\nAlign Illumina reads to the PacBio contig\n\n\n\n\nIndex the contigs file:\n\n\n\n\nbwa index contig1.fasta\n\n\n\n\n\n\n\nAlign Illumina reads using using bwa mem:\n\n\n\n\nbwa mem -t 8 contig1.fasta illumina_R1.fastq.gz illumina_R2.fastq.gz | samtools sort \n aln.bam\n\n\n\n\n\n\n\nbwa mem\n is the alignment tool\n\n\n-t 8\n is the number of cores: choose an appropriate number\n\n\ncontig1.fasta\n is the input assembly file\n\n\nillumina_R1.fastq.gz illumina_R2.fastq.gz\n are the Illumina reads\n\n\n| samtools sort\n pipes the output to samtools to sort\n\n\n aln.bam\n sends the alignment to the file \naln.bam\n\n\n\n\nExtract unmapped Illumina reads\n\n\n\n\nIndex the alignment file:\n\n\n\n\nsamtools index aln.bam\n\n\n\n\n\n\n\nExtract the fastq files from the bam alignment - those reads that were unmapped to the Pacbio alignment - and save them in various \nunmapped\n files:\n\n\n\n\nsamtools fastq -f 4 -1 unmapped.R1.fastq -2 unmapped.R2.fastq -s unmapped.RS.fastq aln.bam\n\n\n\n\n\n\n\nfastq\n is a command that coverts a \n.bam\n file into fastq format\n\n\n-f 4\n : only output unmapped reads\n\n\n-1\n : put R1 reads into a file called \nunmapped.R1.fastq\n\n\n-2\n : put R2 reads into a file called \nunmapped.R2.fastq\n\n\n-s\n : put singleton reads into a file called \nunmapped.RS.fastq\n\n\naln.bam\n : input alignment file\n\n\n\n\nWe now have three files of the unampped reads: \n unmapped.R1.fastq\n, \n unmapped.R2.fastq\n, \n unmapped.RS.fastq\n.\n\n\nAssemble the unmapped reads\n\n\n\n\nAssemble with Spades:\n\n\n\n\nspades.py -1 unmapped.R1.fastq -2 unmapped.R2.fastq -s unmapped.RS.fastq --careful --cov-cutoff auto -o spades_assembly\n\n\n\n\n\n\n\n-1\n is input file forward\n\n\n-2\n is input file reverse\n\n\n-s\n is unpaired\n\n\n--careful\n minimizes mismatches and short indels\n\n\n--cov-cutoff auto\n computes the coverage threshold (rather than the default setting, \noff\n)\n\n\n-o\n is the output directory\n\n\n\n\nMove into the output directory (\nspades_assembly\n) and look at the contigs:\n\n\ninfoseq contigs.fasta\n\n\n\n\n\n\n\n78 contigs were assembled, with the max length of 2250 (the first contig).  \n\n\nAll other nodes are \n 650kb so we will disregard as they are unlikely to be plasmids.\n\n\nType \nq\n to exit.\n\n\nWe will extract the first sequence (NODE_1):\n\n\n\n\nsamtools faidx contigs.fasta\n\n\n\n\n\nsamtools faidx contigs.fasta NODE_1_length_2550_cov_496.613 \n contig2.fasta\n\n\n\n\n\n\n\nThis is now saved as \ncontig2.fasta\n\n\nOpen in nano and change header to \nplasmid\n.\n\n\n\n\nTrim the plasmid\n\n\nTo trim any overhang on this plasmid, we will blast the start of contig2 against itself.\n\n\n\n\nTake the start of the contig:\n\n\n\n\nhead -n 10 contig2.fasta \n contig2.fa.head\n\n\n\n\n\n\n\nWe want to see if it matches the end (overhang).\n\n\nFormat the assembly file for blast:\n\n\n\n\nmakeblastdb -in contig2.fasta -dbtype nucl\n\n\n\n\n\n\n\nBlast the start of the assembly (.head file) against all of the assembly:\n\n\n\n\nblastn -query contig2.fa.head -db contig2.fasta -evalue 1e-3 -dust no -out contig2.bls\n\n\n\n\n\n\n\nLook at \ncontig2.bls\n to see hits:\n\n\n\n\nless contig2.bls\n\n\n\n\n\n\n\nThe first hit is at start, as expected.\n\n\nThe second hit is at 2474 all the way to the end - 2550.\n\n\nThis is the overhang.\n\n\nTrim to position 2473.\n\n\nIndex the plasmid.fa file:\n\n\n\n\nsamtools faidx contig2.fasta\n\n\n\n\n\n\n\nTrim:\n\n\n\n\nsamtools faidx contig2.fasta plasmid:1-2473 \n plasmid.fa.trimmed\n\n\n\n\n\n\n\n\n\nplasmid\n is the name of the contig, and we want the sequence from 1-2473.\n\n\n\n\n\n\nOpen this file in nano (\nnano plasmid.fa.trimmed\n) and change the header to \nplasmid\n, save.\n\n\n\n\nWe now have a trimmed plasmid.\n\n\nMove file back into main folder:\n\n\n\n\ncp plasmid.fa.trimmed ../\n\n\n\n\n\n\n\nMove into the main folder.\n\n\n\n\nPlasmid contig orientation\n\n\nThe bacterial chromosome was oriented at the gene dnaA. Plasmids are often oriented at the replication gene, but this is highly variable and there is no established convention. Here we will orient the plasmid at a gene found by Prodigal, in Circlator:\n\n\ncirclator fixstart plasmid.fa.trimmed plasmid_fixstart\n\n\n\n\n\n\n\nfixstart\n is an option in Circlator just to orient a sequence.\n\n\nplasmid.fa.trimmed\n is our small plasmid.\n\n\nplasmid_fixstart\n is the prefix for the output files.\n\n\n\n\nView the output:\n\n\nless plasmid_fixstart.log\n\n\n\n\n\n\n\nThe plasmid has been oriented at a gene predicted by Prodigal, and the break-point is at position 1200.\n\n\nChange the file name:\n\n\n\n\ncp plasmid_fixstart.fasta contig2.fasta\n\n\n\n\n\n\n\n\nCollect contigs\n\n\ncat contig1.fasta contig2.fasta \n genome.fasta\n\n\n\n\n\n\n\nSee the contigs and sizes:\n\n\n\n\ninfoseq genome.fasta\n\n\n\n\n\n\n\nchromosome: 2823331\n\n\nplasmid: 2473\n\n\n\n\nQuestions\n\n\n\n\nQuestion\n\n\nWhy is this section so complicated?\n\n\nAnswer\nFinding small plasmids is difficult for many reasons! This paper has a nice summary: On the (im)possibility to reconstruct plasmids from whole genome short-read sequencing data. doi: https://doi.org/10.1101/086744\n\n\n\n\nQuestion\n\n\nWhy can PacBio sequencing miss small plasmids?\n\n\nAnswer\nLibrary prep size selection\n\n\n\n\nQuestion\n\n\nWe extract unmapped Illumina reads and assemble these to find small plasmids. What could they be missing?\n\n\nAnswer\nRepeats that have mapped to the PacBio assembly.\n\n\n\n\nQuestion\n\n\nHow do you find a plasmid in a Bandage graph?\n\n\nAnswer\nIt is probably circular, matches the size of a known plasmid, and has a rep gene.\n\n\n\n\nQuestion\n\n\nAre there easier ways to find plasmids?\n\n\nAnswer\nPossibly. One option is the program called Unicycler which may automate many of these steps. https://github.com/rrwick/Unicycler\n\n\nCorrect\n\n\nWe will correct the Pacbio assembly with Illumina reads.\n\n\n\n\n\nMake an alignment file\n\n\n\n\nAlign the Illumina reads (R1 and R2) to the draft PacBio assembly, e.g. \ngenome.fasta\n:\n\n\n\n\nbwa index genome.fasta\nbwa mem -t 32 genome.fasta illumina_R1.fastq.gz illumina_R2.fastq.gz | samtools sort \n aln.bam\n\n\n\n\n\n\n\n\n\n-t\n is the number of cores: set this to an appropriate number. (To find out how many you have, \ngrep -c processor /proc/cpuinfo\n).\n\n\n\n\n\n\nIndex the files:\n\n\n\n\n\n\nsamtools index aln.bam\nsamtools faidx genome.fasta\n\n\n\n\n\n\n\nNow we have an alignment file to use in Pilon: \naln.bam\n\n\n\n\n\n\n\nRun Pilon\n\n\n\n\nRun:\n\n\n\n\npilon --genome genome.fasta --frags aln.bam --output pilon1 --fix all --mindepth 0.5 --changes --verbose --threads 32\n\n\n\n\n\n\n\n--genome\n is the name of the input assembly to be corrected\n\n\n--frags\n is the alignment of the reads against the assembly\n\n\n--output\n is the name of the output prefix\n\n\n--fix\n is an option for types of corrections\n\n\n--mindepth\n gives a minimum read depth to use\n\n\n--changes\n produces an output file of the changes made\n\n\n--verbose\n prints information to the screen during the run\n\n\n--threads\n : set this to an appropriate number\n\n\n\n\nLook at the changes file:\n\n\nless pilon1.changes\n\n\n\n\n\nExample:\n\n\n\n\nLook at the details of the fasta file:\n\n\ninfoseq pilon1.fasta\n\n\n\n\n\n\n\nchromosome - 2823340 (net +9 bases)\n\n\nplasmid - 2473 (no change)\n\n\n\n\nOption:\n\n\nIf there are many changes, run Pilon again, using the \npilon1.fasta\n file as the input assembly, and the Illumina reads to correct.\n\n\nGenome output\n\n\n\n\nChange the file name:\n\n\n\n\ncp pilon1.fasta assembly.fasta\n\n\n\n\n\n\n\nWe now have the corrected genome assembly of \nStaphylococcus aureus\n in .fasta format, containing a chromosome and a small plasmid.  \n\n\n\n\nQuestions\n\n\nQ:\n\n\n\n\nQuestion\n\n\nWhy don\nt we correct earlier in the assembly process?\n\n\nAnswer\nWe need to circularise the contigs and trim overhangs first.\n\n\n\n\nQuestion\n\n\nWhy can we use some reads (Illumina) to correct other reads (PacBio) ?\n\n\nAnswer\nIllumina reads have higher accuracy.\n\n\n\n\nQuestion\n\n\nCould we just use PacBio reads to assemble the genome?\n\n\nAnswer\nYes, if accuracy adequate.\n\n\nAdvanced analysis\n\n\nThis example shows a more complex analysis where many more steps are involved in the finding the small plasmid. The sample used is \nStaphylococcus aureus\n (sample number 25745).\n\n\nAssemble\n\n\ncanu -p canu -d canu_outdir genomeSize=2.8m -pacbio-raw pacbio.fastq.gz\n\n\n\n\n\n\n\nOutput: 2 contigs, likely to be the chromosome (2748030) and a large plasmid (49397).\n\n\n\n\nTrim and circularise\n\n\ncirclator all --threads 16 --verbose canu_outdir/canu.contigs.fasta canu_outdir/canu.correctedReads.fasta.gz circlator_outdir\n\n\n\n\n\n\n\nLook at the information about circularisation, orientation, and trimmed sizes.\n\n\nRe-name the file \ncontigs_1_2.fasta\n and move it into the main folder.\n\n\n\n\nFind smaller plasmids\n\n\n\n\nAlign Illumina reads to the PacBio assembly:\n\n\n\n\nbwa index contigs_1_2.fasta\nbwa mem -t 8 contigs_1_2.fasta illumina_R1.fastq.gz illumina_R2.fastq.gz | samtools sort \n aln.bam\n\n\n\n\n\nsamtools index aln.bam\nsamtools fastq -f 4 -1 unmapped.R1.fastq -2 unmapped.R2.fastq -s unmapped.RS.fastq aln.bam\nspades.py -1 unmapped.R1.fastq -2 unmapped.R2.fastq -s unmapped.RS.fastq --careful --cov-cutoff auto -o spades_assembly\n\n\n\n\n\n\n\nLook at the output:\n\n\n\n\ncd spades_assembly\ninfoseq contigs.fasta\n\n\n\n\n\n\n\nExtract the first node:\n\n\n\n\nsamtools faidx contigs.fasta\nsamtools faidx contigs.fasta NODE_1_length_2229_cov_610.298 \n contig3.fasta\n\n\n\n\n\n\n\nOpen in Nano and change header to \nplasmid\n.\n\n\nLook for overhang by blasting start of plamsid against itself:\n\n\n\n\nhead -n 10 contig3.fasta \n contig3.fa.head\nmakeblastdb -in contig3.fasta -dbtype nucl\nblastn -query contig3.fa.head -db contig3.fasta -evalue 1e-3 -dust no -out contig3.bls\nless contig3.bls\n\n\n\n\n\n\n\nThere is only one hit, to the start of the plasmid. No overhang is found.\n\n\nSearch Genbank for any matching proteins: Copy the sequence\n\n\nGo to NCBI: \nhttps://blast.ncbi.nlm.nih.gov/Blast.cgi\n; choose blastx\n\n\nPaste the sequence from \ncontig3.fasta\n\n\nChoose genetic code = 11\n\n\nBlast\n\n\nThis hits a replication (plasmid) protein. Hypothesise that   this is a small plasmid; search for the entire sequence within the assembly of all the Illumina reads (next step).\n\n\nCopy \ncontig3.fasta\n into the main folder.\n\n\nAssemble all the Illumina reads and produce an assembly graph.\n\n\n\n\nspades.py -1 illumina_R1.fastq.gz -2 illumina_R2.fastq.gz --careful --cov-cutoff auto -o spades_assembly_all_illumina\n\n\n\n\n\n\n\nNavigate to the output and find the \nassembly_graph.fastg\n.\n\n\nTransfer this file to your local computer (e.g. using the file transfer program \nCyberduck\n).\n\n\nExamine the assembly in the program \nBandage\n.\n\n\nFile: Load graph: \nassembly_graph.fastg\n\n\nIn the left hand panel, click \nDraw graph\n\n\nYour assembly graph may look like this:\n\n\n\n\n\n\n\n\n\nBlast the small plasmid sequence in this assembly\n\n\n\n\nIn the left hand panel: Blast: create/view BLAST search\n\n\nBuild blast database\n\n\nPaste in the sequence of contig3.fasta\n\n\nRun Blast search\n\n\nThere are two hits around a node (in this case, node 249).\n\n\n\n\n\n\n\n\nGo to the main Bandage window\n\n\n\n\nIn the right hand panel, enter the node number.\n\n\nClick \nFind nodes\n\n\nThis node is a circular contig in the graph, and is slightly longer (2329) than our contig3 (2229): this could be the plasmid.\n\n\nExtract this node in fasta format: In the top panel, go to Output: Save selected node sequences; save as \ncontig3b.fasta\n\n\n\n\n\n\n\n\nMove this file back to the analysis folder.\n\n\n\n\nOpen this file in nano and change the header to \ncontig3b\n, save.\n\n\nTake the start of the sequence and see if it matches the end:\n\n\n\n\nhead -n 10 contig3b.fasta \n contig3b.fa.head\nmakeblastdb -in contig3b.fasta -dbtype nucl\nblastn -query contig3b.fa.head -db contig3b.fasta -evalue 1e-3 -dust no -out contig3b.bls\nless contig3b.bls\n\n\n\n\n\n\n\nThe first hit is against the start of the chromosome, as expected.\n\n\nThe last hit starts at position 2253; we will trim the plasmid to position 2252\n\n\nIndex and trim the contig3b.fa file:\n\n\n\n\nsamtools faidx contig3b.fasta\nsamtools faidx contig3b.fasta contig3b:1-2252 \n contig3b.fa.trimmed\n\n\n\n\n\n\n\nOpen this file in nano and change the header to \ncontig3b\n, save.\n\n\nWe now have a trimmed contig3b.\n\n\nJoin all contigs:\n\n\n\n\ncat contigs_1_2.fasta contig3b.fa.trimmed \n genome.fasta\n\n\n\n\n\nCorrect\n\n\nbwa index genome.fasta\nbwa mem -t 32 genome.fasta illumina_R1.fastq.gz illumina_R2.fastq.gz | samtools sort \n aln.bam\nsamtools index aln.bam\nsamtools faidx genome.fasta\n\n\n\n\n\npilon --genome genome.fasta --frags aln.bam --output pilon1 --fix all --mindepth 0.5 --changes --verbose --threads 32\n\n\n\n\n\n\n\nLook at the \npilon1.changes\n file.\n\n\nChange the file name.\n\n\n\n\ncp pilon1.fasta assembly.fasta\n\n\n\n\n\n\n\nLook at the final assembly:\n\n\n\n\ninfoseq assembly.fasta\n\n\n\n\n\n\n\n\n\nAssembly details:\n\n\n\n\nChromosome: 2725222\n\n\nLarge plasmid: 25012\n\n\nSmall plasmid: 2252\n\n\n\n\n\n\n\n\nNext\n\n\nFurther analyses:\n\n\n\n\nAnnotate with Prokka.\n\n\nComparative genomics, e.g. with Roary.\n\n\n\n\nLinks:\n\n\n\n\nDetails of bas.h5 files\n\n\nCanu \nmanual\n and \ngitub repository\n\n\nCirclator \narticle\n and \ngithub repository\n\n\nPilon \narticle\n and \ngithub repository\n\n\nNotes on \nfinishing\n and \nevaluating\n assemblies.", 
            "title": "PacBio assembly with command line tools"
        }, 
        {
            "location": "/modules/cmdline_assembly/#pacbio-reads-assembly-with-command-line-tools", 
            "text": "Keywords: de novo assembly, PacBio, PacificBiosciences, Illumina, command line, Canu, Circlator, BWA, Spades, Pilon, Microbial Genomics Virtual Laboratory  This tutorial demonstrates how to use long Pacbio sequence reads to assemble a bacterial genome, including correcting the assembly with short Illumina reads.  Note: this tutorial uses canu v1.5.", 
            "title": "Pacbio reads: assembly with command line tools"
        }, 
        {
            "location": "/modules/cmdline_assembly/#resources", 
            "text": "Tools (and versions) used in this tutorial include:   canu 1.5   infoseq and sizeseq (part of EMBOSS) 6.6.0.0  circlator 1.5.1 [recently updated]  bwa 0.7.15  samtools 1.3.1  spades 3.10.1  makeblastdb and blastn (part of blast) 2.4.0+  pilon 1.20", 
            "title": "Resources"
        }, 
        {
            "location": "/modules/cmdline_assembly/#learning-objectives", 
            "text": "At the end of this tutorial, be able to:   Assemble and circularise a bacterial genome from PacBio sequence data.  Recover small plasmids missed by long read sequencing, using Illumina data  Explore the effect of polishing assembled sequences with a different data set.", 
            "title": "Learning objectives"
        }, 
        {
            "location": "/modules/cmdline_assembly/#overview", 
            "text": "Simplified version of workflow:", 
            "title": "Overview"
        }, 
        {
            "location": "/modules/cmdline_assembly/#get-data", 
            "text": "The files we need are:   pacbio.fastq.gz  : the PacBio reads  illumina_R1.fastq.gz : the Illumina forward reads  illumina_R2.fastq.gz : the Illumina reverse reads   If you already have the files, skip forward to next section,  Assemble .  Otherwise, this section has information about how to find and move the files:", 
            "title": "Get data"
        }, 
        {
            "location": "/modules/cmdline_assembly/#pacbio-files", 
            "text": "Open the command line.   Navigate to or create the directory in which you want to work.  If the files are already on your server, you can symlink by using   ln -s real_file_path [e.g. data/sample_name/pacbio1.fastq.gz] chosen_symlink_name [e.g. pacbio1.fastq.gz]    Alternatively, obtain the input files from elsewhere, e.g. from the BPA portal. (You will need a password.)    Pacbio files are often stored in the format:   Sample_name/Cell_name/Analysis_Results/long_file_name_1.fastq.gz     We will use the  longfilename.subreads.fastq.gz  files.    The reads are usually split into three separate files because they are so large.    Right click on the first  subreads.fastq.gz  file and  copy link address .    In the command line, type:    wget --user username --password password [paste link URL for file]   Repeat for the other two  subreads.fastq.gz  files.  Join the files:   cat pacbio*.fastq.gz   pacbio.fastq.gz   If the files are not gzipped, type:   cat pacbio*.fastq | gzip   pacbio.fastq.gz", 
            "title": "PacBio files"
        }, 
        {
            "location": "/modules/cmdline_assembly/#illumina-files", 
            "text": "We will also use 2 x Illumina (Miseq) fastq.gz files.  These are the  R1.fastq.gz  and  R2.fastq.gz  files.  Symlink or  wget  these files as described above for PacBio files.  Shorten the name of each of these files:   mv longfilename_R1.fastq.gz illumina_R1.fastq.gz\nmv longfilename_R2.fastq.gz illumina_R2.fastq.gz", 
            "title": "Illumina files"
        }, 
        {
            "location": "/modules/cmdline_assembly/#sample-information", 
            "text": "The sample used in this tutorial is a gram-positive bacteria called  Staphylococcus aureus  (sample number 25747). This particular sample is from a strain that is resistant to the antibiotic methicillin (a type of penicillin). It is also called MRSA: methicillin-resistant  Staphylococcus aureus . It was isolated from (human) blood and caused bacteraemia, an infection of the bloodstream.", 
            "title": "Sample information"
        }, 
        {
            "location": "/modules/cmdline_assembly/#assemble", 
            "text": "We will use the assembly software called  Canu .  Run Canu with these commands:   canu -p canu -d canu_outdir genomeSize=2.8m -pacbio-raw pacbio.fastq.gz   the first  canu  tells the program to run  -p canu  names prefix for output files ( canu )  -d canu_outdir  names output directory ( canu_outdir )   genomeSize  only has to be approximate.   e.g.  Staphylococcus aureus , 2.8m  e.g.  Streptococcus pyogenes , 1.8m     Canu will correct, trim and assemble the reads.   Various output will be displayed on the screen.", 
            "title": "Assemble"
        }, 
        {
            "location": "/modules/cmdline_assembly/#check-the-output", 
            "text": "Move into  canu_outdir  and  ls  to see the output files.   The  canu.contigs.fasta  are the assembled sequences.  The  canu.unassembled.fasta  are the reads that could not be assembled.  The  canu.correctedReads.fasta.gz  are the corrected Pacbio reads that were used in the assembly.  The  canu.file.gfa  is the graph of the assembly.  Display summary information about the contigs: ( infoseq  is a tool from  EMBOSS )   infoseq canu.contigs.fasta   This will show the contigs found by Canu. e.g.,       - tig00000001   2851805  This looks like a chromosome of approximately 2.8 million bases.  This matches what we would expect for this sample. For other data, Canu may not be able to join all the reads into one contig, so there may be several contigs in the output. Also, the sample may contain some plasmids and these may be found full or partially by Canu as additional contigs.", 
            "title": "Check the output"
        }, 
        {
            "location": "/modules/cmdline_assembly/#change-canu-parameters-if-required", 
            "text": "If the assembly is poor with many contigs, re-run Canu with extra sensitivity parameters; e.g.  canu -p prefix -d outdir corMhapSensitivity=high corMinCoverage=0 genomeSize=2.8m -pacbio-raw pacbio.fastq.gz", 
            "title": "Change Canu parameters if required"
        }, 
        {
            "location": "/modules/cmdline_assembly/#questions", 
            "text": "Question  How do long- and short-read assembly methods differ?  Answer short reads: De Bruijn graphs; long reads: a move back towards simpler overlap-layout-consensus methods.   Question  Where can we find out the what the approximate genome size should be for the species being assembled?  Answer NCBI Genomes - enter species name - click on Genome Assembly and Annotation report - sort table by clicking on the column header Size (Mb) - look at range of sizes in this column.   Question  In the assembly output, what are the unassembled reads? Why are they there?  Answer   Question  What are the corrected reads? How did canu correct the reads?  Answer   Question  Where could you view the output .gfa and what would it show?  Answer", 
            "title": "Questions"
        }, 
        {
            "location": "/modules/cmdline_assembly/#trim-and-circularise", 
            "text": "", 
            "title": "Trim and circularise"
        }, 
        {
            "location": "/modules/cmdline_assembly/#run-circlator", 
            "text": "Circlator identifies and trims overhangs (on chromosomes and plasmids) and orients the start position at an appropriate gene (e.g. dnaA). It takes in the assembled contigs from Canu, as well as the corrected reads prepared by Canu.  Overhangs are shown in blue:   Adapted from Figure 1. Hunt et al. Genome Biology 2015  Move back into your main analysis folder.  Run Circlator:  circlator all --threads 8 --verbose canu_outdir/canu.contigs.fasta canu_outdir/canu.correctedReads.fasta.gz circlator_outdir   --threads  is the number of cores: change this to an appropriate number  --verbose  prints progress information to the screen  canu_outdir/canu.contigs.fasta  is the file path to the input Canu assembly  canu_outdir/canu.correctedReads.fasta.gz  is the file path to the corrected Pacbio reads - note, fastA not fastQ  circlator_outdir  is the name of the output directory.   Some output will print to screen. When finished, it should say  Circularized x of x contig(s) .", 
            "title": "Run Circlator"
        }, 
        {
            "location": "/modules/cmdline_assembly/#check-the-output_1", 
            "text": "Move into the  circlator_outdir  directory and  ls  to list files.  Were the contigs circularised?  :  less 04.merge.circularise.log   Yes, the contig was circularised (last column).  Type  q  to exit.   Where were the contigs oriented (which gene)?  :  less 06.fixstart.log   Look in the  gene_name  column.  The contig has been oriented at tr|A0A090N2A8|A0A090N2A8_STAAU, which is another name for dnaA.   This is typically used as the start of bacterial chromosome sequences.   What are the trimmed contig sizes?  :  infoseq 06.fixstart.fasta   tig00000001 2823331 (28564 bases trimmed)   This trimmed part is the overlap.  Re-name the contigs file :   The trimmed contigs are in the file called  06.fixstart.fasta .  Re-name it  contig1.fasta :   mv 06.fixstart.fasta contig1.fasta  Open this file in a text editor (e.g. nano:  nano contig1.fasta ) and change the header to  chromosome .  Move the file back into the main folder ( mv contig1.fasta ../ ).", 
            "title": "Check the output"
        }, 
        {
            "location": "/modules/cmdline_assembly/#options", 
            "text": "If all the contigs have not circularised with Circlator, an option is to change the  --b2r_length_cutoff  setting to approximately 2X the average read depth.", 
            "title": "Options"
        }, 
        {
            "location": "/modules/cmdline_assembly/#questions_1", 
            "text": "Question  Were all the contigs circularised? Why/why not?  Answer   Question  Circlator can set the start of the sequence at a particular gene. Which gene does it use? Is this appropriate for all contigs?  Answer Uses dnaA for the chromosomal contig. For other contigs, uses a centrally-located gene. However, ideally, plasmids would be oriented on a gene such as repA. It is possible to provide a file to Circlator to do this.", 
            "title": "Questions"
        }, 
        {
            "location": "/modules/cmdline_assembly/#find-smaller-plasmids", 
            "text": "Pacbio reads are long, and may have been longer than small plasmids. We will look for any small plasmids using the Illumina reads.  This section involves several steps:   Use the Canu+Circlator output of a trimmed assembly contig.  Map all the Illumina reads against this Pacbio-assembled contig.  Extract any reads that  didn t  map and assemble them together: this could be a plasmid, or part of a plasmid.  Look for overhang: if found, trim.", 
            "title": "Find smaller plasmids"
        }, 
        {
            "location": "/modules/cmdline_assembly/#align-illumina-reads-to-the-pacbio-contig", 
            "text": "Index the contigs file:   bwa index contig1.fasta   Align Illumina reads using using bwa mem:   bwa mem -t 8 contig1.fasta illumina_R1.fastq.gz illumina_R2.fastq.gz | samtools sort   aln.bam   bwa mem  is the alignment tool  -t 8  is the number of cores: choose an appropriate number  contig1.fasta  is the input assembly file  illumina_R1.fastq.gz illumina_R2.fastq.gz  are the Illumina reads  | samtools sort  pipes the output to samtools to sort   aln.bam  sends the alignment to the file  aln.bam", 
            "title": "Align Illumina reads to the PacBio contig"
        }, 
        {
            "location": "/modules/cmdline_assembly/#extract-unmapped-illumina-reads", 
            "text": "Index the alignment file:   samtools index aln.bam   Extract the fastq files from the bam alignment - those reads that were unmapped to the Pacbio alignment - and save them in various  unmapped  files:   samtools fastq -f 4 -1 unmapped.R1.fastq -2 unmapped.R2.fastq -s unmapped.RS.fastq aln.bam   fastq  is a command that coverts a  .bam  file into fastq format  -f 4  : only output unmapped reads  -1  : put R1 reads into a file called  unmapped.R1.fastq  -2  : put R2 reads into a file called  unmapped.R2.fastq  -s  : put singleton reads into a file called  unmapped.RS.fastq  aln.bam  : input alignment file   We now have three files of the unampped reads:   unmapped.R1.fastq ,   unmapped.R2.fastq ,   unmapped.RS.fastq .", 
            "title": "Extract unmapped Illumina reads"
        }, 
        {
            "location": "/modules/cmdline_assembly/#assemble-the-unmapped-reads", 
            "text": "Assemble with Spades:   spades.py -1 unmapped.R1.fastq -2 unmapped.R2.fastq -s unmapped.RS.fastq --careful --cov-cutoff auto -o spades_assembly   -1  is input file forward  -2  is input file reverse  -s  is unpaired  --careful  minimizes mismatches and short indels  --cov-cutoff auto  computes the coverage threshold (rather than the default setting,  off )  -o  is the output directory   Move into the output directory ( spades_assembly ) and look at the contigs:  infoseq contigs.fasta   78 contigs were assembled, with the max length of 2250 (the first contig).    All other nodes are   650kb so we will disregard as they are unlikely to be plasmids.  Type  q  to exit.  We will extract the first sequence (NODE_1):   samtools faidx contigs.fasta  samtools faidx contigs.fasta NODE_1_length_2550_cov_496.613   contig2.fasta   This is now saved as  contig2.fasta  Open in nano and change header to  plasmid .", 
            "title": "Assemble the unmapped reads"
        }, 
        {
            "location": "/modules/cmdline_assembly/#trim-the-plasmid", 
            "text": "To trim any overhang on this plasmid, we will blast the start of contig2 against itself.   Take the start of the contig:   head -n 10 contig2.fasta   contig2.fa.head   We want to see if it matches the end (overhang).  Format the assembly file for blast:   makeblastdb -in contig2.fasta -dbtype nucl   Blast the start of the assembly (.head file) against all of the assembly:   blastn -query contig2.fa.head -db contig2.fasta -evalue 1e-3 -dust no -out contig2.bls   Look at  contig2.bls  to see hits:   less contig2.bls   The first hit is at start, as expected.  The second hit is at 2474 all the way to the end - 2550.  This is the overhang.  Trim to position 2473.  Index the plasmid.fa file:   samtools faidx contig2.fasta   Trim:   samtools faidx contig2.fasta plasmid:1-2473   plasmid.fa.trimmed    plasmid  is the name of the contig, and we want the sequence from 1-2473.    Open this file in nano ( nano plasmid.fa.trimmed ) and change the header to  plasmid , save.   We now have a trimmed plasmid.  Move file back into main folder:   cp plasmid.fa.trimmed ../   Move into the main folder.", 
            "title": "Trim the plasmid"
        }, 
        {
            "location": "/modules/cmdline_assembly/#plasmid-contig-orientation", 
            "text": "The bacterial chromosome was oriented at the gene dnaA. Plasmids are often oriented at the replication gene, but this is highly variable and there is no established convention. Here we will orient the plasmid at a gene found by Prodigal, in Circlator:  circlator fixstart plasmid.fa.trimmed plasmid_fixstart   fixstart  is an option in Circlator just to orient a sequence.  plasmid.fa.trimmed  is our small plasmid.  plasmid_fixstart  is the prefix for the output files.   View the output:  less plasmid_fixstart.log   The plasmid has been oriented at a gene predicted by Prodigal, and the break-point is at position 1200.  Change the file name:   cp plasmid_fixstart.fasta contig2.fasta", 
            "title": "Plasmid contig orientation"
        }, 
        {
            "location": "/modules/cmdline_assembly/#collect-contigs", 
            "text": "cat contig1.fasta contig2.fasta   genome.fasta   See the contigs and sizes:   infoseq genome.fasta   chromosome: 2823331  plasmid: 2473", 
            "title": "Collect contigs"
        }, 
        {
            "location": "/modules/cmdline_assembly/#questions_2", 
            "text": "Question  Why is this section so complicated?  Answer Finding small plasmids is difficult for many reasons! This paper has a nice summary: On the (im)possibility to reconstruct plasmids from whole genome short-read sequencing data. doi: https://doi.org/10.1101/086744   Question  Why can PacBio sequencing miss small plasmids?  Answer Library prep size selection   Question  We extract unmapped Illumina reads and assemble these to find small plasmids. What could they be missing?  Answer Repeats that have mapped to the PacBio assembly.   Question  How do you find a plasmid in a Bandage graph?  Answer It is probably circular, matches the size of a known plasmid, and has a rep gene.   Question  Are there easier ways to find plasmids?  Answer Possibly. One option is the program called Unicycler which may automate many of these steps. https://github.com/rrwick/Unicycler", 
            "title": "Questions"
        }, 
        {
            "location": "/modules/cmdline_assembly/#correct", 
            "text": "We will correct the Pacbio assembly with Illumina reads.", 
            "title": "Correct"
        }, 
        {
            "location": "/modules/cmdline_assembly/#make-an-alignment-file", 
            "text": "Align the Illumina reads (R1 and R2) to the draft PacBio assembly, e.g.  genome.fasta :   bwa index genome.fasta\nbwa mem -t 32 genome.fasta illumina_R1.fastq.gz illumina_R2.fastq.gz | samtools sort   aln.bam    -t  is the number of cores: set this to an appropriate number. (To find out how many you have,  grep -c processor /proc/cpuinfo ).    Index the files:    samtools index aln.bam\nsamtools faidx genome.fasta   Now we have an alignment file to use in Pilon:  aln.bam", 
            "title": "Make an alignment file"
        }, 
        {
            "location": "/modules/cmdline_assembly/#run-pilon", 
            "text": "Run:   pilon --genome genome.fasta --frags aln.bam --output pilon1 --fix all --mindepth 0.5 --changes --verbose --threads 32   --genome  is the name of the input assembly to be corrected  --frags  is the alignment of the reads against the assembly  --output  is the name of the output prefix  --fix  is an option for types of corrections  --mindepth  gives a minimum read depth to use  --changes  produces an output file of the changes made  --verbose  prints information to the screen during the run  --threads  : set this to an appropriate number   Look at the changes file:  less pilon1.changes  Example:   Look at the details of the fasta file:  infoseq pilon1.fasta   chromosome - 2823340 (net +9 bases)  plasmid - 2473 (no change)   Option:  If there are many changes, run Pilon again, using the  pilon1.fasta  file as the input assembly, and the Illumina reads to correct.", 
            "title": "Run Pilon"
        }, 
        {
            "location": "/modules/cmdline_assembly/#genome-output", 
            "text": "Change the file name:   cp pilon1.fasta assembly.fasta   We now have the corrected genome assembly of  Staphylococcus aureus  in .fasta format, containing a chromosome and a small plasmid.", 
            "title": "Genome output"
        }, 
        {
            "location": "/modules/cmdline_assembly/#questions_3", 
            "text": "Q:   Question  Why don t we correct earlier in the assembly process?  Answer We need to circularise the contigs and trim overhangs first.   Question  Why can we use some reads (Illumina) to correct other reads (PacBio) ?  Answer Illumina reads have higher accuracy.   Question  Could we just use PacBio reads to assemble the genome?  Answer Yes, if accuracy adequate.", 
            "title": "Questions"
        }, 
        {
            "location": "/modules/cmdline_assembly/#advanced-analysis", 
            "text": "This example shows a more complex analysis where many more steps are involved in the finding the small plasmid. The sample used is  Staphylococcus aureus  (sample number 25745).", 
            "title": "Advanced analysis"
        }, 
        {
            "location": "/modules/cmdline_assembly/#assemble_1", 
            "text": "canu -p canu -d canu_outdir genomeSize=2.8m -pacbio-raw pacbio.fastq.gz   Output: 2 contigs, likely to be the chromosome (2748030) and a large plasmid (49397).", 
            "title": "Assemble"
        }, 
        {
            "location": "/modules/cmdline_assembly/#trim-and-circularise_1", 
            "text": "circlator all --threads 16 --verbose canu_outdir/canu.contigs.fasta canu_outdir/canu.correctedReads.fasta.gz circlator_outdir   Look at the information about circularisation, orientation, and trimmed sizes.  Re-name the file  contigs_1_2.fasta  and move it into the main folder.", 
            "title": "Trim and circularise"
        }, 
        {
            "location": "/modules/cmdline_assembly/#find-smaller-plasmids_1", 
            "text": "Align Illumina reads to the PacBio assembly:   bwa index contigs_1_2.fasta\nbwa mem -t 8 contigs_1_2.fasta illumina_R1.fastq.gz illumina_R2.fastq.gz | samtools sort   aln.bam  samtools index aln.bam\nsamtools fastq -f 4 -1 unmapped.R1.fastq -2 unmapped.R2.fastq -s unmapped.RS.fastq aln.bam\nspades.py -1 unmapped.R1.fastq -2 unmapped.R2.fastq -s unmapped.RS.fastq --careful --cov-cutoff auto -o spades_assembly   Look at the output:   cd spades_assembly\ninfoseq contigs.fasta   Extract the first node:   samtools faidx contigs.fasta\nsamtools faidx contigs.fasta NODE_1_length_2229_cov_610.298   contig3.fasta   Open in Nano and change header to  plasmid .  Look for overhang by blasting start of plamsid against itself:   head -n 10 contig3.fasta   contig3.fa.head\nmakeblastdb -in contig3.fasta -dbtype nucl\nblastn -query contig3.fa.head -db contig3.fasta -evalue 1e-3 -dust no -out contig3.bls\nless contig3.bls   There is only one hit, to the start of the plasmid. No overhang is found.  Search Genbank for any matching proteins: Copy the sequence  Go to NCBI:  https://blast.ncbi.nlm.nih.gov/Blast.cgi ; choose blastx  Paste the sequence from  contig3.fasta  Choose genetic code = 11  Blast  This hits a replication (plasmid) protein. Hypothesise that   this is a small plasmid; search for the entire sequence within the assembly of all the Illumina reads (next step).  Copy  contig3.fasta  into the main folder.  Assemble all the Illumina reads and produce an assembly graph.   spades.py -1 illumina_R1.fastq.gz -2 illumina_R2.fastq.gz --careful --cov-cutoff auto -o spades_assembly_all_illumina   Navigate to the output and find the  assembly_graph.fastg .  Transfer this file to your local computer (e.g. using the file transfer program  Cyberduck ).  Examine the assembly in the program  Bandage .  File: Load graph:  assembly_graph.fastg  In the left hand panel, click  Draw graph  Your assembly graph may look like this:     Blast the small plasmid sequence in this assembly   In the left hand panel: Blast: create/view BLAST search  Build blast database  Paste in the sequence of contig3.fasta  Run Blast search  There are two hits around a node (in this case, node 249).     Go to the main Bandage window   In the right hand panel, enter the node number.  Click  Find nodes  This node is a circular contig in the graph, and is slightly longer (2329) than our contig3 (2229): this could be the plasmid.  Extract this node in fasta format: In the top panel, go to Output: Save selected node sequences; save as  contig3b.fasta     Move this file back to the analysis folder.   Open this file in nano and change the header to  contig3b , save.  Take the start of the sequence and see if it matches the end:   head -n 10 contig3b.fasta   contig3b.fa.head\nmakeblastdb -in contig3b.fasta -dbtype nucl\nblastn -query contig3b.fa.head -db contig3b.fasta -evalue 1e-3 -dust no -out contig3b.bls\nless contig3b.bls   The first hit is against the start of the chromosome, as expected.  The last hit starts at position 2253; we will trim the plasmid to position 2252  Index and trim the contig3b.fa file:   samtools faidx contig3b.fasta\nsamtools faidx contig3b.fasta contig3b:1-2252   contig3b.fa.trimmed   Open this file in nano and change the header to  contig3b , save.  We now have a trimmed contig3b.  Join all contigs:   cat contigs_1_2.fasta contig3b.fa.trimmed   genome.fasta", 
            "title": "Find smaller plasmids"
        }, 
        {
            "location": "/modules/cmdline_assembly/#correct_1", 
            "text": "bwa index genome.fasta\nbwa mem -t 32 genome.fasta illumina_R1.fastq.gz illumina_R2.fastq.gz | samtools sort   aln.bam\nsamtools index aln.bam\nsamtools faidx genome.fasta  pilon --genome genome.fasta --frags aln.bam --output pilon1 --fix all --mindepth 0.5 --changes --verbose --threads 32   Look at the  pilon1.changes  file.  Change the file name.   cp pilon1.fasta assembly.fasta   Look at the final assembly:   infoseq assembly.fasta    Assembly details:   Chromosome: 2725222  Large plasmid: 25012  Small plasmid: 2252", 
            "title": "Correct"
        }, 
        {
            "location": "/modules/cmdline_assembly/#next", 
            "text": "Further analyses:   Annotate with Prokka.  Comparative genomics, e.g. with Roary.   Links:   Details of bas.h5 files  Canu  manual  and  gitub repository  Circlator  article  and  github repository  Pilon  article  and  github repository  Notes on  finishing  and  evaluating  assemblies.", 
            "title": "Next"
        }, 
        {
            "location": "/modules/spades_cmdline/", 
            "text": "Spades - commandline\n\n\nThis tutorial follows on from \nPacBio assembly with commandline tools\n.\n\n\nShort-read assembly: a comparison\n\n\nSo far, we have assembled the long PacBio reads into one contig (the chromosome) and found an additional plasmid in the Illumina short reads.\n\n\nIf we only had Illumina reads, we could also assemble these using the tool Spades.\n\n\nYou can try this here, or try it later on your own data.\n\n\nGet data\n\n\nWe will use the same Illumina data as we used above:\n\n\n\n\nillumina_R1.fastq.gz\n: the Illumina forward reads\n\n\nillumina_R2.fastq.gz\n: the Illumina reverse reads\n\n\n\n\nThis is from Sample 25747.\n\n\nAssemble\n\n\nRun Spades:\n\n\nspades.py -1 illumina_R1.fastq.gz -2 illumina_R2.fastq.gz --careful --cov-cutoff auto -o spades_assembly_all_illumina\n\n\n\n\n\n\n\n-1\n is input file of forward reads\n\n\n-2\n is input file of reverse reads\n\n\n--careful\n minimizes mismatches and short indels\n\n\n--cov-cutoff auto\n computes the coverage threshold (rather than the default setting, \noff\n)\n\n\n-o\n is the output directory\n\n\n\n\nResults\n\n\nMove into the output directory and look at the contigs:\n\n\ninfoseq contigs.fasta\n\n\n\n\n\n\n\n\nNext\n\n\nRun \nProkka\n to annotate the contigs.", 
            "title": "Spades assembly - commandline"
        }, 
        {
            "location": "/modules/spades_cmdline/#spades-commandline", 
            "text": "This tutorial follows on from  PacBio assembly with commandline tools .", 
            "title": "Spades - commandline"
        }, 
        {
            "location": "/modules/spades_cmdline/#short-read-assembly-a-comparison", 
            "text": "So far, we have assembled the long PacBio reads into one contig (the chromosome) and found an additional plasmid in the Illumina short reads.  If we only had Illumina reads, we could also assemble these using the tool Spades.  You can try this here, or try it later on your own data.", 
            "title": "Short-read assembly: a comparison"
        }, 
        {
            "location": "/modules/spades_cmdline/#get-data", 
            "text": "We will use the same Illumina data as we used above:   illumina_R1.fastq.gz : the Illumina forward reads  illumina_R2.fastq.gz : the Illumina reverse reads   This is from Sample 25747.", 
            "title": "Get data"
        }, 
        {
            "location": "/modules/spades_cmdline/#assemble", 
            "text": "Run Spades:  spades.py -1 illumina_R1.fastq.gz -2 illumina_R2.fastq.gz --careful --cov-cutoff auto -o spades_assembly_all_illumina   -1  is input file of forward reads  -2  is input file of reverse reads  --careful  minimizes mismatches and short indels  --cov-cutoff auto  computes the coverage threshold (rather than the default setting,  off )  -o  is the output directory", 
            "title": "Assemble"
        }, 
        {
            "location": "/modules/spades_cmdline/#results", 
            "text": "Move into the output directory and look at the contigs:  infoseq contigs.fasta", 
            "title": "Results"
        }, 
        {
            "location": "/modules/spades_cmdline/#next", 
            "text": "Run  Prokka  to annotate the contigs.", 
            "title": "Next"
        }, 
        {
            "location": "/modules/mauve/", 
            "text": "Mauve\n\n\nMauve is a program to align multiple genomes.\n\n\nDocumentation: \nhttp://darlinglab.org/mauve/mauve.html\n\n\nWhat it does:\n\n\n\n\naligns genomes and identifies homologous blocks\n\n\nthese are likely from a common ancestor or gained via horizontal transfer\n\n\nblocks may have moved or been inverted in the genome\n\n\n\n\nMauve - align three strains\n\n\nWe will align three genomes of \nStreptococcus pneumoniae\n.\n\n\n\nOpen Mauve.\n\n\n\n\nGo to \nFile\n: \nAlign with Progressive Mauve\n\n\n\n\n\n\n\n\n\n\nAdd Sequence\n\n\n\n\n\n\nselect the sequence(s). Use .fasta or .gbk files.\n\n\n\n\n\n\nif using a reference sequence, add that first.\n\n\n\n\n\n\nAlign\n\n\n\n\n\n\n\n\n\n\n\n\nSpecify a name for the alignment.  \n\n\n\n\n\n\nSave\n\n\n\n\n\n\nA console window will open and show the progress of the run.\n\n\n\n\nWhen finished, the alignment will open:\n\n\n\n\n\n\nEach row is a genome. Each coloured block is genetically similar.\n\n\nIf you are using annotated genomes, zoom in (with the magnifying glass) to see annotations. \n\n\n\n\nFor a different view, go to \nView: Style: Solid LCB colouring\n\n\n\n\n\n\nClick on a block to align all genomes around that block.\n\n\nThe blue block is inverted in genome 3 (i.e., the reverse complement).\n\n\n\n\nMauve - align two assemblies from the same sample\n\n\nIn this example, we will align two genomes from the same sample that have been assembled with different tools.\n\n\n\n\nGenome 1: Assembled from long reads; corrected with short reads.\n\n\nGenome 2: Assembled from short reads.\n\n\n\n\nAlign the genomes:\n\n\n\n\nGo to \nFile\n: \nAlign with Progressive Mauve\n\n\nAdd sequences. Add the long-read assembly sequence first.\n\n\nAlign\n\n\nName\n\n\nSave\n\n\n\n\nView the alignment:\n\n\n\n\nGenome 2 has many contigs as it has been assembled using short reads.\n\n\n\n\nThese have been laid out in the order in which they appear in the file.\n\n\nWe need to re-arrange these contigs to align with the reference genome (Genome 1).\n\n\n\n\nRe-order the contigs in Genome 2:\n\n\n\n\nGo to \nTools\n: \nMove Contigs\n\n\nSpecify output folder\n\n\nAdd sequences (add the long-read assembly first)\n\n\nStart\n\n\n\n\nThe Mauve Console window will show the progress.\n\n\nThe re-ordered contigs will then be displayed:\n\n\n\n\nMost of the contigs in Genome 2 can be aligned to one (red) section of Genome 1.", 
            "title": "Genome alignment with Mauve"
        }, 
        {
            "location": "/modules/mauve/#mauve", 
            "text": "Mauve is a program to align multiple genomes.  Documentation:  http://darlinglab.org/mauve/mauve.html  What it does:   aligns genomes and identifies homologous blocks  these are likely from a common ancestor or gained via horizontal transfer  blocks may have moved or been inverted in the genome", 
            "title": "Mauve"
        }, 
        {
            "location": "/modules/mauve/#mauve-align-three-strains", 
            "text": "We will align three genomes of  Streptococcus pneumoniae .  Open Mauve.   Go to  File :  Align with Progressive Mauve      Add Sequence    select the sequence(s). Use .fasta or .gbk files.    if using a reference sequence, add that first.    Align       Specify a name for the alignment.      Save    A console window will open and show the progress of the run.   When finished, the alignment will open:    Each row is a genome. Each coloured block is genetically similar.  If you are using annotated genomes, zoom in (with the magnifying glass) to see annotations.    For a different view, go to  View: Style: Solid LCB colouring    Click on a block to align all genomes around that block.  The blue block is inverted in genome 3 (i.e., the reverse complement).", 
            "title": "Mauve - align three strains"
        }, 
        {
            "location": "/modules/mauve/#mauve-align-two-assemblies-from-the-same-sample", 
            "text": "In this example, we will align two genomes from the same sample that have been assembled with different tools.   Genome 1: Assembled from long reads; corrected with short reads.  Genome 2: Assembled from short reads.   Align the genomes:   Go to  File :  Align with Progressive Mauve  Add sequences. Add the long-read assembly sequence first.  Align  Name  Save   View the alignment:   Genome 2 has many contigs as it has been assembled using short reads.   These have been laid out in the order in which they appear in the file.  We need to re-arrange these contigs to align with the reference genome (Genome 1).   Re-order the contigs in Genome 2:   Go to  Tools :  Move Contigs  Specify output folder  Add sequences (add the long-read assembly first)  Start   The Mauve Console window will show the progress.  The re-ordered contigs will then be displayed:   Most of the contigs in Genome 2 can be aligned to one (red) section of Genome 1.", 
            "title": "Mauve - align two assemblies from the same sample"
        }, 
        {
            "location": "/modules/roary/", 
            "text": "Find pan-genomes using Roary (using the commandline)\n\n\nA concept in comparative microbial genomics is core and pan genomes. If we analyse DNA from several bacterial strains, we may want to know which genes they have in common and which are unique to some strains.\n\n\n\n\n\n\nThe \ncore genome\n is the group of genes shared by all strains in the clade of interest. Gene sequences are similar but not necessarily identical. \nCore genome SNPs\n are those SNPs found in the genes in the core genome; i.e. at a particular site, the nucleotide varies. We can use these SNPs to infer relationships between the strains.\n\n\n\n\n\n\nThe \naccessory genome\n is the group of genes that are not in all the strains. These genes may be in one or more strain.\n\n\n\n\n\n\nThe \npan genome\n is the sum of the core and accessory genomes. That is, a combination of \nall\n the genes that are found in the clade of interest.\n\n\n\n\n\n\nBacteria can horizontally-transfer genes to other bacteria via plasmids, and so their accessory genome can be large relative to those of eurkaryotes. Bacterial accessory genomes often house genes for drug resistance.\n\n\nThis tutorial demonstrates how to calculate the pan and core genomes of a set of input bacterial samples, using the tool \nRoary\n.\n\n\nGet data\n\n\nInput:\n\n\n\n\nannotated genome in GFF3 format, per sample (\ne.g.\n output from Prokka)\n\n\nsamples must be from same species\n\n\n\n\nOur data:\n\n\n\n\n\n\n\n\nFive strains of \nStaphylococcus aureus\n, in .gff format.\n\n\n\n\n\nRun\n\n\nRun roary\n\n\nroary -e --mafft -p 8 *.gff\n\n\n\n\n\n\n\n-e --mafft\n aligns the core genes using the tool MAFFT\n\n\n-p 8\n uses 8 threads\n\n\n\n\nWhat does Roary do\n\n\n\n\nconverts coding sequences into protein sequences\n\n\nclustered these protein sequences by several methods\n\n\nfurther refines clusters into orthologous genes\n\n\nfor each sample, determines if gene is present/absent: produces \ngene_presence_absence.csv\n\n\nuses this gene p/a information to build a tree, using FastTree: produces \naccessory_binary_genes.fa.newick\n\n\noverall, calculates number of genes that are shared, and unique: produces \nsummary_statistics.txt\n\n\naligns the core genes (if option used, as above) for downstream analyses\n\n\n\n\nOutput\n\n\nCore and pan genes\n\n\nOpen the summary file:\n\n\nless summary_statistics.txt\n\n\n\n\n\nThis shows a table of counts of shared genes (core genome) and total genes (pan genome).\n\n\n\n\nWhat are the core genes?\n\n\nquery_pan_genome -a intersection -o core_genome_results *.gff\n\n\n\n\n\nWhat are the accessory genes?\n\n\nquery_pan_genome -a complement -o accessory_genome_results *.gff\n\n\n\n\n\nWhat are the pan genes?\n\n\nquery_pan_genome -a union -o pan_genome_results *.gff\n\n\n\n\n\nView: \ne.g.\n\n\nless core_genome_results | column -t\n\n\n\n\n\nGene presence/absence\n\n\nTransfer the file \ngene_presence_absence.csv\n to your local computer and view in spreadsheet software.\n\n\n\n\nSearch for the gene that confers methicillin resistance. It is only found in some of the strains.\n\n\n\n\n\n\n\nVizualize with Phandango\n\n\nCopy these files to your local computer:\n\n\n\n\naccessory_binary_genes.fa.newick\n\n\ngene_presence_absence.csv\n\n\n\n\nGo to \nhttp://phandango.net\n\n\n\n\ndrag and drop the two files onto the landing page.\n\n\nview the tree of samples and their core and pan genomes\n\n\n\n\n\n\nLinks\n\n\n\n\nRoary: \nhttps://sanger-pathogens.github.io/Roary/\n\n\nRoary publication: \nhttp://bioinformatics.oxfordjournals.org/content/31/22/3691", 
            "title": "Pangenomes with Roary/Phandango - command line"
        }, 
        {
            "location": "/modules/roary/#find-pan-genomes-using-roary-using-the-commandline", 
            "text": "A concept in comparative microbial genomics is core and pan genomes. If we analyse DNA from several bacterial strains, we may want to know which genes they have in common and which are unique to some strains.    The  core genome  is the group of genes shared by all strains in the clade of interest. Gene sequences are similar but not necessarily identical.  Core genome SNPs  are those SNPs found in the genes in the core genome; i.e. at a particular site, the nucleotide varies. We can use these SNPs to infer relationships between the strains.    The  accessory genome  is the group of genes that are not in all the strains. These genes may be in one or more strain.    The  pan genome  is the sum of the core and accessory genomes. That is, a combination of  all  the genes that are found in the clade of interest.    Bacteria can horizontally-transfer genes to other bacteria via plasmids, and so their accessory genome can be large relative to those of eurkaryotes. Bacterial accessory genomes often house genes for drug resistance.  This tutorial demonstrates how to calculate the pan and core genomes of a set of input bacterial samples, using the tool  Roary .", 
            "title": "Find pan-genomes using Roary (using the commandline)"
        }, 
        {
            "location": "/modules/roary/#get-data", 
            "text": "Input:   annotated genome in GFF3 format, per sample ( e.g.  output from Prokka)  samples must be from same species   Our data:    Five strains of  Staphylococcus aureus , in .gff format.", 
            "title": "Get data"
        }, 
        {
            "location": "/modules/roary/#run", 
            "text": "", 
            "title": "Run"
        }, 
        {
            "location": "/modules/roary/#run-roary", 
            "text": "roary -e --mafft -p 8 *.gff   -e --mafft  aligns the core genes using the tool MAFFT  -p 8  uses 8 threads", 
            "title": "Run roary"
        }, 
        {
            "location": "/modules/roary/#what-does-roary-do", 
            "text": "converts coding sequences into protein sequences  clustered these protein sequences by several methods  further refines clusters into orthologous genes  for each sample, determines if gene is present/absent: produces  gene_presence_absence.csv  uses this gene p/a information to build a tree, using FastTree: produces  accessory_binary_genes.fa.newick  overall, calculates number of genes that are shared, and unique: produces  summary_statistics.txt  aligns the core genes (if option used, as above) for downstream analyses", 
            "title": "What does Roary do"
        }, 
        {
            "location": "/modules/roary/#output", 
            "text": "", 
            "title": "Output"
        }, 
        {
            "location": "/modules/roary/#core-and-pan-genes", 
            "text": "Open the summary file:  less summary_statistics.txt  This shows a table of counts of shared genes (core genome) and total genes (pan genome).   What are the core genes?  query_pan_genome -a intersection -o core_genome_results *.gff  What are the accessory genes?  query_pan_genome -a complement -o accessory_genome_results *.gff  What are the pan genes?  query_pan_genome -a union -o pan_genome_results *.gff  View:  e.g.  less core_genome_results | column -t", 
            "title": "Core and pan genes"
        }, 
        {
            "location": "/modules/roary/#gene-presenceabsence", 
            "text": "Transfer the file  gene_presence_absence.csv  to your local computer and view in spreadsheet software.   Search for the gene that confers methicillin resistance. It is only found in some of the strains.", 
            "title": "Gene presence/absence"
        }, 
        {
            "location": "/modules/roary/#vizualize-with-phandango", 
            "text": "Copy these files to your local computer:   accessory_binary_genes.fa.newick  gene_presence_absence.csv   Go to  http://phandango.net   drag and drop the two files onto the landing page.  view the tree of samples and their core and pan genomes", 
            "title": "Vizualize with Phandango"
        }, 
        {
            "location": "/modules/roary/#links", 
            "text": "Roary:  https://sanger-pathogens.github.io/Roary/  Roary publication:  http://bioinformatics.oxfordjournals.org/content/31/22/3691", 
            "title": "Links"
        }, 
        {
            "location": "/modules/roary-galaxy/", 
            "text": "Find pan-genomes using Roary (in Galaxy)\n\n\nA concept in comparative microbial genomics is core and pan genomes. If we analyse DNA from several bacterial strains, we may want to know which genes they have in common and which are unique to some strains.\n\n\n\n\n\n\nThe \ncore genome\n is the group of genes shared by all strains in the clade of interest. Gene sequences are similar but not necessarily identical. \nCore genome SNPs\n are those SNPs found in the genes in the core genome; i.e. at a particular site, the nucleotide varies. We can use these SNPs to infer relationships between the strains.\n\n\n\n\n\n\nThe \naccessory genome\n is the group of genes that are not in all the strains. These genes may be in one or more strain.\n\n\n\n\n\n\nThe \npan genome\n is the sum of the core and accessory genomes. That is, a combination of \nall\n the genes that are found in the clade of interest.\n\n\n\n\n\n\nBacteria can horizontally-transfer genes to other bacteria via plasmids, and so their accessory genome can be large relative to those of eurkaryotes. Bacterial accessory genomes often house genes for drug resistance.\n\n\nThis tutorial demonstrates how to calculate the pan and core genomes of a set of input bacterial samples, using the tool \nRoary\n.\n\n\nGet data\n\n\nInput:\n\n\n\n\nannotated genome in GFF3 format, per sample (\ne.g.\n output from Prokka)\n\n\nsamples must be from same species\n\n\n\n\nOur data:\n\n\n\n\nFive strains of \nStaphylococcus aureus\n, in .gff format.\n\n\nGalaxy or swift location: ask your demonstrator or load your own data. \n\n\n\n\n\n\n\nRun\n\n\nRun Roary\n\n\n\n\nIn Galaxy, go to \nTools \n NGS Analysis \n Pan Genomes \n Roary\n  \n\n\n\n\nSet the following parameters (leave everything else unchanged):\n\n\n\n\nIndividual gff files or a dataset collection\n: \nIndividual\n\n\nselect gff inputs to Roary\n: \nSelect all the .gff input files\n\n\n\n\n\n\n\n\nClick \nExecute\n\n\n\n\n\n\nWhat does Roary do\n\n\n\n\nconverts coding sequences into protein sequences\n\n\nclustered these protein sequences by several methods\n\n\nfurther refines clusters into orthologous genes\n\n\nfor each sample, determines if gene is present/absent: produces \ngene_presence_absence.csv\n\n\nuses this gene p/a information to build a tree, using FastTree: produces \naccessory_binary_genes.fa.newick\n\n\noverall, calculates number of genes that are shared, and unique: produces \nsummary_statistics.txt\n\n\naligns the core genes (if option used, as above) for downstream analyses\n\n\n\n\nOutput\n\n\nThere are three output files. \n\n\n\n\n\nSummary statistics\n\n\nClick on the eye icon. This shows a table of counts of shared genes (core genome) and total genes (pan genome).\n\n\n\n\nCore gene alignment\n\n\nClick on the disk icon under this file to download it.\n\n\nGene presence/absence\n\n\nClick on the disk icon under this file to download it. Open and view in spreadsheet software.\n\n\n\n\nColumn 3 shows the annotated gene name.\n\n\nColumn 4 shows the number of isolates that the gene was found it (in this case, ordered from 5 (all) to 1).\n\n\n\n\n\n\n\nInfer phylogeny using core gene snps\n\n\n\n\n\nRoary has produced an alignment of the core genes. We can use this alignment to infer a phylogenetic tree of the isolates.\n\n\n\n\nIn Galaxy, go to \nTools \n NGS Analysis \n NGS:Phylogenetics \n Phylogeneitc reconstruction with RaXML\n  \n\n\n\n\nSet the following parameters (leave everything else unchanged):\n\n\n\n\nSource file\n: \nRoary on data x, data x, and others Core Gene Alignment\n\n\nModel Type\n: \nNucleotide\n\n\nSubstitution Model\n: \nGTRGAMMA\n\n\n\n\n\n\n\n\nClick \nExecute\n\n\n\n\n\n\nThere are six output files.\n\n\nClick on \nResult\n. Under the file, click on the \nVisualize\n icon (a graph), then choose PhyloViz.\n\n\n\n\n\n\n\n\n\nThese isolates are all very closely related and so the structure of the tree is narrow.\n\n\nTo expand, go to the right hand box for \nPhyloviz Settings\n. Change the Phylogenetic Spacing to 2500 and the Vertical Spacing to 30.\n\n\n\n\nTo return to the main Galaxy screen, go to the top panel and click on \nAnalyze Data\n.\n\n\nClick on the disk icon under the \nResults\n file to download.\n\n\nRe-name with the file extension \n.tree\n\n\nVizualize with Phandango\n\n\nIf not done already, copy these files to your local computer:\n\n\n\n\n\n\nThe \nraxml.tree\n (or the \naccessory_binary_genes.fa.newick\n).\n\n\n\n\n\n\ngene_presence_absence.csv\n\n\n\n\n\n\nGo to \nhttp://phandango.net\n\n\n\n\ndrag and drop the two files onto the landing page.\n\n\nview the tree of samples and their core and pan genomes\n\n\neach blue coloured column is a gene: genes are present or absent in each isolate\n\n\nthe core genes are shared by all isolates", 
            "title": "Pangenomes with Roary/Phandango - Galaxy"
        }, 
        {
            "location": "/modules/roary-galaxy/#find-pan-genomes-using-roary-in-galaxy", 
            "text": "A concept in comparative microbial genomics is core and pan genomes. If we analyse DNA from several bacterial strains, we may want to know which genes they have in common and which are unique to some strains.    The  core genome  is the group of genes shared by all strains in the clade of interest. Gene sequences are similar but not necessarily identical.  Core genome SNPs  are those SNPs found in the genes in the core genome; i.e. at a particular site, the nucleotide varies. We can use these SNPs to infer relationships between the strains.    The  accessory genome  is the group of genes that are not in all the strains. These genes may be in one or more strain.    The  pan genome  is the sum of the core and accessory genomes. That is, a combination of  all  the genes that are found in the clade of interest.    Bacteria can horizontally-transfer genes to other bacteria via plasmids, and so their accessory genome can be large relative to those of eurkaryotes. Bacterial accessory genomes often house genes for drug resistance.  This tutorial demonstrates how to calculate the pan and core genomes of a set of input bacterial samples, using the tool  Roary .", 
            "title": "Find pan-genomes using Roary (in Galaxy)"
        }, 
        {
            "location": "/modules/roary-galaxy/#get-data", 
            "text": "Input:   annotated genome in GFF3 format, per sample ( e.g.  output from Prokka)  samples must be from same species   Our data:   Five strains of  Staphylococcus aureus , in .gff format.  Galaxy or swift location: ask your demonstrator or load your own data.", 
            "title": "Get data"
        }, 
        {
            "location": "/modules/roary-galaxy/#run", 
            "text": "", 
            "title": "Run"
        }, 
        {
            "location": "/modules/roary-galaxy/#run-roary", 
            "text": "In Galaxy, go to  Tools   NGS Analysis   Pan Genomes   Roary      Set the following parameters (leave everything else unchanged):   Individual gff files or a dataset collection :  Individual  select gff inputs to Roary :  Select all the .gff input files     Click  Execute", 
            "title": "Run Roary"
        }, 
        {
            "location": "/modules/roary-galaxy/#what-does-roary-do", 
            "text": "converts coding sequences into protein sequences  clustered these protein sequences by several methods  further refines clusters into orthologous genes  for each sample, determines if gene is present/absent: produces  gene_presence_absence.csv  uses this gene p/a information to build a tree, using FastTree: produces  accessory_binary_genes.fa.newick  overall, calculates number of genes that are shared, and unique: produces  summary_statistics.txt  aligns the core genes (if option used, as above) for downstream analyses", 
            "title": "What does Roary do"
        }, 
        {
            "location": "/modules/roary-galaxy/#output", 
            "text": "There are three output files.", 
            "title": "Output"
        }, 
        {
            "location": "/modules/roary-galaxy/#summary-statistics", 
            "text": "Click on the eye icon. This shows a table of counts of shared genes (core genome) and total genes (pan genome).", 
            "title": "Summary statistics"
        }, 
        {
            "location": "/modules/roary-galaxy/#core-gene-alignment", 
            "text": "Click on the disk icon under this file to download it.", 
            "title": "Core gene alignment"
        }, 
        {
            "location": "/modules/roary-galaxy/#gene-presenceabsence", 
            "text": "Click on the disk icon under this file to download it. Open and view in spreadsheet software.   Column 3 shows the annotated gene name.  Column 4 shows the number of isolates that the gene was found it (in this case, ordered from 5 (all) to 1).", 
            "title": "Gene presence/absence"
        }, 
        {
            "location": "/modules/roary-galaxy/#infer-phylogeny-using-core-gene-snps", 
            "text": "Roary has produced an alignment of the core genes. We can use this alignment to infer a phylogenetic tree of the isolates.   In Galaxy, go to  Tools   NGS Analysis   NGS:Phylogenetics   Phylogeneitc reconstruction with RaXML      Set the following parameters (leave everything else unchanged):   Source file :  Roary on data x, data x, and others Core Gene Alignment  Model Type :  Nucleotide  Substitution Model :  GTRGAMMA     Click  Execute    There are six output files.  Click on  Result . Under the file, click on the  Visualize  icon (a graph), then choose PhyloViz.     These isolates are all very closely related and so the structure of the tree is narrow.  To expand, go to the right hand box for  Phyloviz Settings . Change the Phylogenetic Spacing to 2500 and the Vertical Spacing to 30.   To return to the main Galaxy screen, go to the top panel and click on  Analyze Data .  Click on the disk icon under the  Results  file to download.  Re-name with the file extension  .tree", 
            "title": "Infer phylogeny using core gene snps"
        }, 
        {
            "location": "/modules/roary-galaxy/#vizualize-with-phandango", 
            "text": "If not done already, copy these files to your local computer:    The  raxml.tree  (or the  accessory_binary_genes.fa.newick ).    gene_presence_absence.csv    Go to  http://phandango.net   drag and drop the two files onto the landing page.  view the tree of samples and their core and pan genomes  each blue coloured column is a gene: genes are present or absent in each isolate  the core genes are shared by all isolates", 
            "title": "Vizualize with Phandango"
        }, 
        {
            "location": "/modules/cmdline_assembly_v2/", 
            "text": "Long read assembly workshop\n\n\nThis is a tutorial for a workshop on long-read (PacBio) genome assembly. \n\n\nIt demonstrates how to use long PacBio sequencing reads to assemble a bacterial genome, and includes additional steps for circularising, trimming, finding plasmids, and correcting the assembly with short-read Illumina data. \n\n\nOverview\n\n\nSimplified version of workflow:\n\n\n\n\n1. Get started\n\n\nYour workshop trainers will provide you with the address of a virtual machine. \n\n\nMac users\n\n\nOpen the Terminal. \n\n\n\n\nType in \n\n\n\n\nssh researcher@[your virtual machine address]\n\n\n\n\n\n\n\nType in the password provided. \n\n\n\n\nWindows users\n\n\nIf you are using Windows 10, you might be able to use the Ubuntu Subsystem. Otherwise, install and open Putty. \n\n\n\n\nDownload putty \nhere\n.\n\n\nOpen. A configuration window will appear. \n\n\nUnder \nHost Name (or IP address)\n enter in the address of your virtual machine. \n\n\nUnder \nPort\n type in 22\n\n\nUnder \nConnection Type\n select \nSSH\n\n\nClick \nOpen\n\n\nUnder \nLogin as:\n enter \nresearcher\n\n\nType in the password provided. \n\n\n\n\nCreate a new working directory on your remote computer.\n\n\nBecause we are starting a new analysis it is always good practice to start in a new empty directory. Therefore, we will create a new directory and change to it for the rest of the workshop.\n\n\nIn your terminal:\n\n\n\n\nCreate a new directory called \nWorkshop\n\n\n\n\nmkdir Workshop\n\n\n\n\n\n\n\nChange to that directory\n\n\n\n\ncd Workshop\n\n\n\n\n\nNOTE: Everytime you open a new terminal or Putty session, you will need to make sure you are in this directory again.\n\n\nThe current directory can be obtained with the linux command:\n\n\npwd\n\n\n\n\n\n2. Get data\n\n\nThe sample used in this tutorial is from a bacteria called \nStaphylococcus aureus\n. We have used a small section of its real genome so that the programs can run in the workshop time. \n\n\nThe files we need are:\n\n\n\n\npacbio.fq\n: the PacBio reads\n\n\nR1.fq\n: the Illumina forward reads\n\n\nR2.fq\n: the Illumina reverse reads\n\n\n\n\nIn a new tab, go to \nhttps://doi.org/10.5281/zenodo.1009308\n. \n\n\n\n\nNext to the first file, right-click (or control-click) the \nDownload\n button, and select \nCopy link address\n.\n\n\nBack in your terminal, enter \n\n\n\n\nwget [paste file link here]\n\n\n\n\n\n\n\nThe file should download. \n\n\nNote:\n paste the link to the file, not to the webpage.\n\n\nRepeat this for the other two files. \n\n\n\n\n3. Assemble\n\n\nWe will use the assembly software called \nCanu\n, version 1.6.\n\n\nRun Canu with these commands:\n\n\ncanu -p canu -d canu_outdir genomeSize=0.03m -pacbio-raw pacbio.fq\n\n\n\n\n\n\n\nthe first \ncanu\n tells the program to run\n\n\n-p canu\n names prefix for output files (\ncanu\n)\n\n\n-d canu_outdir\n names output directory (\ncanu_outdir\n)\n\n\ngenomeSize\n only has to be approximate. (In this case we are using a partial genome of expected size 30,000 base pairs). \n\n\nCanu will correct, trim and assemble the reads.\n\n\nVarious output will be displayed on the screen.\n\n\nNote\n: Canu could say \nFinished\n but may still be running. In this case, type \nsqueue\n to see if jobs are still running. \n\n\n\n\nIf you run \nsqueue\n you will see something like this:\n\n\n             JOBID PARTITION     NAME     USER ST       TIME  NODES NODELIST(REASON)\n                 6      main canu_can research PD       0:00      1 (Dependency)\n               5_1      main cormhap_ research  R       0:29      1 master\n\n\n\n\n\nYou will know if \nCanu\n has completely finished when \nsqueue\n shows no jobs listed under the header row. \n\n\n4. Check assembly output\n\n\nMove into the canu output folder: \n\n\ncd canu_outdir\n\n\n\n\n\nView the list of files: \n\n\nls\n\n\n\n\n\n\n\nThe \ncanu.contigs.fasta\n are the assembled sequences.\n\n\nThe \ncanu.unassembled.fasta\n are the reads that could not be assembled.\n\n\nThe \ncanu.correctedReads.fasta.gz\n are the corrected Pacbio reads that were used in the assembly.\n\n\nThe \ncanu.contigs.gfa\n is the graph of the assembly.\n\n\nThe \ncanu.report\n file is a summary of all of the steps Canu performed with information about the reads used, how they were handled and a whole lot of summary information about the assembly.\n\n\n\n\nDisplay summary information about the contigs: (\ninfoseq\n is a tool from \nEMBOSS\n)\n\n\ninfoseq canu.contigs.fasta\n\n\n\n\n\n\n\nThis will show the contigs found by Canu. e.g.,  tig00000001  39136\n\n\ntig00000001\n is the name given to the contig\n\n\n39136\n is the number of base pairs in that contig.\n\n\n\n\nThis matches what we were expecting for this sample (approximately 30,000 base pairs). For other data, Canu may not be able to join all the reads into one contig, so there may be several contigs in the output.\n\n\nWe should also look at the \ncanu.report\n. To do this:\n\n\nless canu.report\n\n\n\n\n\n\n\nless\n is a command to display the file on the screen.\n\n\nUse the up and down arrows to scroll up and down. \n\n\nYou will see lots of histograms of read lengths before and after processing, final contig construction, etc. \n\n\nFor a description of the outputs that Canu produces, see: \nhttp://canu.readthedocs.io/en/latest/tutorial.html#outputs\n\n\nType \nq\n to exit viewing the report. \n\n\n\n\nQuestions\n\n\n\n\nQuestion\n\n\nHow do long- and short-read assembly methods differ?\n\n\nAnswer\nShort reads are usually assembled with De Bruijn graphs. For long reads, there is a move back towards simpler overlap-layout-consensus methods.\n\n\n\n\nQuestion\n\n\nWhere can we find out the what the approximate genome size should be for the species being assembled?\n\n\nAnswer\nGo to NCBI Genomes, enter species name, click on Genome Assembly and Annotation report, sort table by clicking on the column header Size (Mb), look at range of sizes in this column.\n\n\n\n\nQuestion\n\n\nIn the assembly output, what are the unassembled reads? Why are they there?\n\n\nAnswer\nReads and low-coverage contigs that were not used in the assembly. \n\n\n\n\nQuestion\n\n\nWhat are the corrected reads? How did canu correct the reads?\n\n\nAnswer\nCanu builds overlaps between reads. The consensus is used to correct the reads. \n\n\n\n\nQuestion\n\n\nWhere could you view the output .gfa and what would it show?\n\n\nAnswer\nA useful program is \nBandage\n. If the assembly has multiple contigs, the assembly graph shows how these are connected. \n\n\n5. Trim and circularise\n\n\nBacteria have circular chromosomes. \n\n\n\n\nBecause of sequencing errors, there may be some \noverhang\n in the assembled linear sequence. \n\n\nOur assembly may have some overhang because it is 9000 bases longer than expected. \n\n\n\n\n\n\nAdapted from Figure 1. Hunt et al. Genome Biology 2015\n\n\nA tool called \nCirclator\n identifies and trims overhangs (on chromosomes and plasmids). It takes in the assembled contigs from Canu, as well as the corrected reads prepared by Canu.\n\n\nMove back into your main analysis folder: \n\n\ncd ..\n\n\n\n\n\nRun Circlator\n\n\ncirclator all --threads 4 --verbose canu_outdir/canu.contigs.fasta canu_outdir/canu.correctedReads.fasta.gz circlator_outdir\n\n\n\n\n\n\n\n\n\n(Click on the dark grey slider bar above and move it to the right, to see all the way to the end of the line.)\n\n\n\n\n\n\n--threads\n is the number of cores\n\n\n\n\n--verbose\n prints progress information to the screen\n\n\ncanu_outdir/canu.contigs.fasta\n is the file path to the input Canu assembly\n\n\ncanu_outdir/canu.correctedReads.fasta.gz\n is the file path to the corrected Pacbio reads - note, fastA not fastQ\n\n\ncirclator_outdir\n is the name of the output directory.\n\n\n\n\nSome output will print to screen. When finished, it should say \nCircularized x of x contig(s)\n.\n\n\nCheck the output\n\n\nMove into the Circlator output directory: \n\n\ncd circlator_outdir\n\n\n\n\n\nList the files: \n\n\nls\n\n\n\n\n\nCirclator has named the output files with numbers as prefixes. \n\n\nWere the contigs circularised?\n\n\nless 04.merge.circularise.log\n\n\n\n\n\n\n\nless\n is a command to display the file on the screen.\n\n\n04.merge.circularise.log\n is the name of the file. \n\n\nYes, the contig was circularised (last column).\n\n\nType \nq\n to exit.\n\n\n\n\nWhat are the trimmed contig sizes? \n\n\ninfoseq 06.fixstart.fasta\n\n\n\n\n\n\n\nThe contig \ntig00000001\n has a length of 30019.\n\n\nThis is about 9000 bases shorter than before circularisation. This was the \noverhang\n and has now been trimmed. \n\n\n\n\nCopy the circularised contigs file to the main analysis directory with a new name:\n\n\ncp 06.fixstart.fasta ../contig1.fasta\n\n\n\n\n\nMove back into the main folder: \n\n\ncd ..\n\n\n\n\n\nQuestions\n\n\n\n\nQuestion\n\n\nWere all the contigs circularised? \n\n\nAnswer\nIn this example, yes, the contig was circularised. \n\n\n\n\nQuestion\n\n\nCirclator can set the start of the sequence at a particular gene. Which gene does it use? Is this appropriate for all contigs?\n\n\nAnswer\nCirclator uses dnaA (if present) for the chromosomal contig. For other contigs, it uses a centrally-located gene. However, ideally, plasmids would be oriented on a gene such as repA. It is possible to provide a file to Circlator to do this.\n\n\n6. Find smaller plasmids\n\n\nPacbio reads are long, and may have been longer than small plasmids. We will look for any small plasmids using the Illumina reads.\n\n\nThis section involves several steps:\n\n\n\n\nUse the Canu+Circlator output of a trimmed assembly contig.\n\n\nMap all the Illumina reads against this Pacbio-assembled contig.\n\n\nExtract any reads that \ndidn\nt\n map and assemble them together: this could be a plasmid, or part of a plasmid.\n\n\nLook for overhang: if found, trim.\n\n\n\n\nAlign Illumina reads to the PacBio contig\n\n\nIndex the contigs file:\n\n\nbwa index contig1.fasta\n\n\n\n\n\nAlign Illumina reads using using bwa mem:\n\n\nbwa mem -t 4 contig1.fasta R1.fq R2.fq | samtools sort \n aln.bam\n\n\n\n\n\n\n\nbwa mem\n is the alignment tool\n\n\n-t 4\n is the number of cores\n\n\ncontig1.fasta\n is the input assembly file\n\n\nR1.fq R2.fq\n are the Illumina reads\n\n\n| samtools sort\n pipes the output to samtools to sort\n\n\n aln.bam\n sends the alignment to the file \naln.bam\n\n\n\n\nExtract unmapped Illumina reads\n\n\nIndex the alignment file:\n\n\nsamtools index aln.bam\n\n\n\n\n\nExtract the fastq files from the bam alignment - those reads that were unmapped to the Pacbio alignment - and save them in various \nunmapped\n files:\n\n\nsamtools fastq -f 4 -1 unmapped.R1.fastq -2 unmapped.R2.fastq -s unmapped.RS.fastq aln.bam\n\n\n\n\n\n\n\nfastq\n is a command that coverts a \n.bam\n file into fastq format\n\n\n-f 4\n : only output unmapped reads\n\n\n-1\n : put R1 reads into a file called \nunmapped.R1.fastq\n\n\n-2\n : put R2 reads into a file called \nunmapped.R2.fastq\n\n\n-s\n : put singleton reads into a file called \nunmapped.RS.fastq\n\n\naln.bam\n : input alignment file\n\n\n\n\nWe now have three files of the unampped reads: \n unmapped.R1.fastq\n, \n unmapped.R2.fastq\n, \n unmapped.RS.fastq\n.\n\n\nAssemble the unmapped reads\n\n\nAssemble with Spades:\n\n\nspades.py -1 unmapped.R1.fastq -2 unmapped.R2.fastq -s unmapped.RS.fastq --careful --cov-cutoff auto -o spades_assembly\n\n\n\n\n\n\n\n\n\n(Click on the dark grey slider bar above and move it to the right, to see all the way to the end of the line.)\n\n\n\n\n\n\n-1\n is input file forward\n\n\n\n\n-2\n is input file reverse\n\n\n-s\n is unpaired\n\n\n--careful\n minimizes mismatches and short indels\n\n\n--cov-cutoff auto\n computes the coverage threshold (rather than the default setting, \noff\n)\n\n\n-o\n is the output directory\n\n\n\n\nMove into the output directory: \n\n\ncd spades_assembly\n\n\n\n\n\nLook at the contigs: \n\n\ninfoseq contigs.fasta\n\n\n\n\n\n\n\n1 contig has been assembled with a length of 2359 bases. \n\n\n\n\nCopy it to a new file: \n\n\ncp contigs.fasta contig2.fasta\n\n\n\n\n\nTrim the plasmid\n\n\nTo trim any overhang on this plasmid, we will blast the start of contig2 against itself.\n\n\nTake the start of the contig: \n\n\nhead -n 10 contig2.fasta \n contig2.fa.head\n\n\n\n\n\n\n\nhead -n 10\n takes the first ten lines of \ncontig2.fasta\n\n\n\n\n sends that output to a new file called \ncontig2.fa.head\n\n\n\n\n\n\nWe want to see if the start of the contig matches the end (overhang).\n\n\n\n\n\n\nFormat the assembly file for blast: \n\n\nmakeblastdb -in contig2.fasta -dbtype nucl\n\n\n\n\n\n\n\nmakeblastdb\n makes a database for the tool Blast\n\n\nThis will generate three new files in the directory with suffixes .nhr, .nin and .nsq\n\n\n-in\n sets the input file as \n contig2.fasta\n\n\n-dbtype nucl\n sets the type to nucleotide (rather than protein)\n\n\n\n\nBlast the start of the assembly (.head file) against all of the assembly: \n\n\nblastn -query contig2.fa.head -db contig2.fasta -evalue 1e-3 -dust no -out contig2.bls\n\n\n\n\n\n\n\nblastn\n is the tool Blast, set as blast\nn\n to compare sequences of nucleotides to each other\n\n\n-query\n sets the input sequence as \ncontig2.fa.head\n\n\n-db\n sets the database as that of the original sequence \ncontig2.fasta\n. We don\nt have to specify the other files that were created when we formatted this file, but they need to present in our current directory. \n\n\n-evalue\n is the number of hits expected by chance, here set as 1e-3\n\n\n-dust no\n turns off the masking of low-complexity regions\n\n\n-out\n sets the output file as \ncontig2.bls\n\n\n\n\nLook at the hits (the matches): \n\n\nless contig2.bls\n\n\n\n\n\n\n\nThe first hit is at the start, as expected. We can see that \nQuery 1\n (the start of the contig) is aligned to \nSbject 1\n (the whole contig), for the first 540 bases.\n\n\nScroll down with the down arrow. \n\n\nThe second hit shows \nQuery 1\n (the start of the contig) also matches to \nSbject 1\n (the whole contig) at position 2253, all the way to the end, position 2359. \n\n\n\n\n\n\n\n\nThis is the overhang.\n\n\nTherefore, in the next step, we need to trim the contig to position 2252.\n\n\nType \nq\n to exit. \n\n\n\n\nFirst, change the name of the contig within the file:\n\n\nnano contig2.fasta\n\n\n\n\n\n\n\nnano\n opens up a text editor. \n\n\nUse the arrow keys to navigate. (The mouse won\nt work.)\n\n\nAt the first line, delete the text, which will be something like \nNODE_1_length_2359_cov_3.320333\n\n\nType in \ncontig2\n \n\n\nDon\nt forget the \n symbol\n\n\nPress Control-X\n\n\nSave modified buffer ?\n - type \nY\n\n\nPress the Enter key\n\n\n\n\nIndex the file (this will allow samtools to edit the file as it will have an index): \n\n\nsamtools faidx contig2.fasta\n\n\n\n\n\n\n\nfaidx\n means index the fasta file\n\n\n\n\nTrim the contig:\n\n\nsamtools faidx contig2.fasta contig2:1-2252 \n plasmid.fasta\n\n\n\n\n\n\n\nthis extracts contig2 from position 1-2252\n\n\n\n\n plasmid.fasta\n sends the extracted section to a new file\n\n\n\n\n\n\nWe now have a trimmed plasmid.\n\n\n\n\n\n\nCopy the plasmid file into the main folder: \n\n\ncp plasmid.fasta ../\n\n\n\n\n\nMove file back into main folder: \n\n\ncd ..\n\n\n\n\n\nCollect contigs\n\n\nCollect the chromosome and the plasmid in one fasta file (they will be 2 records in the file): \n\n\ncat contig1.fasta plasmid.fasta \n genome.fasta\n\n\n\n\n\nSee the contigs and sizes:\n\n\ninfoseq genome.fasta\n\n\n\n\n\n\n\nchromosome: 30019\n\n\nplasmid: 2252\n\n\n\n\nQuestions\n\n\n\n\nQuestion\n\n\nWhy is this section so complicated?\n\n\nAnswer\nFinding small plasmids is difficult for many reasons! This paper has a nice summary: On the (im)possibility to reconstruct plasmids from whole genome short-read sequencing data. doi: https://doi.org/10.1101/086744\n\n\n\n\nQuestion\n\n\nWhy can PacBio sequencing miss small plasmids?\n\n\nAnswer\nLibrary prep size selection.\n\n\n\n\nQuestion\n\n\nWe extract unmapped Illumina reads and assemble these to find small plasmids. What could they be missing?\n\n\nAnswer\nRepeats that have mapped to the PacBio assembly.\n\n\n\n\nQuestion\n\n\nHow do you find a plasmid in a Bandage graph?\n\n\nAnswer\nIt is probably circular, matches the size of a known plasmid, and has a rep gene.\n\n\n\n\nQuestion\n\n\nAre there easier ways to find plasmids?\n\n\nAnswer\nPossibly. One option is the program called Unicycler which may automate many of these steps. https://github.com/rrwick/Unicycler\n\n\n7. Correct the assembly\n\n\nSequences from PacBio can have more errors than those from Illumina. Therefore, although it is useful to use the long PacBio reads to assemble the genome, we can also use the shorter and more accurate Illumina reads to correct errors in the PacBio assembly. \n\n\nMake an alignment file\n\n\nIndex the fasta file:\n\n\nbwa index genome.fasta\n\n\n\n\n\nAlign the Illumina reads:\n\n\nbwa mem -t 4 genome.fasta R1.fq R2.fq | samtools sort \n pilon_aln.bam\n\n\n\n\n\n\n\nAligns Illumina \nR1.fq\n and \nR2.fq\n to the PacBio assembly \ngenome.fasta\n. \n\n\nThis produces a .bam file\n\n\n|\n pipes the output to samtools to sort (required for downstream processing)\n\n\n pilon_aln.bam\n redirects the sorted bam to this file\n\n\n\n\nIndex the files:\n\n\nsamtools index pilon_aln.bam\n\n\n\n\n\nsamtools faidx genome.fasta\n\n\n\n\n\n\n\nNow we have an alignment file to use  with the tool \nPilon\n: \npilon_aln.bam\n\n\n\n\nRun Pilon\n\n\nRun:\n\n\npilon --genome genome.fasta --frags pilon_aln.bam --output pilon1 --fix all --mindepth 0.5 --changes --verbose --threads 4\n\n\n\n\n\n\n\n--genome\n is the name of the input assembly to be corrected\n\n\n--frags\n is the alignment of the reads against the assembly\n\n\n--output\n is the name of the output prefix\n\n\n--fix\n is an option for types of corrections\n\n\n--mindepth\n gives a minimum read depth to use\n\n\n--changes\n produces an output file of the changes made\n\n\n--verbose\n prints information to the screen during the run\n\n\n--threads\n: number of cores\n\n\n\n\nLook at the changes file: \n\n\nless pilon1.changes\n\n\n\n\n\nExample:\n\n\n\n\n\n\nWe can see lots of cases where a deletion (represented by a dot) has been corrected to a base.  \n\n\nType \nq\n to exit. \n\n\n\n\nLook at the details of the fasta file: \n\n\ninfoseq pilon1.fasta\n\n\n\n\n\n\n\nchromosome - 30060 (net +41 bases)\n\n\nplasmid - 2252 (no change)\n\n\n\n\nChange the file name: \n\n\ncp pilon1.fasta assembly.fasta\n\n\n\n\n\nWe now have the corrected genome assembly of \nStaphylococcus aureus\n in .fasta format, containing a chromosome and a small plasmid.  \n\n\nQuestions\n\n\n\n\nQuestion\n\n\nWhy don\nt we correct earlier in the assembly process?\n\n\nAnswer\nWe need to circularise the contigs and trim overhangs first.\n\n\n\n\nQuestion\n\n\nWhy can we use some reads (Illumina) to correct other reads (PacBio) ?\n\n\nAnswer\nIllumina reads have higher accuracy.\n\n\n\n\nQuestion\n\n\nCould we just use PacBio reads to assemble the genome?\n\n\nAnswer\nYes, if accuracy adequate.\n\n\n8. Comparative Genomics\n\n\nIn the workshop so far, we used a partial bacterial genome so that the exercises could run in the time available. As a demonstration, to better see the effect of long and short reads on the assembly, we will examine complete bacterial genome. \n\n\nAssemblies\n\n\nThis bacterial genome has been assembled from either long PacBio reads (using Canu) or shorter Illumina reads (using Spades). \n\n\nAssembly graphs:\n\n\nLook at the assembly graph (usually has a suffix .gfa), in the program \nBandage\n. This shows how contigs are related, albeit with ambiguity in some places.\n\n\nThe assembly graph from Illumina reads (Spades assembly):\n\n\n\n\nThe assembly graph from PacBio reads (Canu assembly) - this is missing the small plasmid:\n\n\n\n\nHere we can see that the long read data results in a more contiguous assembly - one complete chromosome versus many smaller contigs with ambiguous placement. \n\n\n\n\nQuestion\n\n\nDoes it matter that an assembly is in many contigs?\n\n\nAnswer\nYes and No. Yes: broken genes can lead to missing/incorrect annotations; fragmented assemblies provide less information about the genomic structure (\ne.g.\n the number of plasmids) and the location of genes of interest (\ne.g.\n gene A is located on plasmid X). No: many or all genes may still be annotated correctly. Gene location is useful (e.g. chromosome, plasmid1) but not always essential (e.g. presence/absence of particular resistance genes may be enough information).\n\n\nAnnotations\n\n\nGenomic features such as genes can be identified with annotation tools. We have used a tool called \nProkka\n to annotate the two genomes described above. \n\n\nSome of the output data is displayed here:\n\n\n\n\n\n\n\n\n\n\nassembly:\n\n\nPacBio\n\n\nIllumina\n\n\n\n\n\n\n\n\n\n\nsize\n\n\n2,825,804\n\n\n2,792,905\n\n\n\n\n\n\ncontigs\n\n\n2\n\n\n123\n\n\n\n\n\n\nCDS\n\n\n2614\n\n\n2575\n\n\n\n\n\n\ntRNA\n\n\n61\n\n\n65\n\n\n\n\n\n\nrRNA\n\n\n19\n\n\n4\n\n\n\n\n\n\n\n\n\n\n\n\nQuestion\n\n\nWhy are there more CDS identified in the PacBio assembly? \n\n\nAnswer\nThe PacBio assembly may have errors (usually a one base indel) which will cause a frame shift, which can result in three things: a longer CDS, a shorter CDS, or a shorter CDS plus an additional CDS. In addition, the Illumina assembly is about 33 kb smaller than the PacBio assembly. In bacteria, a rule of thumb is that 1 kb is roughly equal to one gene. Thus, we would probably expect about 33 fewer identified genes, which fits with these results.  \n\n\n\n\nQuestion\n\n\nWhy are there more rRNA identified in the PacBio assembly? \n\n\nAnswer\nThere may be multiple copies of the rRNAs and these could have been collapsed as repeats in the Illumina assembly. \n\n\n9. Summary\n\n\nIn this workshop, we used bacterial sequencing data from long and short reads to produce a polished genome. \n\n\nProcedure and tools: \n\n\n\n\nCanu to assemble long-read PacBio data\n\n\nCirclator to trim and circularise contigs\n\n\nBWA-MEM to map shorter Illumina reads to the PacBio assembly\n\n\nSpades to assemble any unmapped, leftover Illumina reads (the plasmid)\n\n\nPilon to correct the PacBio assembly with the more accurate Illumina reads\n\n\n\n\nWe also looked at comparative genomics:\n\n\n\n\nBandage to examine assembly graphs\n\n\nProkka to annotate genomes with features such as genes\n\n\n\n\nFurther research:\n\n\n\n\nAlign genomes with Mauve: \ntutorial link\n\n\nFind core and pan genomes with Roary and Phandango: \ntutorial link\n\n\n\n\nMelbourne Bioinformatics tutorials:\n\n\n\n\nhttps://www.melbournebioinformatics.org.au/tutorials/\n\n\n\n\nAdditional microbial genomics tutorials:\n\n\n\n\nhttp://sepsis-omics.github.io/tutorials/", 
            "title": "Long read assembly workshop"
        }, 
        {
            "location": "/modules/cmdline_assembly_v2/#long-read-assembly-workshop", 
            "text": "This is a tutorial for a workshop on long-read (PacBio) genome assembly.   It demonstrates how to use long PacBio sequencing reads to assemble a bacterial genome, and includes additional steps for circularising, trimming, finding plasmids, and correcting the assembly with short-read Illumina data.", 
            "title": "Long read assembly workshop"
        }, 
        {
            "location": "/modules/cmdline_assembly_v2/#overview", 
            "text": "Simplified version of workflow:", 
            "title": "Overview"
        }, 
        {
            "location": "/modules/cmdline_assembly_v2/#1-get-started", 
            "text": "Your workshop trainers will provide you with the address of a virtual machine.", 
            "title": "1. Get started"
        }, 
        {
            "location": "/modules/cmdline_assembly_v2/#mac-users", 
            "text": "Open the Terminal.    Type in    ssh researcher@[your virtual machine address]   Type in the password provided.", 
            "title": "Mac users"
        }, 
        {
            "location": "/modules/cmdline_assembly_v2/#windows-users", 
            "text": "If you are using Windows 10, you might be able to use the Ubuntu Subsystem. Otherwise, install and open Putty.    Download putty  here .  Open. A configuration window will appear.   Under  Host Name (or IP address)  enter in the address of your virtual machine.   Under  Port  type in 22  Under  Connection Type  select  SSH  Click  Open  Under  Login as:  enter  researcher  Type in the password provided.", 
            "title": "Windows users"
        }, 
        {
            "location": "/modules/cmdline_assembly_v2/#create-a-new-working-directory-on-your-remote-computer", 
            "text": "Because we are starting a new analysis it is always good practice to start in a new empty directory. Therefore, we will create a new directory and change to it for the rest of the workshop.  In your terminal:   Create a new directory called  Workshop   mkdir Workshop   Change to that directory   cd Workshop  NOTE: Everytime you open a new terminal or Putty session, you will need to make sure you are in this directory again.  The current directory can be obtained with the linux command:  pwd", 
            "title": "Create a new working directory on your remote computer."
        }, 
        {
            "location": "/modules/cmdline_assembly_v2/#2-get-data", 
            "text": "The sample used in this tutorial is from a bacteria called  Staphylococcus aureus . We have used a small section of its real genome so that the programs can run in the workshop time.   The files we need are:   pacbio.fq : the PacBio reads  R1.fq : the Illumina forward reads  R2.fq : the Illumina reverse reads   In a new tab, go to  https://doi.org/10.5281/zenodo.1009308 .    Next to the first file, right-click (or control-click) the  Download  button, and select  Copy link address .  Back in your terminal, enter    wget [paste file link here]   The file should download.   Note:  paste the link to the file, not to the webpage.  Repeat this for the other two files.", 
            "title": "2. Get data"
        }, 
        {
            "location": "/modules/cmdline_assembly_v2/#3-assemble", 
            "text": "We will use the assembly software called  Canu , version 1.6.  Run Canu with these commands:  canu -p canu -d canu_outdir genomeSize=0.03m -pacbio-raw pacbio.fq   the first  canu  tells the program to run  -p canu  names prefix for output files ( canu )  -d canu_outdir  names output directory ( canu_outdir )  genomeSize  only has to be approximate. (In this case we are using a partial genome of expected size 30,000 base pairs).   Canu will correct, trim and assemble the reads.  Various output will be displayed on the screen.  Note : Canu could say  Finished  but may still be running. In this case, type  squeue  to see if jobs are still running.    If you run  squeue  you will see something like this:               JOBID PARTITION     NAME     USER ST       TIME  NODES NODELIST(REASON)\n                 6      main canu_can research PD       0:00      1 (Dependency)\n               5_1      main cormhap_ research  R       0:29      1 master  You will know if  Canu  has completely finished when  squeue  shows no jobs listed under the header row.", 
            "title": "3. Assemble"
        }, 
        {
            "location": "/modules/cmdline_assembly_v2/#4-check-assembly-output", 
            "text": "Move into the canu output folder:   cd canu_outdir  View the list of files:   ls   The  canu.contigs.fasta  are the assembled sequences.  The  canu.unassembled.fasta  are the reads that could not be assembled.  The  canu.correctedReads.fasta.gz  are the corrected Pacbio reads that were used in the assembly.  The  canu.contigs.gfa  is the graph of the assembly.  The  canu.report  file is a summary of all of the steps Canu performed with information about the reads used, how they were handled and a whole lot of summary information about the assembly.   Display summary information about the contigs: ( infoseq  is a tool from  EMBOSS )  infoseq canu.contigs.fasta   This will show the contigs found by Canu. e.g.,  tig00000001  39136  tig00000001  is the name given to the contig  39136  is the number of base pairs in that contig.   This matches what we were expecting for this sample (approximately 30,000 base pairs). For other data, Canu may not be able to join all the reads into one contig, so there may be several contigs in the output.  We should also look at the  canu.report . To do this:  less canu.report   less  is a command to display the file on the screen.  Use the up and down arrows to scroll up and down.   You will see lots of histograms of read lengths before and after processing, final contig construction, etc.   For a description of the outputs that Canu produces, see:  http://canu.readthedocs.io/en/latest/tutorial.html#outputs  Type  q  to exit viewing the report.", 
            "title": "4. Check assembly output"
        }, 
        {
            "location": "/modules/cmdline_assembly_v2/#questions", 
            "text": "Question  How do long- and short-read assembly methods differ?  Answer Short reads are usually assembled with De Bruijn graphs. For long reads, there is a move back towards simpler overlap-layout-consensus methods.   Question  Where can we find out the what the approximate genome size should be for the species being assembled?  Answer Go to NCBI Genomes, enter species name, click on Genome Assembly and Annotation report, sort table by clicking on the column header Size (Mb), look at range of sizes in this column.   Question  In the assembly output, what are the unassembled reads? Why are they there?  Answer Reads and low-coverage contigs that were not used in the assembly.    Question  What are the corrected reads? How did canu correct the reads?  Answer Canu builds overlaps between reads. The consensus is used to correct the reads.    Question  Where could you view the output .gfa and what would it show?  Answer A useful program is  Bandage . If the assembly has multiple contigs, the assembly graph shows how these are connected.", 
            "title": "Questions"
        }, 
        {
            "location": "/modules/cmdline_assembly_v2/#5-trim-and-circularise", 
            "text": "Bacteria have circular chromosomes.    Because of sequencing errors, there may be some  overhang  in the assembled linear sequence.   Our assembly may have some overhang because it is 9000 bases longer than expected.     Adapted from Figure 1. Hunt et al. Genome Biology 2015  A tool called  Circlator  identifies and trims overhangs (on chromosomes and plasmids). It takes in the assembled contigs from Canu, as well as the corrected reads prepared by Canu.  Move back into your main analysis folder:   cd ..", 
            "title": "5. Trim and circularise"
        }, 
        {
            "location": "/modules/cmdline_assembly_v2/#run-circlator", 
            "text": "circlator all --threads 4 --verbose canu_outdir/canu.contigs.fasta canu_outdir/canu.correctedReads.fasta.gz circlator_outdir    (Click on the dark grey slider bar above and move it to the right, to see all the way to the end of the line.)    --threads  is the number of cores   --verbose  prints progress information to the screen  canu_outdir/canu.contigs.fasta  is the file path to the input Canu assembly  canu_outdir/canu.correctedReads.fasta.gz  is the file path to the corrected Pacbio reads - note, fastA not fastQ  circlator_outdir  is the name of the output directory.   Some output will print to screen. When finished, it should say  Circularized x of x contig(s) .", 
            "title": "Run Circlator"
        }, 
        {
            "location": "/modules/cmdline_assembly_v2/#check-the-output", 
            "text": "Move into the Circlator output directory:   cd circlator_outdir  List the files:   ls  Circlator has named the output files with numbers as prefixes.   Were the contigs circularised?  less 04.merge.circularise.log   less  is a command to display the file on the screen.  04.merge.circularise.log  is the name of the file.   Yes, the contig was circularised (last column).  Type  q  to exit.   What are the trimmed contig sizes?   infoseq 06.fixstart.fasta   The contig  tig00000001  has a length of 30019.  This is about 9000 bases shorter than before circularisation. This was the  overhang  and has now been trimmed.    Copy the circularised contigs file to the main analysis directory with a new name:  cp 06.fixstart.fasta ../contig1.fasta  Move back into the main folder:   cd ..", 
            "title": "Check the output"
        }, 
        {
            "location": "/modules/cmdline_assembly_v2/#questions_1", 
            "text": "Question  Were all the contigs circularised?   Answer In this example, yes, the contig was circularised.    Question  Circlator can set the start of the sequence at a particular gene. Which gene does it use? Is this appropriate for all contigs?  Answer Circlator uses dnaA (if present) for the chromosomal contig. For other contigs, it uses a centrally-located gene. However, ideally, plasmids would be oriented on a gene such as repA. It is possible to provide a file to Circlator to do this.", 
            "title": "Questions"
        }, 
        {
            "location": "/modules/cmdline_assembly_v2/#6-find-smaller-plasmids", 
            "text": "Pacbio reads are long, and may have been longer than small plasmids. We will look for any small plasmids using the Illumina reads.  This section involves several steps:   Use the Canu+Circlator output of a trimmed assembly contig.  Map all the Illumina reads against this Pacbio-assembled contig.  Extract any reads that  didn t  map and assemble them together: this could be a plasmid, or part of a plasmid.  Look for overhang: if found, trim.", 
            "title": "6. Find smaller plasmids"
        }, 
        {
            "location": "/modules/cmdline_assembly_v2/#align-illumina-reads-to-the-pacbio-contig", 
            "text": "Index the contigs file:  bwa index contig1.fasta  Align Illumina reads using using bwa mem:  bwa mem -t 4 contig1.fasta R1.fq R2.fq | samtools sort   aln.bam   bwa mem  is the alignment tool  -t 4  is the number of cores  contig1.fasta  is the input assembly file  R1.fq R2.fq  are the Illumina reads  | samtools sort  pipes the output to samtools to sort   aln.bam  sends the alignment to the file  aln.bam", 
            "title": "Align Illumina reads to the PacBio contig"
        }, 
        {
            "location": "/modules/cmdline_assembly_v2/#extract-unmapped-illumina-reads", 
            "text": "Index the alignment file:  samtools index aln.bam  Extract the fastq files from the bam alignment - those reads that were unmapped to the Pacbio alignment - and save them in various  unmapped  files:  samtools fastq -f 4 -1 unmapped.R1.fastq -2 unmapped.R2.fastq -s unmapped.RS.fastq aln.bam   fastq  is a command that coverts a  .bam  file into fastq format  -f 4  : only output unmapped reads  -1  : put R1 reads into a file called  unmapped.R1.fastq  -2  : put R2 reads into a file called  unmapped.R2.fastq  -s  : put singleton reads into a file called  unmapped.RS.fastq  aln.bam  : input alignment file   We now have three files of the unampped reads:   unmapped.R1.fastq ,   unmapped.R2.fastq ,   unmapped.RS.fastq .", 
            "title": "Extract unmapped Illumina reads"
        }, 
        {
            "location": "/modules/cmdline_assembly_v2/#assemble-the-unmapped-reads", 
            "text": "Assemble with Spades:  spades.py -1 unmapped.R1.fastq -2 unmapped.R2.fastq -s unmapped.RS.fastq --careful --cov-cutoff auto -o spades_assembly    (Click on the dark grey slider bar above and move it to the right, to see all the way to the end of the line.)    -1  is input file forward   -2  is input file reverse  -s  is unpaired  --careful  minimizes mismatches and short indels  --cov-cutoff auto  computes the coverage threshold (rather than the default setting,  off )  -o  is the output directory   Move into the output directory:   cd spades_assembly  Look at the contigs:   infoseq contigs.fasta   1 contig has been assembled with a length of 2359 bases.    Copy it to a new file:   cp contigs.fasta contig2.fasta", 
            "title": "Assemble the unmapped reads"
        }, 
        {
            "location": "/modules/cmdline_assembly_v2/#trim-the-plasmid", 
            "text": "To trim any overhang on this plasmid, we will blast the start of contig2 against itself.  Take the start of the contig:   head -n 10 contig2.fasta   contig2.fa.head   head -n 10  takes the first ten lines of  contig2.fasta    sends that output to a new file called  contig2.fa.head    We want to see if the start of the contig matches the end (overhang).    Format the assembly file for blast:   makeblastdb -in contig2.fasta -dbtype nucl   makeblastdb  makes a database for the tool Blast  This will generate three new files in the directory with suffixes .nhr, .nin and .nsq  -in  sets the input file as   contig2.fasta  -dbtype nucl  sets the type to nucleotide (rather than protein)   Blast the start of the assembly (.head file) against all of the assembly:   blastn -query contig2.fa.head -db contig2.fasta -evalue 1e-3 -dust no -out contig2.bls   blastn  is the tool Blast, set as blast n  to compare sequences of nucleotides to each other  -query  sets the input sequence as  contig2.fa.head  -db  sets the database as that of the original sequence  contig2.fasta . We don t have to specify the other files that were created when we formatted this file, but they need to present in our current directory.   -evalue  is the number of hits expected by chance, here set as 1e-3  -dust no  turns off the masking of low-complexity regions  -out  sets the output file as  contig2.bls   Look at the hits (the matches):   less contig2.bls   The first hit is at the start, as expected. We can see that  Query 1  (the start of the contig) is aligned to  Sbject 1  (the whole contig), for the first 540 bases.  Scroll down with the down arrow.   The second hit shows  Query 1  (the start of the contig) also matches to  Sbject 1  (the whole contig) at position 2253, all the way to the end, position 2359.      This is the overhang.  Therefore, in the next step, we need to trim the contig to position 2252.  Type  q  to exit.    First, change the name of the contig within the file:  nano contig2.fasta   nano  opens up a text editor.   Use the arrow keys to navigate. (The mouse won t work.)  At the first line, delete the text, which will be something like  NODE_1_length_2359_cov_3.320333  Type in  contig2    Don t forget the   symbol  Press Control-X  Save modified buffer ?  - type  Y  Press the Enter key   Index the file (this will allow samtools to edit the file as it will have an index):   samtools faidx contig2.fasta   faidx  means index the fasta file   Trim the contig:  samtools faidx contig2.fasta contig2:1-2252   plasmid.fasta   this extracts contig2 from position 1-2252    plasmid.fasta  sends the extracted section to a new file    We now have a trimmed plasmid.    Copy the plasmid file into the main folder:   cp plasmid.fasta ../  Move file back into main folder:   cd ..", 
            "title": "Trim the plasmid"
        }, 
        {
            "location": "/modules/cmdline_assembly_v2/#collect-contigs", 
            "text": "Collect the chromosome and the plasmid in one fasta file (they will be 2 records in the file):   cat contig1.fasta plasmid.fasta   genome.fasta  See the contigs and sizes:  infoseq genome.fasta   chromosome: 30019  plasmid: 2252", 
            "title": "Collect contigs"
        }, 
        {
            "location": "/modules/cmdline_assembly_v2/#questions_2", 
            "text": "Question  Why is this section so complicated?  Answer Finding small plasmids is difficult for many reasons! This paper has a nice summary: On the (im)possibility to reconstruct plasmids from whole genome short-read sequencing data. doi: https://doi.org/10.1101/086744   Question  Why can PacBio sequencing miss small plasmids?  Answer Library prep size selection.   Question  We extract unmapped Illumina reads and assemble these to find small plasmids. What could they be missing?  Answer Repeats that have mapped to the PacBio assembly.   Question  How do you find a plasmid in a Bandage graph?  Answer It is probably circular, matches the size of a known plasmid, and has a rep gene.   Question  Are there easier ways to find plasmids?  Answer Possibly. One option is the program called Unicycler which may automate many of these steps. https://github.com/rrwick/Unicycler", 
            "title": "Questions"
        }, 
        {
            "location": "/modules/cmdline_assembly_v2/#7-correct-the-assembly", 
            "text": "Sequences from PacBio can have more errors than those from Illumina. Therefore, although it is useful to use the long PacBio reads to assemble the genome, we can also use the shorter and more accurate Illumina reads to correct errors in the PacBio assembly.", 
            "title": "7. Correct the assembly"
        }, 
        {
            "location": "/modules/cmdline_assembly_v2/#make-an-alignment-file", 
            "text": "Index the fasta file:  bwa index genome.fasta  Align the Illumina reads:  bwa mem -t 4 genome.fasta R1.fq R2.fq | samtools sort   pilon_aln.bam   Aligns Illumina  R1.fq  and  R2.fq  to the PacBio assembly  genome.fasta .   This produces a .bam file  |  pipes the output to samtools to sort (required for downstream processing)   pilon_aln.bam  redirects the sorted bam to this file   Index the files:  samtools index pilon_aln.bam  samtools faidx genome.fasta   Now we have an alignment file to use  with the tool  Pilon :  pilon_aln.bam", 
            "title": "Make an alignment file"
        }, 
        {
            "location": "/modules/cmdline_assembly_v2/#run-pilon", 
            "text": "Run:  pilon --genome genome.fasta --frags pilon_aln.bam --output pilon1 --fix all --mindepth 0.5 --changes --verbose --threads 4   --genome  is the name of the input assembly to be corrected  --frags  is the alignment of the reads against the assembly  --output  is the name of the output prefix  --fix  is an option for types of corrections  --mindepth  gives a minimum read depth to use  --changes  produces an output file of the changes made  --verbose  prints information to the screen during the run  --threads : number of cores   Look at the changes file:   less pilon1.changes  Example:    We can see lots of cases where a deletion (represented by a dot) has been corrected to a base.    Type  q  to exit.    Look at the details of the fasta file:   infoseq pilon1.fasta   chromosome - 30060 (net +41 bases)  plasmid - 2252 (no change)   Change the file name:   cp pilon1.fasta assembly.fasta  We now have the corrected genome assembly of  Staphylococcus aureus  in .fasta format, containing a chromosome and a small plasmid.", 
            "title": "Run Pilon"
        }, 
        {
            "location": "/modules/cmdline_assembly_v2/#questions_3", 
            "text": "Question  Why don t we correct earlier in the assembly process?  Answer We need to circularise the contigs and trim overhangs first.   Question  Why can we use some reads (Illumina) to correct other reads (PacBio) ?  Answer Illumina reads have higher accuracy.   Question  Could we just use PacBio reads to assemble the genome?  Answer Yes, if accuracy adequate.", 
            "title": "Questions"
        }, 
        {
            "location": "/modules/cmdline_assembly_v2/#8-comparative-genomics", 
            "text": "In the workshop so far, we used a partial bacterial genome so that the exercises could run in the time available. As a demonstration, to better see the effect of long and short reads on the assembly, we will examine complete bacterial genome.", 
            "title": "8. Comparative Genomics"
        }, 
        {
            "location": "/modules/cmdline_assembly_v2/#assemblies", 
            "text": "This bacterial genome has been assembled from either long PacBio reads (using Canu) or shorter Illumina reads (using Spades).   Assembly graphs:  Look at the assembly graph (usually has a suffix .gfa), in the program  Bandage . This shows how contigs are related, albeit with ambiguity in some places.  The assembly graph from Illumina reads (Spades assembly):   The assembly graph from PacBio reads (Canu assembly) - this is missing the small plasmid:   Here we can see that the long read data results in a more contiguous assembly - one complete chromosome versus many smaller contigs with ambiguous placement.    Question  Does it matter that an assembly is in many contigs?  Answer Yes and No. Yes: broken genes can lead to missing/incorrect annotations; fragmented assemblies provide less information about the genomic structure ( e.g.  the number of plasmids) and the location of genes of interest ( e.g.  gene A is located on plasmid X). No: many or all genes may still be annotated correctly. Gene location is useful (e.g. chromosome, plasmid1) but not always essential (e.g. presence/absence of particular resistance genes may be enough information).", 
            "title": "Assemblies"
        }, 
        {
            "location": "/modules/cmdline_assembly_v2/#annotations", 
            "text": "Genomic features such as genes can be identified with annotation tools. We have used a tool called  Prokka  to annotate the two genomes described above.   Some of the output data is displayed here:      assembly:  PacBio  Illumina      size  2,825,804  2,792,905    contigs  2  123    CDS  2614  2575    tRNA  61  65    rRNA  19  4       Question  Why are there more CDS identified in the PacBio assembly?   Answer The PacBio assembly may have errors (usually a one base indel) which will cause a frame shift, which can result in three things: a longer CDS, a shorter CDS, or a shorter CDS plus an additional CDS. In addition, the Illumina assembly is about 33 kb smaller than the PacBio assembly. In bacteria, a rule of thumb is that 1 kb is roughly equal to one gene. Thus, we would probably expect about 33 fewer identified genes, which fits with these results.     Question  Why are there more rRNA identified in the PacBio assembly?   Answer There may be multiple copies of the rRNAs and these could have been collapsed as repeats in the Illumina assembly.", 
            "title": "Annotations"
        }, 
        {
            "location": "/modules/cmdline_assembly_v2/#9-summary", 
            "text": "In this workshop, we used bacterial sequencing data from long and short reads to produce a polished genome.   Procedure and tools:    Canu to assemble long-read PacBio data  Circlator to trim and circularise contigs  BWA-MEM to map shorter Illumina reads to the PacBio assembly  Spades to assemble any unmapped, leftover Illumina reads (the plasmid)  Pilon to correct the PacBio assembly with the more accurate Illumina reads   We also looked at comparative genomics:   Bandage to examine assembly graphs  Prokka to annotate genomes with features such as genes   Further research:   Align genomes with Mauve:  tutorial link  Find core and pan genomes with Roary and Phandango:  tutorial link   Melbourne Bioinformatics tutorials:   https://www.melbournebioinformatics.org.au/tutorials/   Additional microbial genomics tutorials:   http://sepsis-omics.github.io/tutorials/", 
            "title": "9. Summary"
        }, 
        {
            "location": "/modules/dge/", 
            "text": "Differential Gene Expression\n\n\nKeywords: differential gene expression, DGE, RNA, RNA-Seq, transcriptomics, Degust, voom, limma, Galaxy, Microbial Genomics Virtual Laboratory.\n\n\nThis tutorial is about differential gene expression in bacteria, using Galaxy tools and Degust (web).\n\n\n\n\n\nBackground\n\n\nDifferential Gene Expression (DGE) is the process of determining whether any genes were expressed at a different level between two conditions. For example, the conditions could be wildtype versus mutant, or two growth conditions. Usually multiple biological replicates are done for each condition - these are needed to separate variation within the condition from that between the conditions.\n\n\nLearning Objectives\n\n\nAt the end of this tutorial you should be able to:\n\n\n\n\nAlign RNA-Seq data to a reference genome  \n\n\nCount transcripts for each sample\n\n\nPerform statistical analysis to obtain a list of differentially expressed genes\n\n\nVisualize and interpret the results\n\n\n\n\nInput data: reads and reference\n\n\nRNA-Seq reads\n\n\nA typical experiment will have 2 conditions each with 3 replicates, for a total of 6 samples.\n\n\n\n\nOur RNA-seq reads are from 6 samples in \nFASTQ\n format.\n\n\nWe have single-end reads; so one file per sample.\n\n\nData could also be paired-end reads, and there would be two files per sample.\n\n\n\n\n\n\nThese have been reduced to 1% of their original size for this tutorial.\n\n\nThe experiment used the bacteria \nE. coli\n grown in two conditions.\n\n\nFiles labelled \nLB\n are the wildtype\n\n\nFiles labelled \nMG\n have been exposed to 0.5% \nMG - alpha methyglucoside (a sugar solution).\n\n\n\n\n\n\n\n\n\n\n\nReference genome\n\n\nThe reference genomes is in \nFASTA\n format and the gene annotations are in \nGTF\n format.\n\n\n\n\nThe \nFASTA\n file contains the DNA sequence(s) that make up the genome; e.g. the chromosome and any plasmids.\n\n\nThe \nGTF\n file lists the coordinates (position) of each feature. Commonly-annotated features are genes, transcripts and protein-coding sequences.\n\n\n\n\n\n\n\nUpload files to Galaxy\n\n\n\n\nLog in to your Galaxy server.\n\n\nIn the \nHistory\n pane, click on the cog\nicon, and select \nImport from File\n (at the bottom of the list).\n\n\nUnder \nArchived History URL\n paste:\n\nhttps://swift.rc.nectar.org.au:8888/v1/AUTH_377/public/Microbial_tutorials/Galaxy-History-BacterialDGE.tar.gz\n\n\nIn the \nHistory\n pane, click on the view\nicon and find the uploaded history.\n\n\n(This may take a minute. Refresh the page.)\n\n\n\n\n\n\nClick \nSwitch to\n that history, then \nDone\n.\n\n\nThe files should now be ready to use in your current History pane.\n\n\n\n\n\n\nAlign reads to reference\n\n\nThe RNA-Seq reads are fragmented and are not complete transcripts. To determine the transcripts from which the reads originated (and therefore, to which gene they correspond) we can map them to a reference genome.\n\n\nIn Galaxy:\n\n\n\n\nGo to \nTools \n NGS Analysis \n NGS: Mapping \n Map with BWA-MEM\n\n\nUnder \nWill you select a reference genome from your history or use a built-in index?\n: \nUse a genome from history and build index\n\n\nUse the following dataset as the reference sequence\n: \nEcoli_k12.fasta\n\n\nSingle or Paired-end reads\n: \nsingle\n\n\nSelect fastq dataset\n:\n\n\nClick on the \nMultiple Datasets\n icon in centre\n\n\nSelect all 6 \nFASTQ\n files (they turn blue; use side-scroll bar to check all have been selected)\n\n\nThis will map each set of reads to the reference genome\n\n\n\n\n\n\n\n\nYour tool interface should look like this:\n\n\n\n\n\n\nClick \nExecute\n\n\nClick \nRefresh\n in the history pane to see if the analysis has finished.\n\n\n\n\nOutput: 6 \nbam\n files of reads mapped to the reference genome.\n\n\n\n\n\n\nRe-name the output files:\n\n\n\n\nThese are called \nMap with BWA-MEM on data x and data x\n.\n\n\nClick on the pencil icon next to each of these and re-name them as their sample name (e.g. LB1, LB2 etc.).\n\n\nClick \nSave\n.\n\n\n\n\n\n\n\n\nCount reads per gene\n\n\nWe now need to count how many reads overlap with particular genes. The information about gene names is from the annotations in the GTF file.\n\n\nIn Galaxy:\n\n\n\n\nGo to \nTools \n NGS Analysis \n NGS: RNA Analysis \n SAM/BAM to count matrix\n.\n\n\nNote: Don\nt select the tool called \nhtseq-count\n. The \nSAM/BAM to count matrix\n also uses that tool but allows an input of multiple bam files, which is what we want.\n\n\n\n\n\n\nFor \nGene model (GFF) file to count reads over from your current history\n, select the \nGTF\n file.\n\n\nFor \nReads are stranded\n select \nYes\n (box turns dark grey)\n\n\nFor \nGTF feature type for counting reads\n select \ntranscript\n.\n\n\nFor \nbam/sam file from your history\n choose the 6 \nbam\n files.\n\n\n\n\nYour tool interface should look like this:\n\n\n\n\n\n\nClick \nExecute\n\n\nClick \nRefresh\n in the history pane to see if the analysis has finished.\n\n\n\n\nOutput:\n\n\n\n\nThere is one output file: \nbams to DGE count matrix\n.\n\n\nClick on the file name to expand the information in the History pane.\n\n\nClick on the file \nicon underneath to download it to your computer for use later on in this tutorial.\n\n\nClick on the eye icon to see this file.\n\n\n\n\n\n\n\n\nEach row is a gene (or feature) and each column is a sample, with counts against each gene.\n\n\nHave a look at how the counts vary between samples, per gene.\n\n\nWe can\nt just compare the counts directly; they need to be normalized before comparison, and this will be done as part of the DGE analysis in the next step.\n\n\n\n\nDGE in Degust\n\n\nDegust is a tool on the web that can analyse the counts files produced in the step above, to test for differential gene expression.\n\n\n(Degust can also display the results from DGE analyses performed elsewhere.)\n\n\nUpload counts file\n\n\nGo to the \nDegust web page\n. Click \nGet Started\n.\n\n\n\n\n\n\nClick on \nChoose File\n.\n\n\nSelect the \nhtseq output file. tabular\n (that you previously downloaded to your computer from Galaxy) and click \nOpen\n.\n\n\nClick \nUpload\n.\n\n\n\n\nA Configuation page will appear.\n\n\n\n\nFor \nName\n type \nDGE in E coli\n\n\nFor \nInfo columns\n select \nContig\n\n\nFor \nAnalyze server side\n leave box checked.\n\n\nFor \nMin read count\n put \n10\n.\n\n\nClick \nAdd condition\n\n\nAdd a condition called \nControl\n and select the LB columns.\n\n\nAdd a condition called \nTreament\n and select the MG columns.\n\n\n\n\n\n\n\n\nYour Configuration page should look like this:\n\n\n\n\n\n\nSave changes\n\n\nView\n - this brings up the Degust viewing window.\n\n\n\n\nOverview of Degust sections\n\n\n\n\nTop black panel with \nConfigure\n settings at right.\n\n\nLeft: Conditions: Control and Treatment.\n\n\nLeft: Method selection for DGE.\n\n\nTop centre: Plots, with options at right.\n\n\nWhen either of the expression plots are selected, a heatmap appears below.\n\n\nA table of genes (or features); expression in treatment relative to control (Treatment column); and significance (FDR column).  \n\n\n\n\n\n\nAnalyze gene expression\n\n\n\n\nUnder \nMethod\n, make sure that \nVoom/Limma\n is selected.\n\n\nClick \nApply\n. This runs Voom/Limma on the uploaded counts.\n\n\n\n\nMDS plot\n\n\nFirst, look at the MDS plot.\n\n\n\n\n\n\nThis is a multidimensional scaling plot which represents the variation between samples.\n\n\nIdeally:\n\n\nAll the LB samples would be close to each other\n\n\nAll the MG samples would be close to each other\n\n\nThe LB and MG groups would be far apart\n\n\n\n\n\n\nThe x-axis is the dimension with the highest magnitude. The control/treatment samples should be split along this axis.\n\n\nOur LB samples are on the left and the MG samples are on the right, which means they are well separated on their major MDS dimension, which looks correct.\n\n\n\n\nExpression - MA plot\n\n\nEach dot shows the change in expression in one gene.\n\n\n\n\nThe average expression (over both condition and treatment samples) is represented on the x-axis.\n\n\nPlot points should be symmetrical around the x-axis.\n\n\nWe can see that many genes are expressed at a low level, and some are highly expressed.\n\n\n\n\n\n\nThe fold change is represented on the y axis.\n\n\nIf expression is significantly different between treatment and control, the dots are red. If not, they are blue. (In Degust, significant means FDR \n0.05).\n\n\nAt low levels of gene expression (low values of the x axis), fold changes are less likely to be significant.\n\n\n\n\n\n\n\n\nClick on the dot to see the gene name.     \n\n\n\n\nExpression - Parallel Coordinates and heatmap\n\n\nEach line shows the change in expression in one gene, between control and treatment.\n\n\n\n\nGo to \nOptions\n at the right.\n\n\nFor \nFDR cut-off\n set at 0.001.\n\n\nThis is a significance level (an adjusted p value). We will set it quite low in this example, to ensure we only examine key differences.\n\n\n\n\n\n\n\n\nLook at the Parallel Coordinates plot. There are two axes:\n\n\n\n\nLeft: \nControl\n: Gene expression in the control samples. All values are set at zero.\n\n\nRight: \nTreatment\n Gene expression in the treatment samples, relative to expression in the control.\n\n\n\n\n\n\n\n\nThe blocks of blue and red underneath the plot are called a heatmap.\n\n\n\n\nEach block is a gene. Click on a block to see its line in the plot above.\n\n\nLook at the row for the Treatment. Relative to the control, genes expressed more are red; genes expressed less are blue.\n\n\n\n\n\n\n\n\n\n\nNote:\n\n\n\n\nfor an experiment with multiple treatments, the various treatment axes can be dragged to rearrange. There is no natural order (such as a time series).\n\n\n\n\nTable of genes\n\n\n\n\nContig\n: names of genes. Note that gene names are sometimes specific to a species, or they may be only named as a locus ID (a chromosomal location specified in the genome annotation).\n\n\nFDR\n: False Discovery Rate. This is an adjusted p value to show the significance of the difference in gene expression between two conditions. Click on column headings to sort. By default, this table is sorted by FDR.\n\n\nControl\n and \nTreatment\n: log2(Fold Change) of gene expression. The default display is of fold change in the treatment relative to the control. Therefore, values in the \nControl\n column are zero. This can be changed in the \nOptions\n panel at the top right.\n\n\nIn some cases, a large fold change will be meaningful but in others, even a small fold change can be important biologically.\n\n\n\n\nTable of genes and expression:\n\n\n\n\n\n\n\nDGE in Galaxy\n\n\nDifferential gene expression can also be analyzed in Galaxy. The input is the count matrix produced by a tool such as HTSeq-Count (see section above: \nCount reads per gene\n).\n\n\n\n\nGo to \nTools \n NGS Analysis \n NGS: RNA Analysis \n Differential Count models\n\n\nThis has options to use edgeR, DESeq, or Voom. Here we will use Voom.\n\n\n\n\n\n\nFor \nSelect an input matrix\n choose the \ncount matrix\n file generated in the previous step.\n\n\nFor \nTitle for job outputs\n enter \nDGE using voom\n.\n\n\nFor \nSelect columns containing treatment\n tick boxes for the MG samples.\n\n\nFor \nSelect columns containing control\n tick boxes for the LB samples.\n\n\nUnder \nRun this model using edgeR\n choose \nDo not run edgeR\n.\n\n\nUnder \nRun the same model with DESeq2 and compare findings\n choose \nDo not run DESeq2\n.\n\n\nUnder \nRun the same model with Voom/limma and compare findings\n choose \nRun VOOM\n.\n\n\n\n\nYour tool interface should look like this:\n\n\n\n\n\n\nClick \nExecute\n.\n\n\n\n\nThere are two output files.\n\n\nView the file called \nDGEusingvoom.html\n.\n\n\n\n\nScroll down to \nVOOM log output\n and \n#VOOM top 50\n.\n\n\nThe \nContig\n column has the gene names.\n\n\nLook at the \nadj.P.Val\n column. This is an adjusted p value to show the significance of the gene expression difference, accounting for the effect of multiple testing. Also known as False Discovery Rate. The table is ordered by the values in this column.\n\n\nLook at the \nlogFC\n column. This is log2(Fold Change) of relative gene expression between the treatment samples and the control samples.\n\n\n\n\nView the file called \nDEGusingvoom_topTable_VOOM.xls\n.\n\n\n\n\nThis is a list of all the genes that had transcripts mapped, and associated statistics.\n\n\n\n\nWhat next?\n\n\nTo learn more about the differentially-expressed genes:\n\n\n\n\nGo to \nthe NCBI website.\n\n\nUnder \nAll Databases\n, click on \nGene\n\n\nEnter the gene name in the search bar; e.g. ptsG\n\n\nClick on the first result that matches the species (e.g. in this case, \nE. coli\n).\n\n\nThis provides information about the gene, and may also show further references (e.g. in this case, a link to the EcoGene resource).\n\n\n\n\n\n\n\n\nSome of the most (statistically) significant differentially-expressed genes in this experiment are:\n\n\n\n\nptsG\n: a glucose-specific transporter.\n\n\nsetA\n: a sugar efflux transporter; is induced by glucose-phosphate stress.\n\n\nsucD\n: the alpha subunit of the the gene for succinyl-CoA synthetase; involved in ATP production.\n\n\nsucB\n: a component of the 2-oxoglutarate dehydrogenase complex; catalyzes a step in the Krebs cycle.\n\n\ndeoC\n: 2-deoxyribose-5-phosphate aldolase; binds selenium; may be involved in selenium transport.\n\n\n\n\nNext steps: Investigate the biochemical pathways involving the genes of interest.\n\n\nMore information\n\n\n\n\nLink to Degust.\n\n\nLink to Voom paper.", 
            "title": "Differential gene expression using Galaxy and Degust"
        }, 
        {
            "location": "/modules/dge/#differential-gene-expression", 
            "text": "Keywords: differential gene expression, DGE, RNA, RNA-Seq, transcriptomics, Degust, voom, limma, Galaxy, Microbial Genomics Virtual Laboratory.  This tutorial is about differential gene expression in bacteria, using Galaxy tools and Degust (web).", 
            "title": "Differential Gene Expression"
        }, 
        {
            "location": "/modules/dge/#background", 
            "text": "Differential Gene Expression (DGE) is the process of determining whether any genes were expressed at a different level between two conditions. For example, the conditions could be wildtype versus mutant, or two growth conditions. Usually multiple biological replicates are done for each condition - these are needed to separate variation within the condition from that between the conditions.", 
            "title": "Background"
        }, 
        {
            "location": "/modules/dge/#learning-objectives", 
            "text": "At the end of this tutorial you should be able to:   Align RNA-Seq data to a reference genome    Count transcripts for each sample  Perform statistical analysis to obtain a list of differentially expressed genes  Visualize and interpret the results", 
            "title": "Learning Objectives"
        }, 
        {
            "location": "/modules/dge/#input-data-reads-and-reference", 
            "text": "RNA-Seq reads  A typical experiment will have 2 conditions each with 3 replicates, for a total of 6 samples.   Our RNA-seq reads are from 6 samples in  FASTQ  format.  We have single-end reads; so one file per sample.  Data could also be paired-end reads, and there would be two files per sample.    These have been reduced to 1% of their original size for this tutorial.  The experiment used the bacteria  E. coli  grown in two conditions.  Files labelled  LB  are the wildtype  Files labelled  MG  have been exposed to 0.5%  MG - alpha methyglucoside (a sugar solution).      Reference genome  The reference genomes is in  FASTA  format and the gene annotations are in  GTF  format.   The  FASTA  file contains the DNA sequence(s) that make up the genome; e.g. the chromosome and any plasmids.  The  GTF  file lists the coordinates (position) of each feature. Commonly-annotated features are genes, transcripts and protein-coding sequences.    Upload files to Galaxy   Log in to your Galaxy server.  In the  History  pane, click on the cog icon, and select  Import from File  (at the bottom of the list).  Under  Archived History URL  paste: https://swift.rc.nectar.org.au:8888/v1/AUTH_377/public/Microbial_tutorials/Galaxy-History-BacterialDGE.tar.gz  In the  History  pane, click on the view icon and find the uploaded history.  (This may take a minute. Refresh the page.)    Click  Switch to  that history, then  Done .  The files should now be ready to use in your current History pane.", 
            "title": "Input data: reads and reference"
        }, 
        {
            "location": "/modules/dge/#align-reads-to-reference", 
            "text": "The RNA-Seq reads are fragmented and are not complete transcripts. To determine the transcripts from which the reads originated (and therefore, to which gene they correspond) we can map them to a reference genome.  In Galaxy:   Go to  Tools   NGS Analysis   NGS: Mapping   Map with BWA-MEM  Under  Will you select a reference genome from your history or use a built-in index? :  Use a genome from history and build index  Use the following dataset as the reference sequence :  Ecoli_k12.fasta  Single or Paired-end reads :  single  Select fastq dataset :  Click on the  Multiple Datasets  icon in centre  Select all 6  FASTQ  files (they turn blue; use side-scroll bar to check all have been selected)  This will map each set of reads to the reference genome     Your tool interface should look like this:    Click  Execute  Click  Refresh  in the history pane to see if the analysis has finished.   Output: 6  bam  files of reads mapped to the reference genome.    Re-name the output files:   These are called  Map with BWA-MEM on data x and data x .  Click on the pencil icon next to each of these and re-name them as their sample name (e.g. LB1, LB2 etc.).  Click  Save .", 
            "title": "Align reads to reference"
        }, 
        {
            "location": "/modules/dge/#count-reads-per-gene", 
            "text": "We now need to count how many reads overlap with particular genes. The information about gene names is from the annotations in the GTF file.  In Galaxy:   Go to  Tools   NGS Analysis   NGS: RNA Analysis   SAM/BAM to count matrix .  Note: Don t select the tool called  htseq-count . The  SAM/BAM to count matrix  also uses that tool but allows an input of multiple bam files, which is what we want.    For  Gene model (GFF) file to count reads over from your current history , select the  GTF  file.  For  Reads are stranded  select  Yes  (box turns dark grey)  For  GTF feature type for counting reads  select  transcript .  For  bam/sam file from your history  choose the 6  bam  files.   Your tool interface should look like this:    Click  Execute  Click  Refresh  in the history pane to see if the analysis has finished.   Output:   There is one output file:  bams to DGE count matrix .  Click on the file name to expand the information in the History pane.  Click on the file  icon underneath to download it to your computer for use later on in this tutorial.  Click on the eye icon to see this file.     Each row is a gene (or feature) and each column is a sample, with counts against each gene.  Have a look at how the counts vary between samples, per gene.  We can t just compare the counts directly; they need to be normalized before comparison, and this will be done as part of the DGE analysis in the next step.", 
            "title": "Count reads per gene"
        }, 
        {
            "location": "/modules/dge/#dge-in-degust", 
            "text": "Degust is a tool on the web that can analyse the counts files produced in the step above, to test for differential gene expression.  (Degust can also display the results from DGE analyses performed elsewhere.)", 
            "title": "DGE in Degust"
        }, 
        {
            "location": "/modules/dge/#upload-counts-file", 
            "text": "Go to the  Degust web page . Click  Get Started .    Click on  Choose File .  Select the  htseq output file. tabular  (that you previously downloaded to your computer from Galaxy) and click  Open .  Click  Upload .   A Configuation page will appear.   For  Name  type  DGE in E coli  For  Info columns  select  Contig  For  Analyze server side  leave box checked.  For  Min read count  put  10 .  Click  Add condition  Add a condition called  Control  and select the LB columns.  Add a condition called  Treament  and select the MG columns.     Your Configuration page should look like this:    Save changes  View  - this brings up the Degust viewing window.", 
            "title": "Upload counts file"
        }, 
        {
            "location": "/modules/dge/#overview-of-degust-sections", 
            "text": "Top black panel with  Configure  settings at right.  Left: Conditions: Control and Treatment.  Left: Method selection for DGE.  Top centre: Plots, with options at right.  When either of the expression plots are selected, a heatmap appears below.  A table of genes (or features); expression in treatment relative to control (Treatment column); and significance (FDR column).", 
            "title": "Overview of Degust sections"
        }, 
        {
            "location": "/modules/dge/#analyze-gene-expression", 
            "text": "Under  Method , make sure that  Voom/Limma  is selected.  Click  Apply . This runs Voom/Limma on the uploaded counts.", 
            "title": "Analyze gene expression"
        }, 
        {
            "location": "/modules/dge/#mds-plot", 
            "text": "First, look at the MDS plot.    This is a multidimensional scaling plot which represents the variation between samples.  Ideally:  All the LB samples would be close to each other  All the MG samples would be close to each other  The LB and MG groups would be far apart    The x-axis is the dimension with the highest magnitude. The control/treatment samples should be split along this axis.  Our LB samples are on the left and the MG samples are on the right, which means they are well separated on their major MDS dimension, which looks correct.", 
            "title": "MDS plot"
        }, 
        {
            "location": "/modules/dge/#expression-ma-plot", 
            "text": "Each dot shows the change in expression in one gene.   The average expression (over both condition and treatment samples) is represented on the x-axis.  Plot points should be symmetrical around the x-axis.  We can see that many genes are expressed at a low level, and some are highly expressed.    The fold change is represented on the y axis.  If expression is significantly different between treatment and control, the dots are red. If not, they are blue. (In Degust, significant means FDR  0.05).  At low levels of gene expression (low values of the x axis), fold changes are less likely to be significant.     Click on the dot to see the gene name.", 
            "title": "Expression - MA plot"
        }, 
        {
            "location": "/modules/dge/#expression-parallel-coordinates-and-heatmap", 
            "text": "Each line shows the change in expression in one gene, between control and treatment.   Go to  Options  at the right.  For  FDR cut-off  set at 0.001.  This is a significance level (an adjusted p value). We will set it quite low in this example, to ensure we only examine key differences.     Look at the Parallel Coordinates plot. There are two axes:   Left:  Control : Gene expression in the control samples. All values are set at zero.  Right:  Treatment  Gene expression in the treatment samples, relative to expression in the control.     The blocks of blue and red underneath the plot are called a heatmap.   Each block is a gene. Click on a block to see its line in the plot above.  Look at the row for the Treatment. Relative to the control, genes expressed more are red; genes expressed less are blue.      Note:   for an experiment with multiple treatments, the various treatment axes can be dragged to rearrange. There is no natural order (such as a time series).", 
            "title": "Expression - Parallel Coordinates and heatmap"
        }, 
        {
            "location": "/modules/dge/#table-of-genes", 
            "text": "Contig : names of genes. Note that gene names are sometimes specific to a species, or they may be only named as a locus ID (a chromosomal location specified in the genome annotation).  FDR : False Discovery Rate. This is an adjusted p value to show the significance of the difference in gene expression between two conditions. Click on column headings to sort. By default, this table is sorted by FDR.  Control  and  Treatment : log2(Fold Change) of gene expression. The default display is of fold change in the treatment relative to the control. Therefore, values in the  Control  column are zero. This can be changed in the  Options  panel at the top right.  In some cases, a large fold change will be meaningful but in others, even a small fold change can be important biologically.   Table of genes and expression:", 
            "title": "Table of genes"
        }, 
        {
            "location": "/modules/dge/#dge-in-galaxy", 
            "text": "Differential gene expression can also be analyzed in Galaxy. The input is the count matrix produced by a tool such as HTSeq-Count (see section above:  Count reads per gene ).   Go to  Tools   NGS Analysis   NGS: RNA Analysis   Differential Count models  This has options to use edgeR, DESeq, or Voom. Here we will use Voom.    For  Select an input matrix  choose the  count matrix  file generated in the previous step.  For  Title for job outputs  enter  DGE using voom .  For  Select columns containing treatment  tick boxes for the MG samples.  For  Select columns containing control  tick boxes for the LB samples.  Under  Run this model using edgeR  choose  Do not run edgeR .  Under  Run the same model with DESeq2 and compare findings  choose  Do not run DESeq2 .  Under  Run the same model with Voom/limma and compare findings  choose  Run VOOM .   Your tool interface should look like this:    Click  Execute .   There are two output files.  View the file called  DGEusingvoom.html .   Scroll down to  VOOM log output  and  #VOOM top 50 .  The  Contig  column has the gene names.  Look at the  adj.P.Val  column. This is an adjusted p value to show the significance of the gene expression difference, accounting for the effect of multiple testing. Also known as False Discovery Rate. The table is ordered by the values in this column.  Look at the  logFC  column. This is log2(Fold Change) of relative gene expression between the treatment samples and the control samples.   View the file called  DEGusingvoom_topTable_VOOM.xls .   This is a list of all the genes that had transcripts mapped, and associated statistics.", 
            "title": "DGE in Galaxy"
        }, 
        {
            "location": "/modules/dge/#what-next", 
            "text": "To learn more about the differentially-expressed genes:   Go to  the NCBI website.  Under  All Databases , click on  Gene  Enter the gene name in the search bar; e.g. ptsG  Click on the first result that matches the species (e.g. in this case,  E. coli ).  This provides information about the gene, and may also show further references (e.g. in this case, a link to the EcoGene resource).     Some of the most (statistically) significant differentially-expressed genes in this experiment are:   ptsG : a glucose-specific transporter.  setA : a sugar efflux transporter; is induced by glucose-phosphate stress.  sucD : the alpha subunit of the the gene for succinyl-CoA synthetase; involved in ATP production.  sucB : a component of the 2-oxoglutarate dehydrogenase complex; catalyzes a step in the Krebs cycle.  deoC : 2-deoxyribose-5-phosphate aldolase; binds selenium; may be involved in selenium transport.   Next steps: Investigate the biochemical pathways involving the genes of interest.", 
            "title": "What next?"
        }, 
        {
            "location": "/modules/dge/#more-information", 
            "text": "Link to Degust.  Link to Voom paper.", 
            "title": "More information"
        }, 
        {
            "location": "/modules/kallisto/", 
            "text": "DGE using kallisto\n\n\nThis tutorial is about differential gene expression in bacteria, using tools on the command-line tools (kallisto) and the web (Degust).\n\n\nBackground\n\n\nDifferential Gene Expression (DGE) is the process of determining whether any genes were expressed at a different level between two conditions. For example, the conditions could be wildtype versus mutant, or the same sample from two growth conditions. Usually multiple biological replicates are done for each condition - these are needed to separate variation within the condition from that between the conditions.\n\n\nThere are several ways to test for DGE. All involve these steps:\n\n\n\n\nmap/align reads to transcripts\n\n\ncount number of reads per transcript\n\n\nsee if counts differ between conditions\n\n\n\n\nSome tools will combine two of these steps. For example, options include:\n\n\n\n\n\n\nMap reads to reference genome with BWA-MEM, count reads per transcript with HTSeq-count, examine DGE using voom/limma (within Galaxy or Degust).\n\n\n\n\n\n\nPseudo-align reads to a reference transcriptome and count, using kallisto, then examine DGE using voom/limma (within Galaxy or Degust).\n\n\n\n\n\n\n\n\n\nLearning Objectives\n\n\nAt the end of this tutorial you should be able to:\n\n\n\n\n(Pseudo-)align RNA-Seq data to a reference transcriptome and count: kallisto  \n\n\nPerform statistical analysis to obtain a list of differentially expressed genes: Degust\n\n\nVisualize and interpret the results\n\n\n\n\nRNA-Seq reads\n\n\nA typical experiment will have 2 conditions each with 3 replicates, for a total of 6 samples.\n\n\n\n\nOur RNA-seq reads are from 6 samples in \nFASTQ\n format.\n\n\nWe have single-end reads; so one file per sample.\n\n\nData could also be paired-end reads, and there would be two files per sample.\n\n\n\n\n\n\nThese have been reduced to 1% of their original size for this tutorial.\n\n\nThe experiment used the bacteria \nE. coli\n grown in two conditions.\n\n\nFiles labelled \nLB\n are the wildtype\n\n\nFiles labelled \nMG\n have been exposed to 0.5% \nMG - alpha methyglucoside (a sugar solution).\n\n\n\n\n\n\n\n\nThe files are from \nStudy PRJNA194149 from EBI ENA\n. We are using 3 FASTQ files from the control set (SRR794833-835) and 3 FASTQ files from the experimental condition set (SRR794848-850).\n\n\nGet data\n\n\nLogin to your GVL. \ne.g.\n:\n\n\nssh your_username@gvl.genome.edu.au\n\nenter your password\n\n\n\n\n\n\nGet the files:\n\n\nwget https://swift.rc.nectar.org.au:8888/v1/AUTH_377/public/Microbial_tutorials/Ecoli_kallisto_files.tar.gz\n\n\n\n\n\nUncompress and extract the files:\n\n\ntar -zxvf Ecoli_kallisto_files.tar.gz\n\n\n\n\n\nMove into the new directory:\n\n\ncd Ecoli_kallisto_files\n\n\n\n\n\nYou should have the following files:\n\n\n\n\n6 x RNA-seq reads in \nfastq.gz\n\n\n1 x reference transcriptome in \n.fasta\n\n\n1 x table of features in \n.tsv\n\n\n\n\nThe reference transcriptome and features table have been produced from a genbank file, using a custom \npython script\n.\n\n\nWe need to count the number of RNA-seq reads (that exist as fragments) that match different transcripts in the genome, including those for protein-coding sequences (such as genes) and RNA sequences (such as tRNA and mRNA). Therefore, we need a subset of the whole genome - the reference transcriptome.  \n\n\n\n\n\nGenerate counts\n\n\nKallisto will count the reads per transcript.\n\n\nIndex the transcripts file\n\n\nkallisto index -i transcripts.idx Ecoli_transcripts.fasta\n\n\n\n\n\n\n\ntranscripts.idx\n: the name of the output index file\n\n\ntranscripts.ffn\n: the name of the input fasta file file\n\n\n\n\nRun kallisto for every read set\n\n\nFirst, run kallisto for the \nLB1.fastq.gz\n reads:\n\n\nkallisto quant -i transcripts.idx -o LB1 --single -l \n500\n -s \n50\n LB1.fastq.gz\n\n\n\n\n\n\n\n-o LB1: LB1 will be name of the output folder produced from this analysis\n\n\nsingle : single-end reads\n\n\n-l : estimated length of library fragments \n\n\n-s : estimated standard deviation of library fragments\n\n\nLB1.fastq.gz\n : input FASTQ file\n\n\n\n\nRepeat for every FASTQ file (LB2, LB3, MG1, MG2, MG3).\n\n\n\n\nRun as above, but change the name of the output folder, and the file name at the end.\n\n\nWe then need to combine all the counts into one table.\n\n\n\n\nExtract required columns\n\n\nEach output folder includes an \nabundance.tsv\n file. For each of these files, extract the column of counts (column 4) and remove the table heading.\n\n\ncut -f4 -d\n$\n\\t\n abundance.tsv \n|\n tail -n +2 \n LB1_headless.tsv\n\n\n\n\n\nThis cuts column 4, then removes the header, and saves as \nLB1_headless.tsv\n.\n\n\nThen add column heading \nLB1\n and saves as \nLB1.tsv\n:\n\n\necho\n -e \nLB1\n \n|\n cat - LB1_headless.tsv \n LB1.tsv\n\n\n\n\n\nMove \nLB1.tsv\n into the main analysis folder.\n\n\nRepeat with all the other \nabundance.tsv\n files from the kallisto analyses, giving the tables the correct LBx or MGx header.\n\n\nPaste together with features table\n\n\npaste LB1.tsv LB2.tsv LB3.tsv MG1.tsv MG2.tsv MG3.tsv Ecoli_features.tsv \n counts.tsv\n\n\n\n\n\nExamine the file:\n\n\nless counts.tsv\n\n\n\n\n\nThere should be a column for every set of RNA-Seq reads, and then several columns of information including feature, name and description.\n\n\nDownload the \ncounts.tsv\n file to your local computer.\n\n\nTest for DGE\n\n\nDegust is a tool on the web that can analyse the counts files produced in the step above, to test for differential gene expression.\n\n\n(Degust can also display the results from DGE analyses performed elsewhere.)\n\n\nUpload counts file\n\n\nGo to the \nDegust web page\n. Click \nGet Started\n.\n\n\n\n\n\n\nClick on \nChoose File\n.\n\n\nSelect the \ncounts.tsv\n and click \nOpen\n.\n\n\nClick \nUpload\n.\n\n\n\n\nA Configuation page will appear.\n\n\n\n\nFor \nName\n type \nDGE in E coli\n\n\nFor \nInfo columns\n select \nname\n  \n\n\nFor \nEC Number column\n select \nEC\n\n\nFor \nAnalyze server side\n leave box checked.\n\n\nFor \nMin read count\n put \n10\n\n\nClick \nAdd condition\n\n\nUnder \n Replicates\n, select LB1, LB2, LB3.\n\n\n\n\n\n\nClick \nAdd condition\n again\n\n\nUnder \n Replicates\n, select MG1, MG2, MG3.\n\n\n\n\n\n\nSave changes\n  \n\n\nView\n - this brings up the Degust viewing window.\n\n\n\n\nOverview of Degust sections\n\n\n\n\nTop black panel with \nConfigure\n settings at right.\n\n\nLeft: Conditions: LB (control) and MG (treatment).\n\n\nLeft: Method selection for DGE.\n\n\nTop centre: Plots, with options at right.\n\n\nWhen either of the expression plots are selected, a heatmap appears below.\n\n\nA table of genes (or features); expression in treatment relative to control (Treatment column); and significance (FDR column).  \n\n\n\n\n\n\nAnalyze gene expression\n\n\n\n\nUnder \nMethod\n, make sure that \nVoom/Limma\n is selected.\n\n\nClick \nApply\n. This runs Voom/Limma on the uploaded counts.\n\n\n\n\nMDS plot\n\n\nFirst, look at the MDS plot.\n\n\n\n\n\n\nThis is a multidimensional scaling plot which represents the variation between samples.\n\n\nIdeally:\n\n\nAll the LB samples would be close to each other\n\n\nAll the MG samples would be close to each other\n\n\nThe LB and MG groups would be far apart\n\n\n\n\n\n\nThe x-axis is the dimension with the highest magnitude. The control/treatment samples should be split along this axis.\n\n\nOur LB samples are on the left and the MG samples are on the right, which means they are well separated on their major MDS dimension, which looks correct.\n\n\n\n\nExpression - MA plot\n\n\nEach dot shows the change in expression in one gene.\n\n\n\n\nThe average expression (over both condition and treatment samples) is represented on the x-axis.\n\n\nPlot points should be symmetrical around the x-axis.\n\n\nWe can see that many genes are expressed at a low level, and some are highly expressed.\n\n\n\n\n\n\nThe fold change is represented on the y axis.\n\n\nIf expression is significantly different between treatment and control, the dots are red. If not, they are blue. (In Degust, significant means FDR \n0.05).\n\n\nAt low levels of gene expression (low values of the x axis), fold changes are less likely to be significant.\n\n\n\n\n\n\n\n\nClick on the dot to see the gene name.     \n\n\n\n\nExpression - Parallel Coordinates and heatmap\n\n\nEach line shows the change in expression in one gene, between control and treatment.\n\n\n\n\nGo to \nOptions\n at the right.\n\n\nFor \nFDR cut-off\n set at 0.001.\n\n\nThis is a significance level (an adjusted p value). We will set it quite low in this example, to ensure we only examine key differences.\n\n\n\n\n\n\n\n\nLook at the Parallel Coordinates plot. There are two axes:\n\n\n\n\nLeft: \nLB\n: Gene expression in the control samples. All values are set at zero.\n\n\nRight: \nMG\n Gene expression in the treatment samples, relative to expression in the control.\n\n\n\n\n\n\n\n\nThe blocks of blue and red underneath the plot are called a heatmap.\n\n\n\n\nEach block is a gene. Click on a block to see its line in the plot above.\n\n\nLook at the row for the Treatment. Relative to the control, genes expressed more are red; genes expressed less are blue.\n\n\n\n\n\n\n\n\n\n\nNote:\n\n\n\n\nfor an experiment with multiple treatments, the various treatment axes can be dragged to rearrange. There is no natural order (such as a time series).\n\n\n\n\nTable of genes\n\n\n\n\nname\n: names of genes. Note that gene names are sometimes specific to a species, or they may be only named as a locus ID (a chromosomal location specified in the genome annotation).\n\n\nFDR\n: False Discovery Rate. This is an adjusted p value to show the significance of the difference in gene expression between two conditions. Click on column headings to sort. By default, this table is sorted by FDR.\n\n\nLB\n and \nMG\n: log2(Fold Change) of gene expression. The default display is of fold change in the treatment (MG) relative to the control (LB). Therefore, values in the \nLB\n column are zero. This can be changed in the \nOptions\n panel at the top right.\n\n\nIn some cases, a large fold change will be meaningful but in others, even a small fold change can be important biologically.\n\n\n\n\nKegg Pathway\n\n\nA pathway is a drawn network to show the interaction between molecules, including some or all of genes, proteins, RNAs, chemical reactions.\n\n\n\n\nClick on Kegg Pathway, and select \nGlycolysis\n.\n\n\n\n\n\n\n\n\nGenes in this pathway will be highlighted as you hover over them elsewhere in Degust (e.g., in the table).\n\n\n\n\nWhat next?\n\n\nTo learn more about the differentially-expressed genes:\n\n\n\n\nGo to \nthe NCBI website.\n\n\nUnder \nAll Databases\n, click on \nGene\n\n\nEnter the gene name in the search bar; e.g. ptsG\n\n\nClick on the first result that matches the species (e.g. in this case, \nE. coli\n).\n\n\nThis provides information about the gene, and may also show further references (e.g. in this case, a link to the EcoGene resource).\n\n\n\n\n\n\n\n\nNext steps: Investigate the biochemical pathways involving the genes of interest.\n\n\nLinks\n\n\n\n\n\n\nKallisto paper\n\n\n\n\n\n\nKallisto + sleuth paper\n. Sleuth can test for differential gene expression.\n\n\n\n\n\n\nLink to Voom paper", 
            "title": "Differential gene expression using Kallisto and Degust"
        }, 
        {
            "location": "/modules/kallisto/#dge-using-kallisto", 
            "text": "This tutorial is about differential gene expression in bacteria, using tools on the command-line tools (kallisto) and the web (Degust).", 
            "title": "DGE using kallisto"
        }, 
        {
            "location": "/modules/kallisto/#background", 
            "text": "Differential Gene Expression (DGE) is the process of determining whether any genes were expressed at a different level between two conditions. For example, the conditions could be wildtype versus mutant, or the same sample from two growth conditions. Usually multiple biological replicates are done for each condition - these are needed to separate variation within the condition from that between the conditions.  There are several ways to test for DGE. All involve these steps:   map/align reads to transcripts  count number of reads per transcript  see if counts differ between conditions   Some tools will combine two of these steps. For example, options include:    Map reads to reference genome with BWA-MEM, count reads per transcript with HTSeq-count, examine DGE using voom/limma (within Galaxy or Degust).    Pseudo-align reads to a reference transcriptome and count, using kallisto, then examine DGE using voom/limma (within Galaxy or Degust).", 
            "title": "Background"
        }, 
        {
            "location": "/modules/kallisto/#learning-objectives", 
            "text": "At the end of this tutorial you should be able to:   (Pseudo-)align RNA-Seq data to a reference transcriptome and count: kallisto    Perform statistical analysis to obtain a list of differentially expressed genes: Degust  Visualize and interpret the results", 
            "title": "Learning Objectives"
        }, 
        {
            "location": "/modules/kallisto/#rna-seq-reads", 
            "text": "A typical experiment will have 2 conditions each with 3 replicates, for a total of 6 samples.   Our RNA-seq reads are from 6 samples in  FASTQ  format.  We have single-end reads; so one file per sample.  Data could also be paired-end reads, and there would be two files per sample.    These have been reduced to 1% of their original size for this tutorial.  The experiment used the bacteria  E. coli  grown in two conditions.  Files labelled  LB  are the wildtype  Files labelled  MG  have been exposed to 0.5%  MG - alpha methyglucoside (a sugar solution).     The files are from  Study PRJNA194149 from EBI ENA . We are using 3 FASTQ files from the control set (SRR794833-835) and 3 FASTQ files from the experimental condition set (SRR794848-850).", 
            "title": "RNA-Seq reads"
        }, 
        {
            "location": "/modules/kallisto/#get-data", 
            "text": "Login to your GVL.  e.g. :  ssh your_username@gvl.genome.edu.au enter your password   Get the files:  wget https://swift.rc.nectar.org.au:8888/v1/AUTH_377/public/Microbial_tutorials/Ecoli_kallisto_files.tar.gz  Uncompress and extract the files:  tar -zxvf Ecoli_kallisto_files.tar.gz  Move into the new directory:  cd Ecoli_kallisto_files  You should have the following files:   6 x RNA-seq reads in  fastq.gz  1 x reference transcriptome in  .fasta  1 x table of features in  .tsv   The reference transcriptome and features table have been produced from a genbank file, using a custom  python script .  We need to count the number of RNA-seq reads (that exist as fragments) that match different transcripts in the genome, including those for protein-coding sequences (such as genes) and RNA sequences (such as tRNA and mRNA). Therefore, we need a subset of the whole genome - the reference transcriptome.", 
            "title": "Get data"
        }, 
        {
            "location": "/modules/kallisto/#generate-counts", 
            "text": "Kallisto will count the reads per transcript.", 
            "title": "Generate counts"
        }, 
        {
            "location": "/modules/kallisto/#index-the-transcripts-file", 
            "text": "kallisto index -i transcripts.idx Ecoli_transcripts.fasta   transcripts.idx : the name of the output index file  transcripts.ffn : the name of the input fasta file file", 
            "title": "Index the transcripts file"
        }, 
        {
            "location": "/modules/kallisto/#run-kallisto-for-every-read-set", 
            "text": "First, run kallisto for the  LB1.fastq.gz  reads:  kallisto quant -i transcripts.idx -o LB1 --single -l  500  -s  50  LB1.fastq.gz   -o LB1: LB1 will be name of the output folder produced from this analysis  single : single-end reads  -l : estimated length of library fragments   -s : estimated standard deviation of library fragments  LB1.fastq.gz  : input FASTQ file   Repeat for every FASTQ file (LB2, LB3, MG1, MG2, MG3).   Run as above, but change the name of the output folder, and the file name at the end.  We then need to combine all the counts into one table.", 
            "title": "Run kallisto for every read set"
        }, 
        {
            "location": "/modules/kallisto/#extract-required-columns", 
            "text": "Each output folder includes an  abundance.tsv  file. For each of these files, extract the column of counts (column 4) and remove the table heading.  cut -f4 -d $ \\t  abundance.tsv  |  tail -n +2   LB1_headless.tsv  This cuts column 4, then removes the header, and saves as  LB1_headless.tsv .  Then add column heading  LB1  and saves as  LB1.tsv :  echo  -e  LB1   |  cat - LB1_headless.tsv   LB1.tsv  Move  LB1.tsv  into the main analysis folder.  Repeat with all the other  abundance.tsv  files from the kallisto analyses, giving the tables the correct LBx or MGx header.", 
            "title": "Extract required columns"
        }, 
        {
            "location": "/modules/kallisto/#paste-together-with-features-table", 
            "text": "paste LB1.tsv LB2.tsv LB3.tsv MG1.tsv MG2.tsv MG3.tsv Ecoli_features.tsv   counts.tsv  Examine the file:  less counts.tsv  There should be a column for every set of RNA-Seq reads, and then several columns of information including feature, name and description.  Download the  counts.tsv  file to your local computer.", 
            "title": "Paste together with features table"
        }, 
        {
            "location": "/modules/kallisto/#test-for-dge", 
            "text": "Degust is a tool on the web that can analyse the counts files produced in the step above, to test for differential gene expression.  (Degust can also display the results from DGE analyses performed elsewhere.)", 
            "title": "Test for DGE"
        }, 
        {
            "location": "/modules/kallisto/#upload-counts-file", 
            "text": "Go to the  Degust web page . Click  Get Started .    Click on  Choose File .  Select the  counts.tsv  and click  Open .  Click  Upload .   A Configuation page will appear.   For  Name  type  DGE in E coli  For  Info columns  select  name     For  EC Number column  select  EC  For  Analyze server side  leave box checked.  For  Min read count  put  10  Click  Add condition  Under   Replicates , select LB1, LB2, LB3.    Click  Add condition  again  Under   Replicates , select MG1, MG2, MG3.    Save changes     View  - this brings up the Degust viewing window.", 
            "title": "Upload counts file"
        }, 
        {
            "location": "/modules/kallisto/#overview-of-degust-sections", 
            "text": "Top black panel with  Configure  settings at right.  Left: Conditions: LB (control) and MG (treatment).  Left: Method selection for DGE.  Top centre: Plots, with options at right.  When either of the expression plots are selected, a heatmap appears below.  A table of genes (or features); expression in treatment relative to control (Treatment column); and significance (FDR column).", 
            "title": "Overview of Degust sections"
        }, 
        {
            "location": "/modules/kallisto/#analyze-gene-expression", 
            "text": "Under  Method , make sure that  Voom/Limma  is selected.  Click  Apply . This runs Voom/Limma on the uploaded counts.", 
            "title": "Analyze gene expression"
        }, 
        {
            "location": "/modules/kallisto/#mds-plot", 
            "text": "First, look at the MDS plot.    This is a multidimensional scaling plot which represents the variation between samples.  Ideally:  All the LB samples would be close to each other  All the MG samples would be close to each other  The LB and MG groups would be far apart    The x-axis is the dimension with the highest magnitude. The control/treatment samples should be split along this axis.  Our LB samples are on the left and the MG samples are on the right, which means they are well separated on their major MDS dimension, which looks correct.", 
            "title": "MDS plot"
        }, 
        {
            "location": "/modules/kallisto/#expression-ma-plot", 
            "text": "Each dot shows the change in expression in one gene.   The average expression (over both condition and treatment samples) is represented on the x-axis.  Plot points should be symmetrical around the x-axis.  We can see that many genes are expressed at a low level, and some are highly expressed.    The fold change is represented on the y axis.  If expression is significantly different between treatment and control, the dots are red. If not, they are blue. (In Degust, significant means FDR  0.05).  At low levels of gene expression (low values of the x axis), fold changes are less likely to be significant.     Click on the dot to see the gene name.", 
            "title": "Expression - MA plot"
        }, 
        {
            "location": "/modules/kallisto/#expression-parallel-coordinates-and-heatmap", 
            "text": "Each line shows the change in expression in one gene, between control and treatment.   Go to  Options  at the right.  For  FDR cut-off  set at 0.001.  This is a significance level (an adjusted p value). We will set it quite low in this example, to ensure we only examine key differences.     Look at the Parallel Coordinates plot. There are two axes:   Left:  LB : Gene expression in the control samples. All values are set at zero.  Right:  MG  Gene expression in the treatment samples, relative to expression in the control.     The blocks of blue and red underneath the plot are called a heatmap.   Each block is a gene. Click on a block to see its line in the plot above.  Look at the row for the Treatment. Relative to the control, genes expressed more are red; genes expressed less are blue.      Note:   for an experiment with multiple treatments, the various treatment axes can be dragged to rearrange. There is no natural order (such as a time series).", 
            "title": "Expression - Parallel Coordinates and heatmap"
        }, 
        {
            "location": "/modules/kallisto/#table-of-genes", 
            "text": "name : names of genes. Note that gene names are sometimes specific to a species, or they may be only named as a locus ID (a chromosomal location specified in the genome annotation).  FDR : False Discovery Rate. This is an adjusted p value to show the significance of the difference in gene expression between two conditions. Click on column headings to sort. By default, this table is sorted by FDR.  LB  and  MG : log2(Fold Change) of gene expression. The default display is of fold change in the treatment (MG) relative to the control (LB). Therefore, values in the  LB  column are zero. This can be changed in the  Options  panel at the top right.  In some cases, a large fold change will be meaningful but in others, even a small fold change can be important biologically.", 
            "title": "Table of genes"
        }, 
        {
            "location": "/modules/kallisto/#kegg-pathway", 
            "text": "A pathway is a drawn network to show the interaction between molecules, including some or all of genes, proteins, RNAs, chemical reactions.   Click on Kegg Pathway, and select  Glycolysis .     Genes in this pathway will be highlighted as you hover over them elsewhere in Degust (e.g., in the table).", 
            "title": "Kegg Pathway"
        }, 
        {
            "location": "/modules/kallisto/#what-next", 
            "text": "To learn more about the differentially-expressed genes:   Go to  the NCBI website.  Under  All Databases , click on  Gene  Enter the gene name in the search bar; e.g. ptsG  Click on the first result that matches the species (e.g. in this case,  E. coli ).  This provides information about the gene, and may also show further references (e.g. in this case, a link to the EcoGene resource).     Next steps: Investigate the biochemical pathways involving the genes of interest.", 
            "title": "What next?"
        }, 
        {
            "location": "/modules/kallisto/#links", 
            "text": "Kallisto paper    Kallisto + sleuth paper . Sleuth can test for differential gene expression.    Link to Voom paper", 
            "title": "Links"
        }, 
        {
            "location": "/modules/xtandem/", 
            "text": "Protein identification using X!Tandem\n\n\nIntroduction\n\n\nThe high-throughput nature of proteomics mass spectrometry is enabled by a productive combination of data acquisition protocols and the computational tools used to interpret the resulting spectra (list of peaks). One of the key components in mainstream protocols is the generation of tandem mass (MS/MS) spectra by peptide fragmentation. This approach is currently used in the large majority of proteomics experiments to routinely identify hundreds to thousands of proteins from single mass spectrometry runs. In order to do that multiple tools have to be employed: \nLC-MS/MS\n to segregate components of proteomic samples associated with \nprotein identification\n (see \nFigure 1\n) softwares, \nX!Tandem\n1\n, \nMascot\n or \nSEQUEST\n all of which perform protein identification but with different algorithms.\n\n\n\n\n\n\nFigure 1\n \n \nGeneral overview of the experimental steps and flow of data in protein identification using shotgun proteomics experiment.\n2\n.\n\n\n\n\nFigure 1\n shows a general overview of the experimental steps in protein identification. Sample proteins are first cleaved into peptides, which are then separated using chromatography (e.g. HPLC). The peptides are then ionised and then selected ions are fragmented to produce signature tandem mass spectrometry (MS/MS) spectra. Peptides are identified from the MS/MS spectra by using programs such as X!Tandem, which search against a database of known peptides. Sequences of the identified peptides are used to infer which proteins are present in the original sample.\n\n\nBackground\n\n\nLC-MS/MS Analysis\n\n\nLiquid Chromatography\n (LC) is a technique used to separate molecules in the solvent (mobile phase). Nowadays liquid chromatography utilising high pressure to force the solvent through the columns packed with porous particles (stationary phase) is referred as High Pressure Liquid Chromatography (HPLC) \n see \nFigure 2\n. After purifying the proteomic cell content, LC is able to separate the different proteins which are injected in the mass spectrometer. Each peak from the results will be analysed by mass spectrometry.\n\n\n\n\n\n\nFigure 2\n \n \nSchema of High Pressure Liquid Chromatography (HPLC)\n5\n.\n Compounds of the mixture are separated in the HPLC column according to various parameters (polarity, charge, affinity etc). The type of separation depends on the column being used). A detector flow cell is used to detect the separated compounds band.\n\n\n\n\nMass spectrometry\n (MS) \n see \nFigure 3\n \n has been widely used to analyse biological samples and has evolved into an indispensable tool for proteomics research. Fundamentally, MS measures the mass-to-charge ratio (m/z) of gas-phase ions. Mass spectrometers consist of an ion source that converts analyte molecules into gas-phase ions, a mass analyser that separates ionised analytes on the basis of m/z ratio and a detector that records the number of ions at each m/z value.\n\n\n\n\n\n\nFigure 3\n \n \nSchema of mass specter\n. \nA mass spectrometer consists of three components: an ion source, a mass analyzer, and a detector. The ionizer converts a portion of the sample into ions. There is a wide variety of ionization techniques, depending on the phase (solid, liquid, gas) of the sample and the efficiency of various ionization mechanisms for the unknown species. An extraction system removes ions from the sample, which are then targeted through the mass analyzer and onto the detector. The differences in masses of the fragments allows the mass analyzer to sort the ions by their mass-to-charge ratio. The detector measures the value of an indicator quantity and thus provides data for calculating the abundances of each ion present.\n \n6\n\n\n\n\nTandem mass spectrometry\n (MS/MS) \n see \nFigure 4\n \n is a key technique for protein or peptide sequencing and post-translational modifications analysis. Collision-induced dissociation (CID) has been the most widely used MS/MS technique in proteomics research. In this method, gas-phase peptide/protein cations are internally heated by multiple collisions with rare gas atoms. The result is fragmented ions that, after the detection phase and reconstitution, reveal the amino-acid chains.\n\n\n\n\n\n\nFigure 4\n \n \nSchema of a tandem mass spectrometry associated with liquid chromatography (LC-MS/MS)\n. This technique combine separation form liquid chromatography and m/z ratio analyse of the tandem mass spectrometry in order to generate spectra.\n\n\n\n\nFile formats\n : During a full proteomics analysis, as seen in \nFigure 5\n, many files are created. Every step has its own multiple file formats:\n\n\n\n\n\n\nFigure 5\n \n \nMultiple formats during MS treatment\n7\n. From the sample processing to the final file, various file formats can be used. This schema shows the different processes and file formats that are generated during a full MS experiment.\n\n\n\n\nFor this tutorial we will focus on the \nInformatics Analysis\n part using the following file formats:\n\n\n\n\nfasta\n: fasta files are mainly used for representing either nucleotide sequences or peptide sequences, using single-letter codes.\n\n\nMGF\n : Mascot Generic Format (MGF) file is the most common format for MS/MS data encoding in the form of a peak list\n8\n. This file encodes multiple MS/MS spectra in a single file listing the [m/z, intensity] pairs separated by headers \n see \nFigure 6\n. More precisely each query represents a complete MS/MS spectrum delimited by BEGIN IONS and END IONS statements. Embedded parameters\n9\n can be found after each BEGIN IONS statement. An example entry is shown in the figure below:\n\n\n\n\n\n\n\n\nFigure 6\n \n \nSample of a MGF file\n. MGF files are used for enconding MS results, multiple spectra can be enconded in one MGF. Every spectrum begins with the \nBEGINS IONS\n assessment and finishes with \nEND IONS\n. MGF files can be divided in 2 parts :\n    \n The header : containing information about the embedded Search Parameters.\n    \n Ions information : the first figure is the ion mass, the second is the ion charge.\n\n\n\n\nX!Tandem\n\n\nX!Tandem\n is an open source software that can match tandem mass spectra (usually the experiment) with peptide sequences from a database. This process allows identification of proteins in one or more samples.\n\n\nThe X!Tandem search engine calculates a statistical confidence (expectation value) for all of the individual spectrum-to-sequence assignments. Some spectra might map to more than one protein, in this case X!Tandem will pick the best match with the highest confidence score (see \nFigure 7\n). The output is a lists all of the high confidence assignments.\n\n\n\n\n\n\nFigure 7\n \n \nSchema of the X!Tandem analysis\n2\n. After LC-MS/MS analysis the experimental spectrum is compared to a theoretical spectrum made from a protein database. This comparison leads to a list of peptide match ranked by score.\n\n\n\n\nGALAXY\n\n\nGALAXY\n3\n is an open source, web-based platform for biomedical research. GALAXY allows users to perform multi-omics data analyses: genomics, proteomics, transcriptomics and more. Numerous tools are available to achieve various analyses. This tutorial will focus on proteomics identification: matching the experimental data, spectra from LC-MS/MS analysis against data from a protein database using X!Tandem.\n\n\nBefore starting, a quick overview of the GALAXY interface \n see \nFigure 8\n. The interface is divided into three parts:\n\n\n\n\nLeft panel\n:  List the tools that are available.  A search textbox is at the top of the panel in order to find the tool you want.\n\n\nRight panel\n: Is the history of all the data outputs from previous steps and subsequently becoming the input for the next step. For example, the figure below shows the data imported ready for the next step. This panel allows the user to follow the different steps of the  analysis.\n\n\nCentral panel\n: Is the main screen, showing the details and options of the selected tool.\n\n\n\n\n\n\n\n\nFigure 8\n \n \nGalaxy interface\n. Divided in 3 parts Galaxy\ns interface go from the left selecting the tools to the right where the results are displayed.\n\n\n\n\n\n\nTutorial\n\n\nThis tutorial describes how to identify a list of proteins from tandem mass spectrometry data.\n\n\nAnalyses of this type are a fundamental part of most proteomics studies. The basic idea is to match tandem MS spectra obtained from a sample with equivalent theoretical spectra against a reference protein database. The process is referred to as \nprotein identification\n, although amino acid sequences are not obtained \nde novo\n with this method.\n\n\nObjectives\n\n\nThe objective of this tutorial is to perform protein identification from MS/MS spectra data using the X!Tandem tool in GALAXY \n see \nFigure 9\n. The basic steps involved are:\n\n\n\n\nLoading UniProt\n4\n proteome data in GALAXY (fasta file format)\n\n\nLoading your MS/MS spectra in GALAXY\n\n\nRun X!Tandem proteomics search\n\n\nSorting and analysing the results\n\n\n\n\nThe tutorial will finish with an exercise where you repeat the same protocol \nbut\n with your own proteome as the reference database instead of using UniProt.\n\n\n\n\n\n\nFigure 9\n - \nGeneral flowchart of this training\n. The first part is to upload datasets to be investigated. Then the training will cover the key parts of the configuration of a X!Tandem search. Finally, we look at sorting and analysing the results.\n\n\n\n\nThe aim of the training will be to create a list of all proteins that can be confidently said to be present in the sample.\n\n\nThis tutorial uses the following open source tools:\n\n\n\n\nX!Tandem search engine\n\n\nTrans Proteomic Pipeline\n11\n\n\nGALAXY platform with tools already installed\n\n\n\n\nThis tutorial uses an \nE. Coli\n MS/MS spectra dataset \ns1-000.RAW.gz\n that has already been converted to MGF format for use in the Galaxy. The MGF data file is over 200MB, instead of downloading it to your computer, you can upload this file into Galaxy directly. Copy this link (https://swift.rc.nectar.org.au:8888/v1/AUTH_377/public/EColi_K12_MS_Spectra.mgf) and follow the instructions below.\n\n\n\n\nNote\n\nIf you downloaded the RAW data (which can be obtained from \nhere\n), you will need to manually convert it to \nMGF\n before it can be used in Galaxy. To convert the file, follow the following steps:\n\n Download and Install \nProteoWizard\n on your local computer. (Note: version - Windows 64-bit installer(able to convert vendor files except T2D)\n\n Start the ProteoWizard software on your local computer with windows operating system.\n* Upload the raw file and convert to mgf format\n\n\n\n\nSTEP 1: Data import\n\n\n\n\nBefore importing data, \nName\n your history. Click on the \nUnnamed history\n on the top of the right panel until you get the cursor. \nDelete\n and \ntype\n in \nProtein Identificaiton E.coli K12\n or a more meaningful name. You \nmust\n \nhit Enter\n, otherwise the name will not be saved.\n\n\n\n\n\n\n\n\nNext, import data into GALAXY. On the left panel click on the \nupload button\n as shown below:\n\n\n\n\n\n\n\n\nA new window will open, where you can select a method to upload your data: \nChoose local file\n, \nChoose FTP file\n or \nPaste/Fetch data\n. Click on \nPaste/Fetch data\n then copy and paste the URL of the mass spectrometer file into the textbox.\n\n\n\n\n\n\nTip\n : You can also use the \nGet Data \n Upload file\n tool to obtain the same result. Here you want to upload your MS/MS spectra.\n\n\n\n\n\n\n\n\nWarning\n : X!Tandem only accepts mgf files in GALAXY.  Other file formats have to be converted beforehand. A useful tool for that is msconvert\n12\n(download : \nhere\n. This tool only working on Windows).\n\n\n\n\nSTEP 2: Import Reference Data\n\n\nWe will first use the UniProt Database as our reference data to search against.\n\n\n\n\nSelect the tool named \nProtein Database Downloader\n\n\nChoose the database: \nUniProtKB\n\n\nSelect the organism of interest: \nEscherichia Coli (strain K12)\n\n\n\n\nClick on \nExecute\n\n\n\n\n\n\nYou will see your history update with the new data imports\n\n\n\n\n\n\n\n\n\n\nRename your \nProtein Database\n by clicking on pencil \n icon.\n\n\nSelect \nEdit Attributes\n\n\nIn \nName\n, type in \nEColi_K12_UniProt_Database\n\n\nClick \nSave\n\n\n\n\n\n\nSTEP 3: X!Tandem MS/MS Search\n\n\nThis part of the tutorial is to perform the X!Tandem MS/MS search.\n\n\n\n\nThe tool can be found in the left panel under the section \nProteomics Tools \n X!Tandem MSMS Search\n\n\nIn the central section, you should see the following options. Below the key parameters are explained in detail.\n\n\n\n\n\n\nX!Tandem proposes many options, the key options of interest are:\n\n\n\n\nUploaded FASTA file\n: this parameter is to select the fasta file that will be used as the proteins database.\n\n\nMSMS File\n : select the spectra file to analyse.\n\n\nVariable Modifications\n: this option considers possible modification on each residue (which impact the MS/MS spectra).\n\n\nFixed Modifications\n: this option allows you to specify any known modification.\n\n\nMissed Cleavages Allowed\n: \nwhen a cleavage reagent (either chemical or enzymatic) is used to cleave the peptide backbone of a protein to produce peptides, different sites along the backbone will have different reaction rates and kinetics. Therefore, there may be some sites that should be cleaved by the reagent that are not completely cleaved during the course of the experiment. The value of this parameter represents the maximum number of missed cleavage sites allowed within a peptide.\n\n\nEnzyme\n: specify the enzyme that has been used to cleave the proteins (affecting the interpretation of the spectrum).\n\n\nFragment ion tolerance\n: define the minimum weight (in Da) of the fragmented ions, default value is 0.5.\n\n\nPrecursor ion tolerance\n: define the minimum weight (in Da) of the precursor ions.\n\n\n\n\nIn this tutorial, we are using the following parameters:\n\n\n\n\n\n\n\n\nParameters Name\n\n\nValue\n\n\nDefault Value\n\n\n\n\n\n\n\n\n\n\nUploaded FASTA file\n\n\nEColi_K12_UniProt_Database\n\n\n\n\n\n\n\n\nMSMS File\n\n\nEColi_K12_MS_Spectra.mgf\n\n\n\n\n\n\n\n\nVariable Modifications\n\n\nOxidation M\n\n\n\n\n\n\n\n\nFixed Modifications\n\n\nCarbamidomethyl C\n\n\n\n\n\n\n\n\nMissed Cleavages Allowed\n\n\n2\n\n\n2\n\n\n\n\n\n\nEnzyme\n\n\nTrypsin\n\n\nTrypsin\n\n\n\n\n\n\nFragment ion tolerance\n\n\n0.5\n\n\n0.5\n\n\n\n\n\n\nPrecursor ion tolerance\n\n\n10 ppm\n\n\n10 ppm\n\n\n\n\n\n\n\n\n\n\nLeave all other parameters as their default settings.\n\n\n\n\nClick on \nExecute\n\n\n\n\n\n\nThe history should update with a new entry, the output file of the X!Tandem\n\n\n\n\nRename the output by clicking on the \n  icon\n\n\n\n\n\n\n\n\nYou can view the output by click on the name in the history panel.\n\n\n\n\nSTEP 4: Convert X!Tandem XML to Table\n\n\nThe output of X!Tandem is an XML format, which is not easy to decipher. In order to get a more readable file, we will convert the XML format to a table. This is a two step process:\n\n\n\n\nSelect \nProteomics Tools \n Tandem to pepXML\n\n\nSelect your \ntandem\n file in the \nInput File\n field\n\n\nClick on \nExecute\n\n\nThe history should update with a new \npepXML\n file. The pepXML file is still a XML file and needs to be converted to a tabular.\n\n\nSelect \nProteomics Tools \n PepXML to Table\n\n\nSelect your \npepXML\n file in the \nInput File\n field\n\n\nThis history should update with a new file\n\n\n\n\n\n\nAfter the X!Tandem search we obtain a list of proteins present in the sample data from Step 1:\n\n\n\n\n\n\n\n\nTabular name\n\n\nTandem file XML designation\n\n\nDefinition\n\n\n\n\n\n\n\n\n\n\nProtein\n\n\nlabel\n\n\nProtein name according to the database used for the MS/MS search\n\n\n\n\n\n\nPeptide\n\n\nseq\n\n\nPeptide sequence\n\n\n\n\n\n\nAssumed_charge\n\n\nz\n\n\nParent ion mass (plus a proton) from the spectrum\n\n\n\n\n\n\nCalc_neutral_pep_mass\n\n\nmh (+mass of a proton)\n\n\nParent ion mass calculated from the spectrum\n\n\n\n\n\n\nNeutral_mass\n\n\nmh (+mass of a proton)\n\n\nCalculated peptide mass (plus a proton)\n\n\n\n\n\n\nRetention_time\n\n\nrt\n\n\nLength of time between injection and position of the target compound peak.\n10\n\n\n\n\n\n\nStart_scan\n\n\nid\n\n\nid of the group treated (where the analysis starts)\n\n\n\n\n\n\nEnd_scan\n\n\nid\n\n\nid of the domain treated (usually the same as start_scan, no consideration of the doted name in the original XML file)\n\n\n\n\n\n\nSearch_engine\n\n\n\n\nName of the search engine used, in our case X!Tandem (associated with the scoring method : \nk-score\n)\n\n\n\n\n\n\nRaw_score\n\n\nexpect\n\n\nExpectation value for the top ranked protein identified with this spectrum\n\n\n\n\n\n\n\n\n\n\nNote:\n You can find all the details on the X!Tandem output file here: \nThe file format for X! series search engines\n. The tandem XML file contains more information than the tabular format which can also be of further use (e.i. the score for the different ions \nx, y, z, a, b, c\n \n)\n\n\n\n\n\n\nReferences\n\n\n\n\n\n\n\n\n\n\nX!Tandem website\n and \nX!Tandem documentation\n. Craig, R., and R. C. Beavis. 2004. \n\u201cTANDEM: matching proteins with tandem mass spectra.\u201d\n Bioinformatics 20, no. 9 (June): 1466-67. http://dx.doi.org/10.1093/bioinformatics/bth092.\n\n\n\n\n\n\nNesvizhskii, Alexey I. \nProtein Identification By Tandem Mass Spectrometry And Sequence Database Searching\n. Mass Spectrometry Data Analysis in Proteomics 87-120.\n \n \nMass Spectrometry Data Analysis in Proteomics\n\n\n\n\n\n\nGALAXY platform : https://usegalaxy.org/. You can also find a more extensive documentation here : https://galaxyproject.org/.\nAfgan, Enis et al. \nThe Galaxy Platform For Accessible, Reproducible And Collaborative Biomedical Analyses: 2016 Update\n. Nucleic Acids Res 44.W1 (2016): W3-W10.\n \n \nThe Galaxy platform for accessible, reproducible and collaborative biomedical analyses: 2016 update\n\n\n\n\n\n\nUniProt : http://www.uniprot.org/. Apweiler, R. \nUniprot: The Universal Protein Knowledgebase\n. Nucleic Acids Research 32.90001 (2004): 115D-119.\n \n \nUniProt: the Universal Protein knowledgebase\n\n\n\n\n\n\nHigh-performance liquid chromatography (HPLC): \nHow Does High Performance Liquid Chromatography Work ?\n Mant, Colin T. et al. \nHPLC Analysis And Purification Of Peptides\n. Peptide Characterization and Application Protocols (2007): 3-55.\n\n\n\n\n\n\nAebersold, Ruedi and Matthias Mann. \nMass Spectrometry-Based Proteomics\n. Nature 422.6928 (2003): 198-207.\n \n \nMass Spectrometry-Based Proteomics\n\n\n\n\n\n\nDeutsch, E. W. \nFile Formats Commonly Used In Mass Spectrometry Proteomics\n. Molecular \n Cellular Proteomics 11.12 (2012): 1612-1621.\n \n \nFile Formats Commonly Used in Mass Spectrometry Proteomics\n\n\n\n\n\n\nMascot Generic Format (MGF) file is likely the most common text format for MS/MS data encoding in the form of a peak list. This file encodes multiple MS/MS spectra in a single file via m/z, intensity pairs separated by headers.\n \n \nMGF file format\n\n\n\n\n\n\nThe MGF format allows parameters that can be found after the BEGIN IONS statement.\n \n \nEmbedded Parameters\n\n\n\n\n\n\nThe retention time of a peak can be used as means of qualitative identification. The length of time between injection and position of the target compound peak.\n \n \nRetention Time Parameters\n\n \n \nRetention Time explained for GC/MS\n\n\n\n\n\n\nThe Trans-Proteomic Pipeline (TPP) website : http://tools.proteomecenter.org/wiki/index.php?title=Software:TPP. Deutsch, Eric W. et al. \nA Guided Tour Of The Trans-Proteomic Pipeline\n. Proteomics 10.6 (2010): 1150-1159.\n \n \nA Guided Tour of the Trans-Proteomic Pipeline\n\n\n\n\n\n\nProteoWizard Tools website : http://proteowizard.sourceforge.net/tools.shtml. Holman, Jerry D., David L. Tabb, and Parag Mallick. \nEmploying Proteowizard To Convert Raw Mass Spectrometry Data\n. Current Protocols in Bioinformatics (2014): 13.24.1-13.24.9.\n\n \nEmploying ProteoWizard to Convert Raw Mass Spectrometry Data", 
            "title": "Protein Identification"
        }, 
        {
            "location": "/modules/xtandem/#protein-identification-using-xtandem", 
            "text": "", 
            "title": "Protein identification using X!Tandem"
        }, 
        {
            "location": "/modules/xtandem/#introduction", 
            "text": "The high-throughput nature of proteomics mass spectrometry is enabled by a productive combination of data acquisition protocols and the computational tools used to interpret the resulting spectra (list of peaks). One of the key components in mainstream protocols is the generation of tandem mass (MS/MS) spectra by peptide fragmentation. This approach is currently used in the large majority of proteomics experiments to routinely identify hundreds to thousands of proteins from single mass spectrometry runs. In order to do that multiple tools have to be employed:  LC-MS/MS  to segregate components of proteomic samples associated with  protein identification  (see  Figure 1 ) softwares,  X!Tandem 1 ,  Mascot  or  SEQUEST  all of which perform protein identification but with different algorithms.    Figure 1     General overview of the experimental steps and flow of data in protein identification using shotgun proteomics experiment. 2 .   Figure 1  shows a general overview of the experimental steps in protein identification. Sample proteins are first cleaved into peptides, which are then separated using chromatography (e.g. HPLC). The peptides are then ionised and then selected ions are fragmented to produce signature tandem mass spectrometry (MS/MS) spectra. Peptides are identified from the MS/MS spectra by using programs such as X!Tandem, which search against a database of known peptides. Sequences of the identified peptides are used to infer which proteins are present in the original sample.", 
            "title": "Introduction"
        }, 
        {
            "location": "/modules/xtandem/#background", 
            "text": "", 
            "title": "Background"
        }, 
        {
            "location": "/modules/xtandem/#lc-msms-analysis", 
            "text": "Liquid Chromatography  (LC) is a technique used to separate molecules in the solvent (mobile phase). Nowadays liquid chromatography utilising high pressure to force the solvent through the columns packed with porous particles (stationary phase) is referred as High Pressure Liquid Chromatography (HPLC)   see  Figure 2 . After purifying the proteomic cell content, LC is able to separate the different proteins which are injected in the mass spectrometer. Each peak from the results will be analysed by mass spectrometry.    Figure 2     Schema of High Pressure Liquid Chromatography (HPLC) 5 .  Compounds of the mixture are separated in the HPLC column according to various parameters (polarity, charge, affinity etc). The type of separation depends on the column being used). A detector flow cell is used to detect the separated compounds band.   Mass spectrometry  (MS)   see  Figure 3    has been widely used to analyse biological samples and has evolved into an indispensable tool for proteomics research. Fundamentally, MS measures the mass-to-charge ratio (m/z) of gas-phase ions. Mass spectrometers consist of an ion source that converts analyte molecules into gas-phase ions, a mass analyser that separates ionised analytes on the basis of m/z ratio and a detector that records the number of ions at each m/z value.    Figure 3     Schema of mass specter .  A mass spectrometer consists of three components: an ion source, a mass analyzer, and a detector. The ionizer converts a portion of the sample into ions. There is a wide variety of ionization techniques, depending on the phase (solid, liquid, gas) of the sample and the efficiency of various ionization mechanisms for the unknown species. An extraction system removes ions from the sample, which are then targeted through the mass analyzer and onto the detector. The differences in masses of the fragments allows the mass analyzer to sort the ions by their mass-to-charge ratio. The detector measures the value of an indicator quantity and thus provides data for calculating the abundances of each ion present.   6   Tandem mass spectrometry  (MS/MS)   see  Figure 4    is a key technique for protein or peptide sequencing and post-translational modifications analysis. Collision-induced dissociation (CID) has been the most widely used MS/MS technique in proteomics research. In this method, gas-phase peptide/protein cations are internally heated by multiple collisions with rare gas atoms. The result is fragmented ions that, after the detection phase and reconstitution, reveal the amino-acid chains.    Figure 4     Schema of a tandem mass spectrometry associated with liquid chromatography (LC-MS/MS) . This technique combine separation form liquid chromatography and m/z ratio analyse of the tandem mass spectrometry in order to generate spectra.   File formats  : During a full proteomics analysis, as seen in  Figure 5 , many files are created. Every step has its own multiple file formats:    Figure 5     Multiple formats during MS treatment 7 . From the sample processing to the final file, various file formats can be used. This schema shows the different processes and file formats that are generated during a full MS experiment.   For this tutorial we will focus on the  Informatics Analysis  part using the following file formats:   fasta : fasta files are mainly used for representing either nucleotide sequences or peptide sequences, using single-letter codes.  MGF  : Mascot Generic Format (MGF) file is the most common format for MS/MS data encoding in the form of a peak list 8 . This file encodes multiple MS/MS spectra in a single file listing the [m/z, intensity] pairs separated by headers   see  Figure 6 . More precisely each query represents a complete MS/MS spectrum delimited by BEGIN IONS and END IONS statements. Embedded parameters 9  can be found after each BEGIN IONS statement. An example entry is shown in the figure below:     Figure 6     Sample of a MGF file . MGF files are used for enconding MS results, multiple spectra can be enconded in one MGF. Every spectrum begins with the  BEGINS IONS  assessment and finishes with  END IONS . MGF files can be divided in 2 parts :\n      The header : containing information about the embedded Search Parameters.\n      Ions information : the first figure is the ion mass, the second is the ion charge.", 
            "title": "LC-MS/MS Analysis"
        }, 
        {
            "location": "/modules/xtandem/#xtandem", 
            "text": "X!Tandem  is an open source software that can match tandem mass spectra (usually the experiment) with peptide sequences from a database. This process allows identification of proteins in one or more samples.  The X!Tandem search engine calculates a statistical confidence (expectation value) for all of the individual spectrum-to-sequence assignments. Some spectra might map to more than one protein, in this case X!Tandem will pick the best match with the highest confidence score (see  Figure 7 ). The output is a lists all of the high confidence assignments.    Figure 7     Schema of the X!Tandem analysis 2 . After LC-MS/MS analysis the experimental spectrum is compared to a theoretical spectrum made from a protein database. This comparison leads to a list of peptide match ranked by score.", 
            "title": "X!Tandem"
        }, 
        {
            "location": "/modules/xtandem/#galaxy", 
            "text": "GALAXY 3  is an open source, web-based platform for biomedical research. GALAXY allows users to perform multi-omics data analyses: genomics, proteomics, transcriptomics and more. Numerous tools are available to achieve various analyses. This tutorial will focus on proteomics identification: matching the experimental data, spectra from LC-MS/MS analysis against data from a protein database using X!Tandem.  Before starting, a quick overview of the GALAXY interface   see  Figure 8 . The interface is divided into three parts:   Left panel :  List the tools that are available.  A search textbox is at the top of the panel in order to find the tool you want.  Right panel : Is the history of all the data outputs from previous steps and subsequently becoming the input for the next step. For example, the figure below shows the data imported ready for the next step. This panel allows the user to follow the different steps of the  analysis.  Central panel : Is the main screen, showing the details and options of the selected tool.     Figure 8     Galaxy interface . Divided in 3 parts Galaxy s interface go from the left selecting the tools to the right where the results are displayed.", 
            "title": "GALAXY"
        }, 
        {
            "location": "/modules/xtandem/#tutorial", 
            "text": "This tutorial describes how to identify a list of proteins from tandem mass spectrometry data.  Analyses of this type are a fundamental part of most proteomics studies. The basic idea is to match tandem MS spectra obtained from a sample with equivalent theoretical spectra against a reference protein database. The process is referred to as  protein identification , although amino acid sequences are not obtained  de novo  with this method.", 
            "title": "Tutorial"
        }, 
        {
            "location": "/modules/xtandem/#objectives", 
            "text": "The objective of this tutorial is to perform protein identification from MS/MS spectra data using the X!Tandem tool in GALAXY   see  Figure 9 . The basic steps involved are:   Loading UniProt 4  proteome data in GALAXY (fasta file format)  Loading your MS/MS spectra in GALAXY  Run X!Tandem proteomics search  Sorting and analysing the results   The tutorial will finish with an exercise where you repeat the same protocol  but  with your own proteome as the reference database instead of using UniProt.    Figure 9  -  General flowchart of this training . The first part is to upload datasets to be investigated. Then the training will cover the key parts of the configuration of a X!Tandem search. Finally, we look at sorting and analysing the results.   The aim of the training will be to create a list of all proteins that can be confidently said to be present in the sample.  This tutorial uses the following open source tools:   X!Tandem search engine  Trans Proteomic Pipeline 11  GALAXY platform with tools already installed   This tutorial uses an  E. Coli  MS/MS spectra dataset  s1-000.RAW.gz  that has already been converted to MGF format for use in the Galaxy. The MGF data file is over 200MB, instead of downloading it to your computer, you can upload this file into Galaxy directly. Copy this link (https://swift.rc.nectar.org.au:8888/v1/AUTH_377/public/EColi_K12_MS_Spectra.mgf) and follow the instructions below.   Note \nIf you downloaded the RAW data (which can be obtained from  here ), you will need to manually convert it to  MGF  before it can be used in Galaxy. To convert the file, follow the following steps:  Download and Install  ProteoWizard  on your local computer. (Note: version - Windows 64-bit installer(able to convert vendor files except T2D)  Start the ProteoWizard software on your local computer with windows operating system.\n* Upload the raw file and convert to mgf format", 
            "title": "Objectives"
        }, 
        {
            "location": "/modules/xtandem/#step-1-data-import", 
            "text": "Before importing data,  Name  your history. Click on the  Unnamed history  on the top of the right panel until you get the cursor.  Delete  and  type  in  Protein Identificaiton E.coli K12  or a more meaningful name. You  must   hit Enter , otherwise the name will not be saved.     Next, import data into GALAXY. On the left panel click on the  upload button  as shown below:     A new window will open, where you can select a method to upload your data:  Choose local file ,  Choose FTP file  or  Paste/Fetch data . Click on  Paste/Fetch data  then copy and paste the URL of the mass spectrometer file into the textbox.    Tip  : You can also use the  Get Data   Upload file  tool to obtain the same result. Here you want to upload your MS/MS spectra.     Warning  : X!Tandem only accepts mgf files in GALAXY.  Other file formats have to be converted beforehand. A useful tool for that is msconvert 12 (download :  here . This tool only working on Windows).", 
            "title": "STEP 1: Data import"
        }, 
        {
            "location": "/modules/xtandem/#step-2-import-reference-data", 
            "text": "We will first use the UniProt Database as our reference data to search against.   Select the tool named  Protein Database Downloader  Choose the database:  UniProtKB  Select the organism of interest:  Escherichia Coli (strain K12)   Click on  Execute    You will see your history update with the new data imports      Rename your  Protein Database  by clicking on pencil   icon.  Select  Edit Attributes  In  Name , type in  EColi_K12_UniProt_Database  Click  Save", 
            "title": "STEP 2: Import Reference Data"
        }, 
        {
            "location": "/modules/xtandem/#step-3-xtandem-msms-search", 
            "text": "This part of the tutorial is to perform the X!Tandem MS/MS search.   The tool can be found in the left panel under the section  Proteomics Tools   X!Tandem MSMS Search  In the central section, you should see the following options. Below the key parameters are explained in detail.    X!Tandem proposes many options, the key options of interest are:   Uploaded FASTA file : this parameter is to select the fasta file that will be used as the proteins database.  MSMS File  : select the spectra file to analyse.  Variable Modifications : this option considers possible modification on each residue (which impact the MS/MS spectra).  Fixed Modifications : this option allows you to specify any known modification.  Missed Cleavages Allowed :  when a cleavage reagent (either chemical or enzymatic) is used to cleave the peptide backbone of a protein to produce peptides, different sites along the backbone will have different reaction rates and kinetics. Therefore, there may be some sites that should be cleaved by the reagent that are not completely cleaved during the course of the experiment. The value of this parameter represents the maximum number of missed cleavage sites allowed within a peptide.  Enzyme : specify the enzyme that has been used to cleave the proteins (affecting the interpretation of the spectrum).  Fragment ion tolerance : define the minimum weight (in Da) of the fragmented ions, default value is 0.5.  Precursor ion tolerance : define the minimum weight (in Da) of the precursor ions.   In this tutorial, we are using the following parameters:     Parameters Name  Value  Default Value      Uploaded FASTA file  EColi_K12_UniProt_Database     MSMS File  EColi_K12_MS_Spectra.mgf     Variable Modifications  Oxidation M     Fixed Modifications  Carbamidomethyl C     Missed Cleavages Allowed  2  2    Enzyme  Trypsin  Trypsin    Fragment ion tolerance  0.5  0.5    Precursor ion tolerance  10 ppm  10 ppm      Leave all other parameters as their default settings.   Click on  Execute    The history should update with a new entry, the output file of the X!Tandem   Rename the output by clicking on the    icon     You can view the output by click on the name in the history panel.", 
            "title": "STEP 3: X!Tandem MS/MS Search"
        }, 
        {
            "location": "/modules/xtandem/#step-4-convert-xtandem-xml-to-table", 
            "text": "The output of X!Tandem is an XML format, which is not easy to decipher. In order to get a more readable file, we will convert the XML format to a table. This is a two step process:   Select  Proteomics Tools   Tandem to pepXML  Select your  tandem  file in the  Input File  field  Click on  Execute  The history should update with a new  pepXML  file. The pepXML file is still a XML file and needs to be converted to a tabular.  Select  Proteomics Tools   PepXML to Table  Select your  pepXML  file in the  Input File  field  This history should update with a new file    After the X!Tandem search we obtain a list of proteins present in the sample data from Step 1:     Tabular name  Tandem file XML designation  Definition      Protein  label  Protein name according to the database used for the MS/MS search    Peptide  seq  Peptide sequence    Assumed_charge  z  Parent ion mass (plus a proton) from the spectrum    Calc_neutral_pep_mass  mh (+mass of a proton)  Parent ion mass calculated from the spectrum    Neutral_mass  mh (+mass of a proton)  Calculated peptide mass (plus a proton)    Retention_time  rt  Length of time between injection and position of the target compound peak. 10    Start_scan  id  id of the group treated (where the analysis starts)    End_scan  id  id of the domain treated (usually the same as start_scan, no consideration of the doted name in the original XML file)    Search_engine   Name of the search engine used, in our case X!Tandem (associated with the scoring method :  k-score )    Raw_score  expect  Expectation value for the top ranked protein identified with this spectrum      Note:  You can find all the details on the X!Tandem output file here:  The file format for X! series search engines . The tandem XML file contains more information than the tabular format which can also be of further use (e.i. the score for the different ions  x, y, z, a, b, c   )", 
            "title": "STEP 4: Convert X!Tandem XML to Table"
        }, 
        {
            "location": "/modules/xtandem/#references", 
            "text": "X!Tandem website  and  X!Tandem documentation . Craig, R., and R. C. Beavis. 2004.  \u201cTANDEM: matching proteins with tandem mass spectra.\u201d  Bioinformatics 20, no. 9 (June): 1466-67. http://dx.doi.org/10.1093/bioinformatics/bth092.    Nesvizhskii, Alexey I.  Protein Identification By Tandem Mass Spectrometry And Sequence Database Searching . Mass Spectrometry Data Analysis in Proteomics 87-120.\n    Mass Spectrometry Data Analysis in Proteomics    GALAXY platform : https://usegalaxy.org/. You can also find a more extensive documentation here : https://galaxyproject.org/.\nAfgan, Enis et al.  The Galaxy Platform For Accessible, Reproducible And Collaborative Biomedical Analyses: 2016 Update . Nucleic Acids Res 44.W1 (2016): W3-W10.\n    The Galaxy platform for accessible, reproducible and collaborative biomedical analyses: 2016 update    UniProt : http://www.uniprot.org/. Apweiler, R.  Uniprot: The Universal Protein Knowledgebase . Nucleic Acids Research 32.90001 (2004): 115D-119.\n    UniProt: the Universal Protein knowledgebase    High-performance liquid chromatography (HPLC):  How Does High Performance Liquid Chromatography Work ?  Mant, Colin T. et al.  HPLC Analysis And Purification Of Peptides . Peptide Characterization and Application Protocols (2007): 3-55.    Aebersold, Ruedi and Matthias Mann.  Mass Spectrometry-Based Proteomics . Nature 422.6928 (2003): 198-207.\n    Mass Spectrometry-Based Proteomics    Deutsch, E. W.  File Formats Commonly Used In Mass Spectrometry Proteomics . Molecular   Cellular Proteomics 11.12 (2012): 1612-1621.\n    File Formats Commonly Used in Mass Spectrometry Proteomics    Mascot Generic Format (MGF) file is likely the most common text format for MS/MS data encoding in the form of a peak list. This file encodes multiple MS/MS spectra in a single file via m/z, intensity pairs separated by headers.\n    MGF file format    The MGF format allows parameters that can be found after the BEGIN IONS statement.\n    Embedded Parameters    The retention time of a peak can be used as means of qualitative identification. The length of time between injection and position of the target compound peak.\n    Retention Time Parameters \n    Retention Time explained for GC/MS    The Trans-Proteomic Pipeline (TPP) website : http://tools.proteomecenter.org/wiki/index.php?title=Software:TPP. Deutsch, Eric W. et al.  A Guided Tour Of The Trans-Proteomic Pipeline . Proteomics 10.6 (2010): 1150-1159.\n    A Guided Tour of the Trans-Proteomic Pipeline    ProteoWizard Tools website : http://proteowizard.sourceforge.net/tools.shtml. Holman, Jerry D., David L. Tabb, and Parag Mallick.  Employing Proteowizard To Convert Raw Mass Spectrometry Data . Current Protocols in Bioinformatics (2014): 13.24.1-13.24.9.   Employing ProteoWizard to Convert Raw Mass Spectrometry Data", 
            "title": "References"
        }, 
        {
            "location": "/modules/pathway_tools/annotation/", 
            "text": "Pathway prediction and annotations for new organisms\n\n\nConnect to mGVL using VNC\n\n\n\n\nGo to the mGVL dashboard\n\n\nClick on the link next to the \nLubuntu Destkop\n (http://your-mgvl-ip-address/vnc)\n\n\n\n\n\n\nA new browser will appear, enter your user credentials to login\n\n\n\n\nCreate a new Database\n\n\nOnce logged in, you should see the following desktop with the 3 Pathway tools icons on the left. Click on the first\nicon \nPathway Tools v1.9.5\n. This will bring up a new window.\n\n\n\n\n\n\nIn the \nPathway Tools\n window, click on \nTools\n menu item and then click on \nPathLogic\n\n\nIn the new window, at the top, click on \nDatabase\n and then \nCreate New\n\n\n\n\nProvide the metadata for the new database. In the \nDatabase(required)\n section, enter the following values:\n\n\n\n\nOrganism/Project ID:\n \nSEPSIS25707\n\n\nDatabase Name:\n \nSepsisCycl\n\n\n\n\nLeave the other parameters as the default values, that is:\n\n   Version: 1.0 (default)\n\n   DB Storage Type: File (default)\n\n\n\n\nUnder the \nTaxonomy (required)\n section:\n\n\n\n\nCheck Box if this is a multi-organism database: \nuncheck\n\n\nIn \nOrganism taxonomic class\n, type \n1314\n and click on \nSelect\n. The species name of Streptococcus pyogenes will appear and a popup window will also appear. Click on to close the window.\n\n\nCreate organism?: click \nyes\n\n\nStrain: \nHKU419(ARP)\n for sample (25707)\n\n\nGenome Source: \nARP\n\n\nNCBI taxonomy ID: \n1314\n (come back to this after Select \nStrain\n in next step)\n\n\nRank : Select \nStrain\n\n\n\n\nLeave all other fields as their default values:\n\n\n\n\nFull Species Name: autocomplete from the previous step\n\n\nAbbreviated Species Name: auto complete from the previous step\n\n\nSubspecies : leave it blank\n\n\nDefault Codon Table: 11 - Bacterial and Plant Plastid\n\n\nMitochondrial Codon Table : 0 - Unspecified\n\n\n\n\n\n\nLeave \nCredits(optional)\n section black.\n\n\n\n\nClick \nOK\n.\n\n\n\n\nAnother window will appear while processing. Wait for processing to complete, until you see the next window. Click on \nEnter Replicon Editor\n.\n\n\n\n\nSpecify Replicon details\n\n\nIn this view, you provide the details of the annotated assembly. Each chromosome will have a separate entry. For each chromosome, you need to provide the \nGBK\n and \nFNA\n annotation files from Prokka.\n\n\n\n\nName : \n1\n ( This is the chromosome name or number)\n\n\nCircular: \nchecked\n if circulator was performed or leave it unchecked\n\n\nSelect annotation file: select the gbk from prokka\n\n\nSelect sequence file: select the fna from prokka\n\n\n\n\nLeave other fields as their default value:\n\n\n\n\nType: Chromosome (default)\n\n\nCode: Bacterial, Archaeal and Plant Plastid (default)\n\n\nID: leave it blank (default)\n\n\nLinks to other database: NCBI Reference Sequences Database (default)\n\n\n\n\nRelationship : same Entity (default)\n\n\n\n\n\n\nClick \nOK\n\n\n\n\n\n\n\n\nThe metada for this database has now been created. Next we need to predict the pathways and annotate them.\n\n\nPredict and annotate the pathways\n\n\nStill on the previous window, from the top menu bar, click on \nBuild\n and then \nAutomated Build\n. This will take a while depending on the number of replicons that was included for this database.\n\n\n\n\nOnce the process has completed, a new window, \nPathway Scoring Parameters\n will appear. Leave the values as their default values.\n\n\n\n\nTaxonomic Pruning: Enabled (default)\n\n\nPathway Prediction Score Cutoff: 0.15 (default).\n\n\n\n\nA higher cutoff value for the \nprediction score\n will mean less pathways are predicted. This is the level of stringency imposed on the prediction.\n\n\nClick \nOK\n.\n\n\n\n\nAgain the process can take several minutes depending on the number of replicons included. Wait until the process is complete.\n\n\nClick on \nDatabase\n and then \nSave DB\n from the menu. The pathways have now been predicted, annotated and stored in the database.  \n\n\nVerify and test the new Database\n\n\nNow that the database has been created, we need to verify that it is available for use. First we check that it is present in the Pathway Tools. On the main screen, \nPathway Tools - Available Databases\n, you should see a new entry at the bottom of the pre-existing list, \nStreptococcus pyogenes HKU419(ARP)\n.\n\n\n\n\nTo see this newly created database in the Pathway Tools web-application, start up the Pathway Tools Web service (if not already running).\n\n\n\n\nYou can close all the windows, to exit Pathway Tools\n\n\nIf the web server is not already running, click on the \nPathway Tool Web server\n from the desktop, this is the third icon.\n\n\nOpen an internet brwoser and go to http://your-mgvl-ip-address:1555\n\n\n\n\n\n\nUsing the new database in Pathway Tools Web service\n\n\n\n\nOn the main screen, click on \nchange organism database\n at the top right corner, under the search box.\n\n\nA new window will appear, select the newly created species from the list\n\n\nClick \nOK\n\n\n\n\n\n\n\n\nA statistic table of the species will be available for overview.\n\n\n\n\nClick on the \nPathways\n link in the table, which will show the list of all predicted pathways in this database.\n\n\n\n\nYou can navigate through the list of pathways and highlight a pathway of interest. For example,\n\n\n\n\nClick on the \n+\n symbol next to \nDetoxification\n\n\nClick on the \n+\n symbol again next to \nAntibiotic Resistance\n\n\nClick on \npeptidoglycan biosynthesis V (beta-lactam resistance)\n which will bring up the pathway view  \n\n\n\n\n\n\nGo back to the previous screen with the statistics summary table and this time click on the \n1\n under the \nReplicon\n heading in the top table. The following genome browser will be shown.\n\n\n\n\nFrom here forward the user can explore using the Pathway Tools webservice.", 
            "title": "Pathway annotation and prediction"
        }, 
        {
            "location": "/modules/pathway_tools/annotation/#pathway-prediction-and-annotations-for-new-organisms", 
            "text": "", 
            "title": "Pathway prediction and annotations for new organisms"
        }, 
        {
            "location": "/modules/pathway_tools/annotation/#connect-to-mgvl-using-vnc", 
            "text": "Go to the mGVL dashboard  Click on the link next to the  Lubuntu Destkop  (http://your-mgvl-ip-address/vnc)    A new browser will appear, enter your user credentials to login", 
            "title": "Connect to mGVL using VNC"
        }, 
        {
            "location": "/modules/pathway_tools/annotation/#create-a-new-database", 
            "text": "Once logged in, you should see the following desktop with the 3 Pathway tools icons on the left. Click on the first\nicon  Pathway Tools v1.9.5 . This will bring up a new window.    In the  Pathway Tools  window, click on  Tools  menu item and then click on  PathLogic  In the new window, at the top, click on  Database  and then  Create New   Provide the metadata for the new database. In the  Database(required)  section, enter the following values:   Organism/Project ID:   SEPSIS25707  Database Name:   SepsisCycl   Leave the other parameters as the default values, that is:    Version: 1.0 (default)    DB Storage Type: File (default)   Under the  Taxonomy (required)  section:   Check Box if this is a multi-organism database:  uncheck  In  Organism taxonomic class , type  1314  and click on  Select . The species name of Streptococcus pyogenes will appear and a popup window will also appear. Click on to close the window.  Create organism?: click  yes  Strain:  HKU419(ARP)  for sample (25707)  Genome Source:  ARP  NCBI taxonomy ID:  1314  (come back to this after Select  Strain  in next step)  Rank : Select  Strain   Leave all other fields as their default values:   Full Species Name: autocomplete from the previous step  Abbreviated Species Name: auto complete from the previous step  Subspecies : leave it blank  Default Codon Table: 11 - Bacterial and Plant Plastid  Mitochondrial Codon Table : 0 - Unspecified    Leave  Credits(optional)  section black.   Click  OK .   Another window will appear while processing. Wait for processing to complete, until you see the next window. Click on  Enter Replicon Editor .", 
            "title": "Create a new Database"
        }, 
        {
            "location": "/modules/pathway_tools/annotation/#specify-replicon-details", 
            "text": "In this view, you provide the details of the annotated assembly. Each chromosome will have a separate entry. For each chromosome, you need to provide the  GBK  and  FNA  annotation files from Prokka.   Name :  1  ( This is the chromosome name or number)  Circular:  checked  if circulator was performed or leave it unchecked  Select annotation file: select the gbk from prokka  Select sequence file: select the fna from prokka   Leave other fields as their default value:   Type: Chromosome (default)  Code: Bacterial, Archaeal and Plant Plastid (default)  ID: leave it blank (default)  Links to other database: NCBI Reference Sequences Database (default)   Relationship : same Entity (default)    Click  OK     The metada for this database has now been created. Next we need to predict the pathways and annotate them.", 
            "title": "Specify Replicon details"
        }, 
        {
            "location": "/modules/pathway_tools/annotation/#predict-and-annotate-the-pathways", 
            "text": "Still on the previous window, from the top menu bar, click on  Build  and then  Automated Build . This will take a while depending on the number of replicons that was included for this database.   Once the process has completed, a new window,  Pathway Scoring Parameters  will appear. Leave the values as their default values.   Taxonomic Pruning: Enabled (default)  Pathway Prediction Score Cutoff: 0.15 (default).   A higher cutoff value for the  prediction score  will mean less pathways are predicted. This is the level of stringency imposed on the prediction.  Click  OK .   Again the process can take several minutes depending on the number of replicons included. Wait until the process is complete.  Click on  Database  and then  Save DB  from the menu. The pathways have now been predicted, annotated and stored in the database.", 
            "title": "Predict and annotate the pathways"
        }, 
        {
            "location": "/modules/pathway_tools/annotation/#verify-and-test-the-new-database", 
            "text": "Now that the database has been created, we need to verify that it is available for use. First we check that it is present in the Pathway Tools. On the main screen,  Pathway Tools - Available Databases , you should see a new entry at the bottom of the pre-existing list,  Streptococcus pyogenes HKU419(ARP) .   To see this newly created database in the Pathway Tools web-application, start up the Pathway Tools Web service (if not already running).   You can close all the windows, to exit Pathway Tools  If the web server is not already running, click on the  Pathway Tool Web server  from the desktop, this is the third icon.  Open an internet brwoser and go to http://your-mgvl-ip-address:1555", 
            "title": "Verify and test the new Database"
        }, 
        {
            "location": "/modules/pathway_tools/annotation/#using-the-new-database-in-pathway-tools-web-service", 
            "text": "On the main screen, click on  change organism database  at the top right corner, under the search box.  A new window will appear, select the newly created species from the list  Click  OK     A statistic table of the species will be available for overview.   Click on the  Pathways  link in the table, which will show the list of all predicted pathways in this database.   You can navigate through the list of pathways and highlight a pathway of interest. For example,   Click on the  +  symbol next to  Detoxification  Click on the  +  symbol again next to  Antibiotic Resistance  Click on  peptidoglycan biosynthesis V (beta-lactam resistance)  which will bring up the pathway view      Go back to the previous screen with the statistics summary table and this time click on the  1  under the  Replicon  heading in the top table. The following genome browser will be shown.   From here forward the user can explore using the Pathway Tools webservice.", 
            "title": "Using the new database in Pathway Tools Web service"
        }, 
        {
            "location": "/modules/xcms/", 
            "text": "Metabolomics with XCMS\n\n\nOverview\n\n\nMetabolomics is the study of metabolites: small molecules (smaller than proteins) produced by organisms. One technique to identify and quantify metabolites is LC/MS (liquid chromatography-mass spectrometry).\n\n\nIn liquid chromatography, metabolites are sent through a column and are separated by various chemical properties.\n\n\n\n\nAt each time point, the abundance of the particular group of metabolites is measured (the intensity).\n\n\nThis is called a chromatogram:\n\n\n\n\n\n\nimage: C Wenger, Wikipedia\n\n\nAt each time point in this chromatogram, the group of metabolites is then ionized (charged) and fired through a mass spectrometer.\n\n\n\n\nThese are separated based on their mass-to-charge ratio.\n\n\nThis adds another dimension to the graph: an axis with the mass-to-charge ratio of the metabolites found at that time point, and their intensities.\n\n\n\n\n\n\nimage: Daniel Norena-Caro, Wikipedia.\n\n\nThere are multiple mass spectra. Each spectrum is often simplified into a graph of peaks only (local maxima):\n\n\n\n\nimage: Wikipedia.\n\n\n\n\nEach of these peaks is a \nfeature\n: an ion with a unique m/z and retention time.\n\n\nThese masses can then be matched to a database to identify the metabolites.\n\n\n\n\n\n\n\nA common aim is to compare metabolites between two samples (e.g. two different bacterial strains), and from there, to understand which biological pathways may be up- or down-regulated.\n\n\nIn this tutorial, we will use a platform called \nXCMS online\n to analyse metabolite data.\n\n\n\n\nInput: raw data from mass spectrometry\n\n\nOutput: identified metabolites, and a comparison of their abundances between samples.\n\n\n\n\nXCMS\n\n\nGo to: \nhttps://xcmsonline.scripps.edu\n and sign up.\n\n\n\n\nGet data\n\n\nThe data we will use today is from two bacterial strains of \nKlebsiella pneumoniae\n.\n\n\n\n\nstrain AJ218 - 6 replicates\n\n\nstrain KPC2 (antibiotic resistance) - 6 replicates\n\n\n\n\nThe raw data output from the mass spectrometer are points in a 3D graph: intensity, m/z, time (retention time).\n\n\nDownload these files to your local computer.\n\n\n\n\n\nData format:\n\n\n\n\n\n\nWe will use .mzML format. \n\n\n\n\n\n\nThe machine used to produced this data originally produced .d files. These have been converted into .mzML format using the Proteowizard MSConvert program.\n\n\n\n\n\n\nTo use Proteowizard: (Windows only)\n\n\n\n\nDownload the program and open the MSConvert program.\n\n\nBrowse. Add files.\n\n\nChange output format to .mzML\n\n\nLeave default settings.\n\n\nClick Start in the bottom right hand corner.\n\n\n\n\nAn alternative is the commercially-available Qualitative Analysis Software.\n\n\nUpload data\n\n\nIn the top panel, go to \nStored Datasets\n. We will upload some data here.\n\n\n\n\n\n\n\n\nDrag the \n.mzML\n files into the \nDrop Here\n box - 6 replicates for each strain.\n\n\n\n\n\n\nWait until all files have a green tick (scroll down to check all).\n\n\n\n\nName the datset (e.g. Sample AJ218 or Sample KPC2) and click \nSave\n.\n\n\nClick \nSave Dataset \n Proceed\n.\n\n\n\n\n\n\nRepeat with the second strain.\n\n\nSet up job\n\n\nIn the top panel, click on \nCreate Job\n and select \nPairwise Job\n.\n\n\n\n\nOn the right hand side, under Job Summary, Job Name: click \nEdit\n, enter job name: e.g. Klebsiella, and then click \nSave\n.\n\n\nUnder \nDataset 1\n click on \nSelect Dataset\n.\n\n\n\n\nChoose AJ218.\n\n\n\n\nUnder \nDataset 2\n click on \nSelect Dataset\n.\n\n\n\n\nChoose KPC2.\n\n\n\n\nWe now need to set parameters that correspond with the machine on which the data was generated. In a typical analysis, we would look at the raw output files and examine the chromatograms and mass spectra to inform some of the settings. Here we have chosen appropriate settings for this data set.\n\n\n\n\n\nUnder \nParameters\n select HPLC / UHD Q-TOF (HILIC, neg. mode).\n\n\n\n\nClick \nView/Edit\n.\n\n\nThis brings up a window to change some settings.\n\n\n\n\n\n\n\n\n\nGeneral\n\n\n\n\nFirst, click \nCreate New\n in the bottom right hand corner.\n\n\nGive it a name. e.g. Agilent 6545\n\n\n(Don\nt click Save Current yet).\n\n\nRetention time format\n: seconds\n\n\nPolarity\n: negative\n\n\n\n\nSee the tabs along the top: we will change some of these settings.\n\n\nFeature Detection\n\n\nThis is to adjust for noise in the centroid data.\n\n\n\n\nMethod\n: centWave\n\n\nppm\n: 50\n\n\nminimum peak width\n: 10\n\n\nmaximum peak width\n: 50\n\n\n\n\nRetention time correction\n\n\nThis is to correct the shift that occurs as the run progresses.\n\n\n\n\nMethod\n: obiwarp\n\n\nprofStep\n: 0.1\n\n\n\n\nAlignment\n\n\nThis is to align spectra after retention time correction.\n\n\n\n\nmzwid\n: 0.5\n\n\nminfrac\n: 0.5\n\n\nbw\n: 20\n\n\n\n\nStatistics\n\n\nSet up the statistical test for the metabolites from two strains.\n\n\n\n\nStatistical\n test: Unpaired non-parametric (Mann-Whitney)\n\n\n\n\nAnnotation\n\n\n\n\nSearch for\n: isotopes + adducts\n\n\nm/z absolute error\n: 0.05\n\n\nppm\n: 50\n\n\n\n\n\n\n\nIdentification\n\n\n\n\nppm\n: 50\n\n\nadducts\n: [M-H]-\n\n\nsample biosource\n: Select biosource. Search: K pneumo. \nSelect\n the top strain.\n\n\npathway ppm deviation\n: 5\n\n\n\n\nVisualization\n\n\n\n\nEIC width\n: 200\n\n\n\n\nMiscellaneous\n\n\n\n\nBypass file sanity check\n: tick\n\n\n\n\nNext\n\n\n\n\nSave Current\n\n\nSubmit Job\n\n\n\n\nThis will now bring up the \nView Results\n page.\n\n\n\n\nThe current job will be listed as \nProcessing\n with a % completion bar.\n\n\nThe time taken will depend on server load.\n\n\n\n\nView results\n\n\nClick on \nView\n.\n\n\nThere are six graphs, and options for other results in the left hand panel.\n\n\n\n\nIons detected\n\n\nLook at the top three graphs.\n\n\n\n\n\n\nGraph 1: Total ion Chromatograms (original):\n\n\n\n\nAll the ions detected. Their intensity vs retention time.\n\n\n\n\n\n\n\n\nGraph 2: Retention Time Deviation vs. Retention Time:\n\n\n\n\nA graph showing the correction curve.\n\n\n\n\n\n\n\n\nGraph 3: Total ion Chromatograms (corrected):\n\n\n\n\nA corrected version of graph 1.\n\n\n\n\n\n\n\n\nSample information\n\n\n\n\n\n\nGraphs 5 and 6 show MDS (Multi-dimensional Scaling) and PCA (Principal Components Analysis) results.\n\n\n\n\nAre the samples separated well?\n\n\nSamples (or conditions) should be separated into two groups.\n\n\nFor a more detailed examination, click on \niPCA\n in the left hand panel.\n\n\n\n\n\n\n\n\nResults Table\n\n\nClick on the Results Table in the left hand panel. This is a table of \nfeatures\n - a feature is an ion with unique m/z and retention time.\n\n\n\n\n\n\n\nClick on a row (a feature) to display associated graphs in the right-hand panel.\n\n\n\n\n\n\n\n\nThe \nMETLIN database\n contains data on metabolites, their mass, and their known and predicted fragment masses.\n\n\n\n\nTo filter the table, click on the small magnifying glass:\n\n\n\n\n\n\nFilter by p-value or fold change (or both).\n\n\ne.g. p-value less or equal to 0.01, fold change greater than 30\n\n\nInvestigate these features and the identified matches in the Metlin database.\n\n\n\n\n\n\n\nCloud plot\n\n\nIn the results pane on the left, click on Metabolomic Cloud Plot.\n\n\n\n\nA cloud plot shows the features (m/z and retention time) as dots/circles.\n\n\nThe size of the circles is relative to their fold change.\n\n\nFeatures are shown as either up- or down-regulated, by their position above or below the 0-axis.\n\n\nAdjust p-value and fold change, and click \nRegenerate Cloud Plot\n.\n\n\nClick on a feature to see its associated graphs in the left hand panel.\n\n\n\n\n\n\nActivity network\n\n\nThis shows the pathways that correspond to the identified metabolites. The table under the image shows the \nTop pathways\n - these are ordered by their p-values.\n\n\n\n\n\nLinks\n\n\nXCMS Online\n\n\nXCMS Documentation\n\n\nTautenhahn, R. et al. (2012) XCMS Online: A Web-Based Platform to Process Untargeted Metabolomic Data. \nAnalytical Chemistry\n. DOI: 10.1021/ac300698c\n\n\nSmith, R. et al. (2014) Proteomics, lipidomics, metabolomics: a mass spectrometry tutorial from a computer scientist\ns point of view. \nBMC Bioinformatics\n. DOI: 10.1186/1471-2105-15-S7-S9. \nSee Figure 2 for an excellent explanation of the various graphs produced from MS.\n\n\nPatti, G. J. et al. (2013) A View from Above: Cloud Plots to Visualize Global Metabolomic Data. \nAnalytical Chemistry\n. DOI: 10.1021/ac3029745", 
            "title": "Metabolite identification"
        }, 
        {
            "location": "/modules/xcms/#metabolomics-with-xcms", 
            "text": "", 
            "title": "Metabolomics with XCMS"
        }, 
        {
            "location": "/modules/xcms/#overview", 
            "text": "Metabolomics is the study of metabolites: small molecules (smaller than proteins) produced by organisms. One technique to identify and quantify metabolites is LC/MS (liquid chromatography-mass spectrometry).  In liquid chromatography, metabolites are sent through a column and are separated by various chemical properties.   At each time point, the abundance of the particular group of metabolites is measured (the intensity).  This is called a chromatogram:    image: C Wenger, Wikipedia  At each time point in this chromatogram, the group of metabolites is then ionized (charged) and fired through a mass spectrometer.   These are separated based on their mass-to-charge ratio.  This adds another dimension to the graph: an axis with the mass-to-charge ratio of the metabolites found at that time point, and their intensities.    image: Daniel Norena-Caro, Wikipedia.  There are multiple mass spectra. Each spectrum is often simplified into a graph of peaks only (local maxima):   image: Wikipedia.   Each of these peaks is a  feature : an ion with a unique m/z and retention time.  These masses can then be matched to a database to identify the metabolites.    A common aim is to compare metabolites between two samples (e.g. two different bacterial strains), and from there, to understand which biological pathways may be up- or down-regulated.  In this tutorial, we will use a platform called  XCMS online  to analyse metabolite data.   Input: raw data from mass spectrometry  Output: identified metabolites, and a comparison of their abundances between samples.", 
            "title": "Overview"
        }, 
        {
            "location": "/modules/xcms/#xcms", 
            "text": "Go to:  https://xcmsonline.scripps.edu  and sign up.", 
            "title": "XCMS"
        }, 
        {
            "location": "/modules/xcms/#get-data", 
            "text": "The data we will use today is from two bacterial strains of  Klebsiella pneumoniae .   strain AJ218 - 6 replicates  strain KPC2 (antibiotic resistance) - 6 replicates   The raw data output from the mass spectrometer are points in a 3D graph: intensity, m/z, time (retention time).  Download these files to your local computer.   Data format:    We will use .mzML format.     The machine used to produced this data originally produced .d files. These have been converted into .mzML format using the Proteowizard MSConvert program.    To use Proteowizard: (Windows only)   Download the program and open the MSConvert program.  Browse. Add files.  Change output format to .mzML  Leave default settings.  Click Start in the bottom right hand corner.   An alternative is the commercially-available Qualitative Analysis Software.", 
            "title": "Get data"
        }, 
        {
            "location": "/modules/xcms/#upload-data", 
            "text": "In the top panel, go to  Stored Datasets . We will upload some data here.     Drag the  .mzML  files into the  Drop Here  box - 6 replicates for each strain.    Wait until all files have a green tick (scroll down to check all).   Name the datset (e.g. Sample AJ218 or Sample KPC2) and click  Save .  Click  Save Dataset   Proceed .    Repeat with the second strain.", 
            "title": "Upload data"
        }, 
        {
            "location": "/modules/xcms/#set-up-job", 
            "text": "In the top panel, click on  Create Job  and select  Pairwise Job .   On the right hand side, under Job Summary, Job Name: click  Edit , enter job name: e.g. Klebsiella, and then click  Save .  Under  Dataset 1  click on  Select Dataset .   Choose AJ218.   Under  Dataset 2  click on  Select Dataset .   Choose KPC2.   We now need to set parameters that correspond with the machine on which the data was generated. In a typical analysis, we would look at the raw output files and examine the chromatograms and mass spectra to inform some of the settings. Here we have chosen appropriate settings for this data set.   Under  Parameters  select HPLC / UHD Q-TOF (HILIC, neg. mode).   Click  View/Edit .  This brings up a window to change some settings.", 
            "title": "Set up job"
        }, 
        {
            "location": "/modules/xcms/#general", 
            "text": "First, click  Create New  in the bottom right hand corner.  Give it a name. e.g. Agilent 6545  (Don t click Save Current yet).  Retention time format : seconds  Polarity : negative   See the tabs along the top: we will change some of these settings.", 
            "title": "General"
        }, 
        {
            "location": "/modules/xcms/#feature-detection", 
            "text": "This is to adjust for noise in the centroid data.   Method : centWave  ppm : 50  minimum peak width : 10  maximum peak width : 50", 
            "title": "Feature Detection"
        }, 
        {
            "location": "/modules/xcms/#retention-time-correction", 
            "text": "This is to correct the shift that occurs as the run progresses.   Method : obiwarp  profStep : 0.1", 
            "title": "Retention time correction"
        }, 
        {
            "location": "/modules/xcms/#alignment", 
            "text": "This is to align spectra after retention time correction.   mzwid : 0.5  minfrac : 0.5  bw : 20", 
            "title": "Alignment"
        }, 
        {
            "location": "/modules/xcms/#statistics", 
            "text": "Set up the statistical test for the metabolites from two strains.   Statistical  test: Unpaired non-parametric (Mann-Whitney)", 
            "title": "Statistics"
        }, 
        {
            "location": "/modules/xcms/#annotation", 
            "text": "Search for : isotopes + adducts  m/z absolute error : 0.05  ppm : 50", 
            "title": "Annotation"
        }, 
        {
            "location": "/modules/xcms/#identification", 
            "text": "ppm : 50  adducts : [M-H]-  sample biosource : Select biosource. Search: K pneumo.  Select  the top strain.  pathway ppm deviation : 5", 
            "title": "Identification"
        }, 
        {
            "location": "/modules/xcms/#visualization", 
            "text": "EIC width : 200", 
            "title": "Visualization"
        }, 
        {
            "location": "/modules/xcms/#miscellaneous", 
            "text": "Bypass file sanity check : tick", 
            "title": "Miscellaneous"
        }, 
        {
            "location": "/modules/xcms/#next", 
            "text": "Save Current  Submit Job   This will now bring up the  View Results  page.   The current job will be listed as  Processing  with a % completion bar.  The time taken will depend on server load.", 
            "title": "Next"
        }, 
        {
            "location": "/modules/xcms/#view-results", 
            "text": "Click on  View .  There are six graphs, and options for other results in the left hand panel.", 
            "title": "View results"
        }, 
        {
            "location": "/modules/xcms/#ions-detected", 
            "text": "Look at the top three graphs.    Graph 1: Total ion Chromatograms (original):   All the ions detected. Their intensity vs retention time.     Graph 2: Retention Time Deviation vs. Retention Time:   A graph showing the correction curve.     Graph 3: Total ion Chromatograms (corrected):   A corrected version of graph 1.", 
            "title": "Ions detected"
        }, 
        {
            "location": "/modules/xcms/#sample-information", 
            "text": "Graphs 5 and 6 show MDS (Multi-dimensional Scaling) and PCA (Principal Components Analysis) results.   Are the samples separated well?  Samples (or conditions) should be separated into two groups.  For a more detailed examination, click on  iPCA  in the left hand panel.", 
            "title": "Sample information"
        }, 
        {
            "location": "/modules/xcms/#results-table", 
            "text": "Click on the Results Table in the left hand panel. This is a table of  features  - a feature is an ion with unique m/z and retention time.    Click on a row (a feature) to display associated graphs in the right-hand panel.     The  METLIN database  contains data on metabolites, their mass, and their known and predicted fragment masses.   To filter the table, click on the small magnifying glass:    Filter by p-value or fold change (or both).  e.g. p-value less or equal to 0.01, fold change greater than 30  Investigate these features and the identified matches in the Metlin database.", 
            "title": "Results Table"
        }, 
        {
            "location": "/modules/xcms/#cloud-plot", 
            "text": "In the results pane on the left, click on Metabolomic Cloud Plot.   A cloud plot shows the features (m/z and retention time) as dots/circles.  The size of the circles is relative to their fold change.  Features are shown as either up- or down-regulated, by their position above or below the 0-axis.  Adjust p-value and fold change, and click  Regenerate Cloud Plot .  Click on a feature to see its associated graphs in the left hand panel.", 
            "title": "Cloud plot"
        }, 
        {
            "location": "/modules/xcms/#activity-network", 
            "text": "This shows the pathways that correspond to the identified metabolites. The table under the image shows the  Top pathways  - these are ordered by their p-values.", 
            "title": "Activity network"
        }, 
        {
            "location": "/modules/xcms/#links", 
            "text": "XCMS Online  XCMS Documentation  Tautenhahn, R. et al. (2012) XCMS Online: A Web-Based Platform to Process Untargeted Metabolomic Data.  Analytical Chemistry . DOI: 10.1021/ac300698c  Smith, R. et al. (2014) Proteomics, lipidomics, metabolomics: a mass spectrometry tutorial from a computer scientist s point of view.  BMC Bioinformatics . DOI: 10.1186/1471-2105-15-S7-S9.  See Figure 2 for an excellent explanation of the various graphs produced from MS.  Patti, G. J. et al. (2013) A View from Above: Cloud Plots to Visualize Global Metabolomic Data.  Analytical Chemistry . DOI: 10.1021/ac3029745", 
            "title": "Links"
        }, 
        {
            "location": "/about/", 
            "text": "About\n\n\nThe Food and Health Flagship is an \nRDS-funded\n project to provide cloud-based data services and tools\nfor Australian Life Science Researchers to combine, analyse and interpret\ngenomic, transcriptomic, proteomic and metabolomic data. The data platform will incorporate the \nBioplatforms Australia Antibiotic Resistant Pathogens Initiative (ABRPI)\n.\n\n\nAuthors\n\n\n Anna Syme\n\n\n Torsten Seemann\n\n\n Simon Gladman\n\n\n Dieter Bulach\n\n\n Xin-Yi Chua\n\n\n Dominique Gorse\n\n\n Mike Thang\n\n\nSupport\n\n\n\n\nResearch Data Services\n\n\nBioplatforms Australia\n\n\nNectar\n\n\n\n\n\n\nThese training materials have been used for:\n\n\nMcGill Summer Institute in Infectious Diseases and Global Health, June 2016, Montreal, Canada\n\n\n\n\n\n\nGalaxy Community Conference 2016, Indiana, USA\n\n\n\n\n\n\nCLIMB UK Launch: Cloud Infrastructure for Microbial Bioinformatics, 2016", 
            "title": "About"
        }, 
        {
            "location": "/about/#about", 
            "text": "The Food and Health Flagship is an  RDS-funded  project to provide cloud-based data services and tools\nfor Australian Life Science Researchers to combine, analyse and interpret\ngenomic, transcriptomic, proteomic and metabolomic data. The data platform will incorporate the  Bioplatforms Australia Antibiotic Resistant Pathogens Initiative (ABRPI) .", 
            "title": "About"
        }, 
        {
            "location": "/about/#authors", 
            "text": "Anna Syme   Torsten Seemann   Simon Gladman   Dieter Bulach   Xin-Yi Chua   Dominique Gorse   Mike Thang", 
            "title": "Authors"
        }, 
        {
            "location": "/about/#support", 
            "text": "Research Data Services  Bioplatforms Australia  Nectar    These training materials have been used for:  McGill Summer Institute in Infectious Diseases and Global Health, June 2016, Montreal, Canada    Galaxy Community Conference 2016, Indiana, USA    CLIMB UK Launch: Cloud Infrastructure for Microbial Bioinformatics, 2016", 
            "title": "Support"
        }
    ]
}